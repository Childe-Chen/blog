<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[(译)JVM Concurrent Mark Sweep (CMS) Collector 1.8]]></title>
      <url>%2F2017%2F05%2F22%2F%E8%AF%91-JVM-Concurrent-Mark-Sweep-CMS-Collector-1-8%2F</url>
      <content type="text"><![CDATA[原文链接：https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html The Concurrent Mark Sweep (CMS) collector is designed for applications that prefer shorter garbage collection pauses and that can afford to share processor resources with the garbage collector while the application is running. Typically applications that have a relatively large set of long-lived data (a large tenured generation) and run on machines with two or more processors tend to benefit from the use of this collector. However, this collector should be considered for any application with a low pause time requirement. The CMS collector is enabled with the command-line option -XX:+UseConcMarkSweepGC. CMS收集器特点：1.更短的垃圾回收暂停(stop the world) 2.垃圾收集器能够在应用运行时与其共享处理器资源。通常，一个运行在多处理器机器上并且其中有长期存活的大集合(较大的老生代)的应用可以考虑使用CMS收集器。当然，对于具有低暂停时间要求的应用，都可以考虑该收集器。使用-XX:+UseConcMarkSweepGC选项启用CMS收集器。 Similar to the other available collectors, the CMS collector is generational; thus both minor and major collections occur. The CMS collector attempts to reduce pause times due to major collections by using separate garbage collector threads to trace the reachable objects concurrently with the execution of the application threads. During each major collection cycle, the CMS collector pauses all the application threads for a brief period at the beginning of the collection and again toward the middle of the collection. The second pause tends to be the longer of the two pauses. Multiple threads are used to do the collection work during both pauses. The remainder of the collection (including most of the tracing of live objects and sweeping of unreachable objects is done with one or more garbage collector threads that run concurrently with the application. Minor collections can interleave with an ongoing major cycle, and are done in a manner similar to the parallel collector (in particular, the application threads are stopped during minor collections). 和其他收集器一样，CMS是分代的，新生代和老年代都会发生回收。CMS尝试通过多个跟踪对象的可达性的垃圾收集线程和应用线程并发的方式来减少老生代的收集时间。在老年代垃圾回收期间，CMS会发生两次STW：1.收集开始首次标记时（initial-mark）2.二次标记时（remark）。第二次暂停的时间往往比第一次要长。这两次标记均使用多线程。其余的收集（包括大多存活对象跟踪和不可大对象的清除）使用一个或多个回收线程和应用并发执行。新生代的回收可以和正在执行老年年代回收交错执行，以类似于并行收集器的方式完成（在新生代回收期间应用程序线程被停止STW）。 Concurrent Mode FailureThe CMS collector uses one or more garbage collector threads that run simultaneously with the application threads with the goal of completing the collection of the tenured generation before it becomes full. As described previously, in normal operation, the CMS collector does most of its tracing and sweeping work with the application threads still running, so only brief pauses are seen by the application threads. However, if the CMS collector is unable to finish reclaiming the unreachable objects before the tenured generation fills up, or if an allocation cannot be satisfied with the available free space blocks in the tenured generation, then the application is paused and the collection is completed with all the application threads stopped. The inability to complete a collection concurrently is referred to as concurrent mode failure and indicates the need to adjust the CMS collector parameters. If a concurrent collection is interrupted by an explicit garbage collection (System.gc()) or for a garbage collection needed to provide information for diagnostic tools, then a concurrent mode interruption is reported. CMS使用一个或多个线程和应用线程同时进行，目标是在老生代被消耗完之前完成回收。如前所述，在正常操作中，CMS收集器执行大部分追踪和清理工作时，应用程序线程仍在运行，因此应用线程只会短暂暂停。但是，如果在垃圾回收完成前，老生代被耗尽，或者老生代无法分配足够的空间，此时会暂停所有的应用线程直到垃圾回收完成。没有在并发期间完成收集工作称为concurrent mode failure，这个失败表明我们需要调整CMS收集器的参数。如果并发回收被显示调用(System.gc()) 或者为了给诊断工具提供信息而发生中断，则会报告并发模式中断。 Excessive GC Time and OutOfMemoryErrorExcessive GC Time and OutOfMemoryErrorThe CMS collector throws an OutOfMemoryError if too much time is being spent in garbage collection: if more than 98% of the total time is spent in garbage collection and less than 2% of the heap is recovered, then an OutOfMemoryError is thrown. This feature is designed to prevent applications from running for an extended period of time while making little or no progress because the heap is too small. If necessary, this feature can be disabled by adding the option -XX:-UseGCOverheadLimit to the command line. The policy is the same as that in the parallel collector, except that time spent performing concurrent collections is not counted toward the 98% time limit. In other words, only collections performed while the application is stopped count toward excessive GC time. Such collections are typically due to a concurrent mode failure or an explicit collection request (for example, a call to System.gc). 当GC时间太久（垃圾收集花费时间，超过了总时间的98%，但是回收的堆少于2%,总时间究竟是相对哪个时间而言？在下还未找到解释。），CMS会抛出OutOfMemoryError。这个特性旨在避免由于对空间过小而导致应用程序业务处理缓慢或者无进展。这个特性可以用-XX:-UseGCOverheadLimit命令禁用。 这个策略和并发收集器一致，只是并发回收垃圾的时间不计入98%的时间消耗中。换句话讲，只有发生了STW情况下的收集时间（两次标记的时间）会计入这98%的时间限制内。这种回收通常是由于concurrent mode failure或者回收请求（比如：显示调用System.gc）。 Floating GarbageThe CMS collector, like all the other collectors in Java HotSpot VM, is a tracing collector that identifies at least all the reachable objects in the heap. In the parlance of Richard Jones and Rafael D. Lins in their publication Garbage Collection: Algorithms for Automated Dynamic Memory, it is an incremental update collector. Because application threads and the garbage collector thread run concurrently during a major collection, objects that are traced by the garbage collector thread may subsequently become unreachable by the time collection process ends. Such unreachable objects that have not yet been reclaimed are referred to as floating garbage. The amount of floating garbage depends on the duration of the concurrent collection cycle and on the frequency of reference updates, also known as mutations, by the application. Furthermore, because the young generation and the tenured generation are collected independently, each acts a source of roots to the other. As a rough guideline, try increasing the size of the tenured generation by 20% to account for the floating garbage. Floating garbage in the heap at the end of one concurrent collection cycle is collected during the next collection cycle.``` CMS和其他Java HotSpot VM一样，是一个会标记堆中所有可达对象的追踪回收器。在《Algorithms for Automated Dynamic Memory》中CMS被称作增量收集器。因为应用线程和垃圾回收线程在老年代回收时是并发运行的，所以，那些被垃圾回收线程追踪的对象在会后结束时可能会变得不可达。像这些尚未被回收并且不可达的引用被称为浮动垃圾。浮动垃圾的数量取决于并发收集周期的持续时间以及应用程序的引用更新频率（也称为突变）。此外，因为新生代和老年代的垃圾回收是相互独立的，各自的根部相同，所以，根据经验建议将老年代的增加20%来承载浮动垃圾。一个并发回收周期节后产生的浮动垃圾会在下个垃圾回收中回收。 PausesThe CMS collector pauses an application twice during a concurrent collection cycle. The first pause is to mark as live the objects directly reachable from the roots (for example, object references from application thread stacks and registers, static objects and so on) and from elsewhere in the heap (for example, the young generation). This first pause is referred to as the initial mark pause. The second pause comes at the end of the concurrent tracing phase and finds objects that were missed by the concurrent tracing due to updates by the application threads of references in an object after the CMS collector had finished tracing that object. This second pause is referred to as the remark pause. CMS在一次回收的过程中会两次暂停（STW）应用。第一次是标记从GC root（比如：被应用线程栈引用的对象和registers，静态的对象等等）可以直接到达的对象和从堆的其他地方（比如：新生代）。第一次暂停叫做初始标记暂停（initial mark pause）。第二次暂停发生在并发追踪阶段结束后，这次暂停是为了标记那些在并发追踪期间因为被应用线程更新引用而错过的对象。第二次暂停叫做重新标记暂停（remark pause）。 Concurrent PhasesThe concurrent tracing of the reachable object graph occurs between the initial mark pause and the remark pause. During this concurrent tracing phase one or more concurrent garbage collector threads may be using processor resources that would otherwise have been available to the application. As a result, compute-bound applications may see a commensurate fall in application throughput during this and other concurrent phases even though the application threads are not paused. After the remark pause, a concurrent sweeping phase collects the objects identified as unreachable. Once a collection cycle completes, the CMS collector waits, consuming almost no computational resources, until the start of the next major collection cycle. 并发追踪可达对象图发生在初始标记（initial mark）和重新标记（remark）之间。在并发标记阶段会有一个或者多个垃圾回收线程在使用处理器资源（？otherwise怎么译）。因此，在垃圾回收期间计算密集型应用吞吐量会下降，即使应用线程没有被暂停。在冲标记阶段后，会并发清理那些被被标记为不可达的对象。垃圾回收完成后，CMS进入等待，几乎不消耗任何计算资源，直到下一个老年代回收开始。 Starting a Concurrent Collection CycleWith the serial collector a major collection occurs whenever the tenured generation becomes full and all application threads are stopped while the collection is done. In contrast, the start of a concurrent collection must be timed such that the collection can finish before the tenured generation becomes full; otherwise, the application would observe longer pauses due to concurrent mode failure. There are several ways to start a concurrent collection. Based on recent history, the CMS collector maintains estimates of the time remaining before the tenured generation will be exhausted and of the time needed for a concurrent collection cycle. Using these dynamic estimates, a concurrent collection cycle is started with the aim of completing the collection cycle before the tenured generation is exhausted. These estimates are padded for safety, because concurrent mode failure can be very costly. A concurrent collection also starts if the occupancy of the tenured generation exceeds an initiating occupancy (a percentage of the tenured generation). The default value for this initiating occupancy threshold is approximately 92%, but the value is subject to change from release to release. This value can be manually adjusted using the command-line option -XX:CMSInitiatingOccupancyFraction=, where is an integral percentage (0 to 100) of the tenured generation size. 老年代串行垃圾收集器在老年代即将耗尽时开始工作，此时所有应用线程都会暂停直到垃圾回收完成。相反，从开始并发回收时进行计时，以使收集在老年代耗尽之前完成，否则会因为concurrent mode failure使得应用暂停更长时间。有几种方式可以开始一个并发回收。 基于最近的回收历史，CMS会维护两个预估时间：老年代多久会被耗尽；完成一次老年代的回收需要多久。依据这些动态估计值，在老年代耗尽前适时开始老年代的回收。这些预估值是为了避免耗时的concurrent mode failure。 如果老年代占用的空间超过了启动设置的大小（一个老生代的占用比）。默认的启动设置的阀值是92%，但是这个值会随着版本发布改变。这个值可以通过命令行选项配置-XX:CMSInitiatingOccupancyFraction=，N是占用老生代大小的百分比（0-100）。 Scheduling PausesThe pauses for the young generation collection and the tenured generation collection occur independently. They do not overlap, but may occur in quick succession such that the pause from one collection, immediately followed by one from the other collection, can appear to be a single, longer pause. To avoid this, the CMS collector attempts to schedule the remark pause roughly midway between the previous and next young generation pauses. This scheduling is currently not done for the initial mark pause, which is usually much shorter than the remark pause. 老年代和新生代垃圾回收引起的暂停是独立的。它们不会重叠，但是可能会快速连续发生，比如：一个回收暂停结束后另一个回收又立刻导致暂停，看起来就像单独一个很长的暂停。为了避免这种情况，CMS尝试规划将remark暂停放在两次新生代回收（Young GC）之间。这个规划尚未在初始标记暂停（initial mark pause）使用，因为初始标记暂停（initial mark pause）通常比remark pause要短。 Incremental ModeNote that the incremental mode is being deprecated in Java SE 8 and may be removed in a future major release. 请注意，增量模式在Java SE 8中已被弃用，并可能在将来的主要版本中被删除，所以不在翻译和i-cms有关部分。 MeasurementsExample 8-1, “Output from the CMS Collector” is the output from the CMS collector with the options -verbose:gc and -XX:+PrintGCDetails, with a few minor details removed. Note that the output for the CMS collector is interspersed with the output from the minor collections; typically many minor collections occur during a concurrent collection cycle. CMS-initial-mark indicates the start of the concurrent collection cycle, CMS-concurrent-mark indicates the end of the concurrent marking phase, and CMS-concurrent-sweep marks the end of the concurrent sweeping phase. Not discussed previously is the precleaning phase indicated by CMS-concurrent-preclean. Precleaning represents work that can be done concurrently in preparation for the remark phase CMS-remark. The final phase is indicated by CMS-concurrent-reset and is in preparation for the next concurrent collection. Example 8-1 Output from the CMS Collector [GC [1 CMS-initial-mark: 13991K(20288K)] 14103K(22400K), 0.0023781 secs] [GC [DefNew: 2112K-&gt;64K(2112K), 0.0837052 secs] 16103K-&gt;15476K(22400K), 0.0838519 secs] ... [GC [DefNew: 2077K-&gt;63K(2112K), 0.0126205 secs] 17552K-&gt;15855K(22400K), 0.0127482 secs] [CMS-concurrent-mark: 0.267/0.374 secs] [GC [DefNew: 2111K-&gt;64K(2112K), 0.0190851 secs] 17903K-&gt;16154K(22400K), 0.0191903 secs] [CMS-concurrent-preclean: 0.044/0.064 secs] [GC [1 CMS-remark: 16090K(20288K)] 17242K(22400K), 0.0210460 secs] [GC [DefNew: 2112K-&gt;63K(2112K), 0.0716116 secs] 18177K-&gt;17382K(22400K), 0.0718204 secs] [GC [DefNew: 2111K-&gt;63K(2112K), 0.0830392 secs] 19363K-&gt;18757K(22400K), 0.0832943 secs] ... [GC [DefNew: 2111K-&gt;0K(2112K), 0.0035190 secs] 17527K-&gt;15479K(22400K), 0.0036052 secs] [CMS-concurrent-sweep: 0.291/0.662 secs] [GC [DefNew: 2048K-&gt;0K(2112K), 0.0013347 secs] 17527K-&gt;15479K(27912K), 0.0014231 secs] [CMS-concurrent-reset: 0.016/0.016 secs] [GC [DefNew: 2048K-&gt;1K(2112K), 0.0013936 secs] 17527K-&gt;15479K(27912K), 0.0014814 secs] The initial mark pause is typically short relative to the minor collection pause time. The concurrent phases (concurrent mark, concurrent preclean and concurrent sweep) normally last significantly longer than a minor collection pause, as indicated by Example 8-1, “Output from the CMS Collector”. Note, however, that the application is not paused during these concurrent phases. The remark pause is often comparable in length to a minor collection. The remark pause is affected by certain application characteristics (for example, a high rate of object modification can increase this pause) and the time since the last minor collection (for example, more objects in the young generation may increase this pause). 例子8-1是打开-verbose:gc和-XX:+PrintGCDetails选项后的gc打印日志，例子中略去了一些新生代的收集细节。注意CMS收集器打印的日志和新生代回收打印的日志是穿插在一起的，通常在一个老年代回收周期中会发生多次新生代回收。CMS-initial-mark表明一个并发收集周期的开始，CMS-concurrent-mark表明并发标记阶段已经完成，CMS-concurrent-sweep说明并发清除阶段已经结束。CMS-concurrent-preclean是预清理阶段。预清理工作并发进行，是CMS-remark阶段的前置操作。CMS-concurrent-reset是老年代垃圾回收的最后一个阶段也是为下次回收做预备工作。 初始标记阶段耗时通常比年轻代暂停时间短。从例8-1我们不难发现，并发阶段（并发标记，并发预清理和并发清除）通常耗时比新生代回收时间长。但是，应用在这些阶段中并没有暂停。重新标记耗时与新生代回收耗时差不多。重新标记的耗时会受某些应用特性（比如：高对象修改率会增加此阶段耗时）和距离上次老年代收集时间（比如：新生代有了更多的对象会增加此阶段耗时）的影响。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK源码 Hash杂记]]></title>
      <url>%2F2017%2F05%2F11%2FJDK%E6%BA%90%E7%A0%81-hash%E6%9D%82%E8%AE%B0%2F</url>
      <content type="text"><![CDATA[最早了解Hash的用法，是一次分表的经历，公司用户表数据有几千万，查询的效率已经比较低了，需要做拆分处理，之前系统中已经有分表的数据，处理方式比较简单，没有使用中间件，按照商家的ID（32位字符串）做Hash然后取模，算出其落在表的编号，然后加上前缀得到最终表名。 最近在了解zk分布式锁时，为了避免一种实现方式的羊群效应，其改进思路类似一致性哈希算法。于是，便看了下Hash相关的知识，并用Java做了简单实现。 哈希简介哈希算法将任意长度的二进制值映射为较短的固定长度的二进制值，这个小的二进制值称为哈希值。哈希值是一段数据唯一且极其紧凑的数值表示形式。如果散列一段明文而且哪怕只更改该段落的一个字母，随后的哈希都将产生不同的值。要找到散列为同一个值的两个不同的输入，在计算上是不可能的，所以数据的哈希值可以检验数据的完整性。一般用于快速查找和加密算法。 简单的Hash应用类似开头我们的场景，我们根据Hash的特性用代码来模拟下。 123456789101112131415161718192021/** * 表，实际存储 * Created by childe on 2017/5/14. */public class Table &#123; private String name; Map&lt;String,Merchant&gt; merchantMap; Table(String name) &#123; this.name = name; merchantMap = new HashMap&lt;&gt;(); &#125; public void insert(Merchant merchant) &#123; merchantMap.put(merchant.getId(),merchant); &#125; public Merchant select(String id) &#123; return merchantMap.get(id); &#125;&#125; 12345678910111213141516171819/** * 商家 * Created by childe on 2017/5/14. */public class Merchant &#123; private String id; public Merchant(String id) &#123; this.id = id; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 表路由 * Created by childe on 2017/5/14. */public class TableRoute &#123; private static final int TABLE_SIZE_MAX = 512; private Table[] tables = new Table[TABLE_SIZE_MAX]; private int size = 0; public void insert(Merchant merchant) &#123; //以merchant的ID为key，其不能为空 if (merchant == null &amp;&amp; StringUtils.isEmpty(merchant.getId())) &#123; return; &#125; int index = merchant.getId().hashCode() % size; Table table = tables[index]; table.insert(merchant); &#125; public Merchant select(String id) &#123; if (StringUtils.isEmpty(id)) &#123; return null; &#125; int index = id.hashCode() % size; Table table = tables[index]; return table.select(id); &#125; public void addTable(Table table) &#123; if (table == null) &#123; return; &#125; tables[size++] = table; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Created by childe on 2017/5/14. */public class Main &#123; static int tableNum = 3; static int merchantNum = 100; public static void main(String[] args) &#123; //初始化表 TableRoute tableRoute = creatTableRoute(tableNum); //插入数据 for (int i = 0; i &lt; merchantNum; i++) &#123; Merchant merchant = new Merchant(String.valueOf(i)); tableRoute.insert(merchant); &#125; //有效数据统计 validCount(tableRoute); //增加一个表 tableRoute.addTable(new Table("merchant_100")); System.out.println("after add a table"); //有效数据统计 validCount(tableRoute); &#125; private static void validCount(TableRoute tableRoute) &#123; int validNum = 0; //获取数据 for (int i = 0; i &lt; merchantNum; i++) &#123; Merchant merchant = tableRoute.select(String.valueOf(i)); if (merchant != null) &#123; validNum++; &#125; &#125; System.out.println("vaild merchant : " + validNum + ", total merchant : " + merchantNum); &#125; public static TableRoute creatTableRoute(int tableNum) &#123; TableRoute tableRoute = new TableRoute(); for (int i = 0; i &lt; tableNum; i++) &#123; tableRoute.addTable(new Table("merchant_" + String.valueOf(i))); &#125; return tableRoute; &#125;&#125; 在上述代码中我们我们模拟了分表插入和查找的过程，最终输出如下：123vaild merchant : 100, total merchant : 100after add a tablevaild merchant : 24, total merchant : 100 在Main中两次统计了表中有效的数据个数，两次差别还是比较大的，为什么新加入一个表会导致这么多数据实效呢？很简单，因为我们是以分表的个数取模的，当表的数量增加后，当然会造成数据失效。还以开篇的分表为例，如果商家的数据再次很快的增长，那么商家的用户数据当然会更多（商家:用户=1:n），当某个分表记录再次到达千万级别，此时就又面临分表的可能，那么此时就面临数据迁移的问题，否则就会出现我们模拟的状况，从实验上来看，失效的比例还是很高的，迁移就会比较头疼。当然，牵扯到实际问题需要我们对业务的增长有个大概的预测，来计算初次分表的数量。但是大量数据的迁移还是难以避免。 一致性哈希上面我们看到一旦表的数量增加数据失效比例很高，就需要面临大量的数据迁移，这是难以忍受的。 在应用中还有其他一些类似的场景，比如：缓存（假设我们缓存按照上述方式存放）。本来是为了减轻后方服务的压力，如果缓存的机器挂掉了一台或者我们需要新增加一台，那么，后端服务将面临大量缓存失效而带来的压力，甚至造成雪崩。 一致性哈希很好的解决了这个问题，什么是一致性哈希呢？一致性哈希将整个哈希值空间组织成一个虚拟的圆环，所有待落到该环上的节点（包括存储节点）均需要按照同一套Hash算法得出落点位置。节点落入到闭环后，按照顺时针的方向存储到离自己最近的一个存储节点。因为存储节点可能比较少，可能会导致存储节点存储数据不均衡，所以需要引入虚拟存储节点。比如：有A、B两台机器提供存储，我们一般使用机器的IP来计算机器的Hash，如果A、B两台机器的hash值比较靠近，数据存储就会出现倾斜，要尽可能保证数据的均匀分布，我们可以再做一层映射，在闭环上放置4个（A#0、A#1、B#0、B#1）或者更多存储节点（使得数据分布约趋于均匀）。 我们简单模拟下一致性哈希的实现：1234567891011121314151617181920212223242526/** * 模拟缓存机器 * Created by childe on 2017/5/14. */public class Server &#123; private String name; private Map&lt;String, Entry&gt; entries; Server(String name) &#123; this.name = name; entries = new HashMap&lt;&gt;(); &#125; public void put(Entry e) &#123; entries.put(e.getKey(), e); &#125; public Entry get(String key) &#123; return entries.get(key); &#125; public int hashCode() &#123; return name.hashCode(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 缓存集群 * Created by childe on 2017/5/14. */public class Cluster &#123; private static final int SERVER_SIZE_MAX = 1024; private SortedMap&lt;Integer, Server&gt; servers = new TreeMap&lt;&gt;(); private int size = 0; public void put(Entry e) &#123; routeServer(e.getKey().hashCode()).put(e); &#125; public Entry get(String key) &#123; return routeServer(key.hashCode()).get(key); &#125; private Server routeServer(int hash) &#123; if (servers.isEmpty())&#123; return null; &#125; /** * 顺时针找到离该hash最近的slot（server） */ if (!servers.containsKey(hash)) &#123; SortedMap&lt;Integer, Server&gt; tailMap = servers.tailMap(hash); hash = tailMap.isEmpty() ? servers.firstKey() : tailMap.firstKey(); &#125; return servers.get(hash); &#125; public boolean addServer(Server s) &#123; if (size &gt;= SERVER_SIZE_MAX) &#123; return false; &#125; servers.put(s.hashCode(), s); size++; return true; &#125;&#125; 12345678910111213141516171819/** * 缓存实体 * Created by childe on 2017/5/14. */public class Entry &#123; private String key; Entry(String key) &#123; this.key = key; &#125; public String getKey() &#123; return key; &#125; public void setKey(String key) &#123; this.key = key; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Created by childe on 2017/5/5. */public class Main &#123; static int entryNum = 100; public static void main(String[] args) &#123; //创建缓存集群 Cluster cluster = createCluster(); //写入缓存实体 for (int i = 0; i &lt; entryNum; i++) &#123; cluster.put(new Entry(String.valueOf(i))); &#125; //有效数据统计 validCount(cluster); //新增缓存节点 cluster.addServer(new Server("C")); System.out.println("afer add a server"); //有效数据统计 validCount(cluster); &#125; private static Cluster createCluster() &#123; Cluster c = new Cluster(); c.addServer(new Server("A#1")); c.addServer(new Server("A#2")); c.addServer(new Server("B#1")); c.addServer(new Server("B#2")); return c; &#125; private static void validCount(Cluster cluster) &#123; int validNum = 0; for (int i = 0; i &lt; entryNum; i++) &#123; Entry entry = cluster.get(String.valueOf(i)); if (entry != null) &#123; validNum++; &#125; &#125; System.out.println("valid entry : " + validNum + ", total entry : " + entryNum); &#125;&#125; 1234//输出如下valid entry : 100, total entry : 100afer add a servervalid entry : 90, total entry : 100 从输出结果我们看到失效率明显降低。据了解，Memcahce中便采用了一致性哈希的算法。 HashMapJDK中我们常用的HashMap也是基于哈希实现，JDK1.8以前采用数组和链表来组织数据，1.8中引入了红黑树对链表部分进行了优化。为什么HashMap要采用链表和红黑树呢？因为我们得到某个key的HashCode需要落到具体的桶中，而桶的数量是有限并且固定的，所以难免遇到不同的key却落到相同的桶中，于是就需要链表将这些数据链接起来，这也就是为什么当碰撞比较严重时，HashMap查询变慢的原因，在JDK1.8在处理冲突时采用链表加红黑树，当链表长度大于8时，就将链表转换为红黑树，从而达到加速查找的目的。 JDK1.8中还对HashMap的扩容做了优化，在1.8以前扩容时，需要重新计算每个key的HashCode然后入桶，所以扩容是一个耗时的操作，在1.8中避免了重新计算Hash，加快了扩容操作。 不管是JDK1.7还是1.8我们使用HashMap时最好对需要的容量进行评估，尽量避免扩容操作。JDK1.8对HashMap的优化，想深入了解的可参考美团点评团队的这篇博客 参考：http://wiki.mbalib.com/wiki/%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95http://www.berlinix.com/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK源码 Java Reference]]></title>
      <url>%2F2017%2F04%2F24%2FJDK%E6%BA%90%E7%A0%81-java%E7%9A%84%E5%9B%9B%E7%A7%8DReference%2F</url>
      <content type="text"><![CDATA[之前探讨过一次JAVA的FinalReference，这次我们来看下java.lang.ref包下对应的其他三种引用。 走近引用Reference和ReferenceQueue在使用中一定是结伴出现的，当一个Reference确定要被GC回收，GC便会把Reference加入到与之关联的ReferenceQueue中。注意：在Reference的构造方法中，我们可以传入一个注册队列ReferenceQueue，这个队列我们稍后会具体看，需要主要的是，这个队列需要单独的线程去做消费，否则会存在OOM的隐患。 这些引用可用来实现不同的缓存类型（内存敏感和内存不敏感），大名鼎鼎的Guava cache就是基于引用的这些特性来实现高速本地缓存。 StrongReference（强引用）我们平时开发中new一个对象出来，这种引用便是强引用。 JVM 系统采用 Finalizer 来管理每个强引用对象 , 并将其被标记要清理时加入 ReferenceQueue, 并逐一调用该对象的 finalize() 方法。具体详见我的前一篇博客：JDK源码 FinalReference SoftReference（软引用）当内存足够的时候，软引用所指向的对象没有其他强引用指向的话，GC的时候并不会被回收，当且只当内存不够时才会被GC回收（调用finalize方法）。强度仅次于强引用。GC回收前，会将那些已经向引用队列注册的新清除的软引用加入队列。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class ClassSoft &#123; public static class Referred &#123; /** * 不是必须实现，和Strong不同。 * 实现该方法是为了追踪GC， * 实现后也会被当作Finalizer * @throws Throwable */ @Override protected void finalize() throws Throwable &#123; System.out.println("Referred对象被垃圾收集"); &#125; @Override public String toString() &#123; return "I am Referred"; &#125; &#125; public static void collect() throws InterruptedException &#123; System.gc(); Thread.sleep(2000); &#125; static class CheckRefQueueThread extends Thread&#123; @Override public void run() &#123; Reference&lt;Referred&gt; obj = null; try &#123; obj = (Reference&lt;Referred&gt;)softQueue.remove(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if(obj != null) &#123; try &#123; Field referent = Reference.class.getDeclaredField("referent"); referent.setAccessible(true); Object result = referent.get(obj); //此处异常可以说明，在被放入队列之前referent已经被JVM置为null System.out.println("gc will collect: " + result.getClass() + "@" + result.hashCode()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println("Object for SoftReference is " + obj.get()); &#125; &#125; &#125; //如果我们使用了自定义的注册队列，一定要启动一个线程来处理该队列 //JVM只负责像队列中放入对象，不负责清理 static ReferenceQueue&lt;Referred&gt; softQueue = new ReferenceQueue&lt;&gt;(); /** * JVM配置 * -Xms4m -Xmx4m * -XX:+PrintGCDetails -Xloggc:/Users/childe/logs/gc-f.log * 务必加上该参数，以确定collect方法后GC被执行 * @param args * @throws InterruptedException */ public static void main(String[] args) throws InterruptedException &#123; System.out.println("创建软引用"); Referred strong = new Referred(); SoftReference&lt;Referred&gt; soft = new SoftReference&lt;&gt;(strong,softQueue); new CheckRefQueueThread().start(); ClassSoft.collect(); System.out.println("切断强引用"); strong = null; ClassSoft.collect(); System.out.println("GC之前，软引用值：" + soft.get().toString()); System.out.println("开始堆占用"); try &#123; List&lt;byte[]&gt; bytes = new ArrayList&lt;&gt;(); while (true) &#123; bytes.add(new byte[1024*1024]); ClassSoft.collect(); &#125; &#125; catch (OutOfMemoryError e) &#123; // 软引用对象应该在这个之前被收集 System.out.println("内存溢出..."); &#125; System.out.println("Done"); &#125;&#125; 程序输出如下：12345678910创建软引用切断强引用GC之前，软引用值：I am Referred开始堆占用java.lang.NullPointerExceptionReferred对象被垃圾收集 at com.cxd.jvm.references.ref.ClassSoft$CheckRefQueueThread.run(ClassSoft.java:54)Object for SoftReference is null内存溢出...Done 我们可以看到，软引用在GC回收前，调用get方法是可以返回其关联的实际对象的，当其被GC加入ReferenceQueue前，JVM会将其关联的对象置为null。 WeakReference（弱引用）弱引用指向的对象没有任何强引用指向的话，GC的时候会进行回收。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * * Created by childe on 2017/3/31. */public class ClassWeak &#123; public static class Referred &#123; /** * 不是必须实现，和Strong不同。 * 实现该方法是为了追踪GC * 实现后也会被当作Finalizer * @throws Throwable */ @Override protected void finalize() throws Throwable &#123; System.out.println("Referred对象被垃圾收集"); &#125; @Override public String toString() &#123; return "I am weak"; &#125; &#125; public static void collect() throws InterruptedException &#123; System.gc(); Thread.sleep(2000); &#125; /** * JVM配置 * -XX:+PrintGCDetails -Xloggc:/Users/childe/logs/gc-f.log * 务必加上该参数，以确定collect方法后GC被执行 * @param args * @throws InterruptedException */ public static void main(String[] args) throws InterruptedException &#123; System.out.println("创建一个弱引用"); Referred strong = new Referred(); WeakReference&lt;Referred&gt; weak = new WeakReference&lt;&gt;(strong); ClassWeak.collect(); System.out.println("切断强引用"); strong = null; System.out.println("GC之前，弱引用值：" + weak.get().toString()); ClassWeak.collect(); System.out.println("Done"); &#125;&#125; 程序输出如下：12345创建一个弱引用切断强引用GC之前，弱引用值：I am weakReferred对象被垃圾收集Done PhantomReference（虚引用）如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。这个特性，决定了他的get方法每次调用均会返回null。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * Created by childe on 2017/3/31. */public class ClassPhantom &#123; public static class Referred &#123; @Override protected void finalize() throws Throwable &#123; System.out.println("Referred对象被垃圾收集"); &#125; @Override public String toString() &#123; return "Referredqq"; &#125; &#125; public static void collect() throws InterruptedException &#123; System.gc(); Thread.sleep(2000); &#125; static class CheckRefQueueThread extends Thread&#123; @Override public void run() &#123; Reference&lt;Referred&gt; obj = null; try &#123; obj = (Reference&lt;Referred&gt;) phantomQueue.remove(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if(obj != null) &#123; //因为虚引用的指示对象总是不可到达的，所以此方法总是返回 null System.out.println("Object for phantomReference is " + obj.get()); try &#123; Field referent = Reference.class.getDeclaredField("referent"); referent.setAccessible(true); Object result = referent.get(obj); System.out.println("gc will collect: " + result.getClass() + "@" + result.toString()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;; &#125; static ReferenceQueue&lt;Referred&gt; phantomQueue = new ReferenceQueue&lt;&gt;(); /** * -Xms4m -Xmx4m * @param args * @throws InterruptedException */ public static void main(String[] args) throws InterruptedException &#123; System.out.println("创建一个软引用"); Referred strong = new Referred(); PhantomReference&lt;Referred&gt; soft = new PhantomReference&lt;&gt;(strong, phantomQueue); new CheckRefQueueThread().start(); collect(); System.out.println("切断强引用"); strong = null; collect(); System.out.println("开始堆占用"); try &#123; List&lt;byte[]&gt; bytes = new ArrayList&lt;&gt;(); while (true) &#123; bytes.add(new byte[1024*1024]); collect(); &#125; &#125; catch (OutOfMemoryError e) &#123; // 软引用对象应该在这个之前被收集 System.out.println("内存溢出..."); &#125; System.out.println("Done"); &#125;&#125; 输出如下：12345678创建一个软引用切断强引用Referred对象被垃圾收集开始堆占用Object for phantomReference is nullgc will collect: class com.cxd.jvm.references.ref.ClassPhantom$Referred@Referredqq内存溢出...Done 引用间的差别我们注意到虚引用在被加入到ReferenceQueue中后，关联对象并没有被置为null，这点和弱引用及软引用不同。这也是我开头说的潜在OOM的最大风险。当然，这种现象只是加速了OOM问题的暴露，并不是根本原因。JVM GC的这个模型可以看作是生产-消费模型，GC是生产者，我们自己起的线程是消费者（Finalizer中JDK自带线程），当只有生产者时，OOM是迟早的事情。 ReferenceQueue我们介绍的这四种引用都从java.lang.ref.Reference继承，Reference是个单向链表，ReferenceQueue利用Reference的这个特性来维护先进后出单向队列（类似栈）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public abstract class Reference&lt;T&gt; &#123; //...... //引用有4中概念上的状态：Active、Pending、 Enqueued 、Inactive //引用的初始态为Active或者Pending，它的生命后期为：（Active || Pending）-&gt; Enqueued -&gt; Inactive private T referent; /* Treated specially by GC 由GC专门处理*/ ReferenceQueue&lt;? super T&gt; queue; /* Reference 关联的引用队列 */ Reference next; /* 指向下一个引用 */ //......&#125;public class ReferenceQueue&lt;T&gt; &#123; //...... //如果我们构造Reference时，未传入自定义队列，默认使用此队列。 private static class Null extends ReferenceQueue &#123; //入队操作直接返回 boolean enqueue(Reference r) &#123; return false; &#125; &#125; static ReferenceQueue NULL = new Null(); static ReferenceQueue ENQUEUED = new Null(); boolean enqueue(Reference&lt;? extends T&gt; r) &#123; /* Called only by Reference class 只会对Reference类调用该方法 */ synchronized (r) &#123; //以入队的引用不多次入队 if (r.queue == ENQUEUED) return false; synchronized (lock) &#123; //修改引用入队状态为Enqueued r.queue = ENQUEUED; //插入对头 r.next = (head == null) ? r : head; head = r; queueLength++; if (r instanceof FinalReference) &#123; sun.misc.VM.addFinalRefCount(1); &#125; //通知等待在锁上的线程ReferenceQueue.remove() lock.notifyAll(); return true; &#125; &#125; &#125; private Reference&lt;? extends T&gt; reallyPoll() &#123; /* Must hold lock 必须在持有lock锁的情况下执行，lock由其外层方法获取 */ if (head != null) &#123; //获取队头 Reference&lt;? extends T&gt; r = head; head = (r.next == r) ? null : r.next; //将关联的队列置为NULL，此时r的状态为Inactive，处于此状态的引用不会再发生变化，等待被回收。 r.queue = NULL; r.next = r; queueLength--; if (r instanceof FinalReference) &#123; sun.misc.VM.addFinalRefCount(-1); &#125; return r; &#125; return null; &#125; //......&#125; 扩展WeakHashMapJDK中有对引用的具体使用，当我们需要实现一个简单的本地内存敏感缓存时，可以考虑使用WeakHashMap，此处不再分析其源码。WeakHashMap的每个Entry都是WeakReference的子类，每次put或者get或者resize扩容时，都会调用WeakHashMap的expungeStaleEntries方法，清除那些被GC加入到ReferenceQueue的Entry。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK源码 FinalReference]]></title>
      <url>%2F2017%2F04%2F01%2FJDK%E6%BA%90%E7%A0%81-FinalReference%2F</url>
      <content type="text"><![CDATA[JAVA FinalReference引入使用MAT分析dump出的内存时，常会看到java.lang.ref.Finalizer占用内存也不小，比较纳闷我们在编程中并没有用到这个东西，为什么他会出现并且占用分量不算小的一部分内存呢？1234final class Finalizer extends FinalReference &#123; private static ReferenceQueue queue = new ReferenceQueue(); //... ...&#125; 结合它的数据结构基本可以看出来，Finalizer中持有一个一个引用队列。猜测是这个队列吃掉了那些内存。 引用类型Java开发不必关心内存的释放、申请和垃圾回收，这些事情都有JVM代劳，但是JVM依然提供了一些方式，让我们能够在应用的层次利用内存或者GC特性，从而更好的使用内存。Reference(引用)就是其中一种。 StrongReference（强引用）我们平时开发中new一个对象出来，这种引用便是强引用。 JVM 系统采用 Finalizer 来管理每个强引用对象 , 并将其被标记要清理时加入 ReferenceQueue, 并逐一调用该对象的 finalize() 方法。 SoftReference（软引用）当内存足够的时候，软引用所指向的对象没有其他强引用指向的话，GC的时候并不会被回收，当且只当内存不够时才会被GC回收（调用finalize方法）。强度仅次于强引用。 WeakReference（弱引用）弱引用指向的对象没有任何强引用指向的话，GC的时候会进行回收。 PhantomReference（虚引用）如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 TODO引用详细介绍单独在另一篇作介绍 java.lang.ref包简介 ref包下对应了Java中对应几种引用类型，改包下的类的可见性均为包内可见。FinalReference可以看作是强引用的一个对应。 FinalReferenceFinalReference由JVM来实例化，VM会对那些实现了Object中finalize()方法的类实例化一个对应的FinalReference。注意：实现的finalize方法体必须非空。 FinalizerFinalizer是FinalReference的子类，该类被final修饰，不可再被继承，JVM实际操作的是Finalizer。当一个类满足实例化FinalReference的条件时，JVM会调用Finalizer.register()进行注册。(PS：后续讲的Finalizer其实也是在说FinalReference。) 何时注册（实例化FinalReference）JVM在类加载的时候会遍历当前类的所有方法，包括父类的方法，只要有一个参数为空且返回void的非空finalize方法就认为这个类在创建对象的时候需要进行注册。 对象的创建其实是被拆分成多个步骤，注册的时机可以在为对象分配好内存空间后，也可以在构造函数返回之前，这个点由-XX:-RegisterFinalizersAtInit控制，这个参数默认为true，即：在构造函数返回之前调用。注册入口是Finalizer的register()方法。 12345678910111213141516171819202122232425262728293031323334353637final class Finalizer extends FinalReference &#123; private static ReferenceQueue queue = new ReferenceQueue(); private static Finalizer unfinalized = null; private static final Object lock = new Object(); private Finalizer next = null, prev = null; //构造一个对象链表，如图 /** * +------+ prev +-----+ +-----+ *unfinalized | f3 | &lt;----&gt; | f2 | &lt;----&gt; | f1 | * +------+ next +-----+ +-----+ **/ private void add() &#123; synchronized (lock) &#123; if (unfinalized != null) &#123; this.next = unfinalized; unfinalized.prev = this; &#125; unfinalized = this; &#125; &#125; private Finalizer(Object finalizee) &#123; super(finalizee, queue); add(); &#125; /* Invoked by VM 入口在这里 */ static void register(Object finalizee) &#123; new Finalizer(finalizee); &#125; //... &#125; 何时进入ReferenceQueueGC工作时，如果发现对象只被Finalizer类引用，说明他可以被回收了，那么就把该对象从对象链中取出，放入ReferenceQueue，并通知FinalizerThread去消费。也就是说，本次GC并不能回收掉这个对象占用的内存。 ReferenceQueue是个典型的生产消费队列，此处不在赘述，可看其源码，实现很简单。 FinalizerThread线程在Finalizer类的clinit方法（静态块）里，会创建一个FinalizerThread守护线程，这个线程的优先级不是最高的，这就意味着在CPU很紧张的情况下其被调度的优先级可能会受到影响。 FinalizerThread业务很简单，从ReferenceQueue拿出Finalizer，执行finalize方法，并且忽略其抛出的所有异常。执行完毕后，该对象称为真正的垃圾对象，再次发生GC，他的一生也就结束了。 12345678910111213141516171819202122232425262728293031private static class FinalizerThread extends Thread &#123; private volatile boolean running; FinalizerThread(ThreadGroup g) &#123; super(g, "Finalizer"); &#125; public void run() &#123; if (running) return; //... running = true; for (;;) &#123; try &#123; Finalizer f = (Finalizer)queue.remove(); f.runFinalizer(jla); &#125; catch (InterruptedException x) &#123; // ignore and continue &#125; &#125; &#125; &#125; static &#123; ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); Thread finalizer = new FinalizerThread(tg); finalizer.setPriority(Thread.MAX_PRIORITY - 2); finalizer.setDaemon(true); finalizer.start(); &#125; GC回收问题 对象因为Finalizer的引用而变成了一个临时的强引用，即使没有其他的强引用，还是无法立即被回收； 对象至少经历两次GC才能被回收，因为只有在FinalizerThread执行完了f对象的finalize方法的情况下才有可能被下次GC回收，而有可能期间已经经历过多次GC了，但是一直还没执行对象的finalize方法； CPU资源比较稀缺的情况下FinalizerThread线程有可能因为优先级比较低而延迟执行对象的finalize方法； 因为对象的finalize方法迟迟没有执行，有可能会导致大部分f对象进入到old分代，此时容易引发old分代的GC，甚至Full GC，GC暂停时间明显变长，甚至导致OOM； 对象的finalize方法被调用后，这个对象其实还并没有被回收，虽然可能在不久的将来会被回收。 举个例子12345678910111213141516171819202122232425262728/** * -Xms4m -Xmx4m -XX:+PrintGCDetails -Xloggc:/Users/childe/logs/gc-f.log * -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/Users/childe/logs/oom-f.hprof * Created by childe on 2017/3/31. */public class Finalizable &#123; static AtomicInteger aliveCount = new AtomicInteger(0); Finalizable() &#123; //如果注释掉改行，在GC日志中仅能看到简单的新生代GC，程序不会因为内存问题停止 //如果未注释，程序跑上几分钟就挂掉了，因为生产和消费的能力不对等。GC日志中大部分是Full GC。 aliveCount.incrementAndGet(); &#125; @Override protected void finalize() throws Throwable &#123; Finalizable.aliveCount.decrementAndGet(); &#125; public static void main(String args[]) &#123; for (int i = 0;; i++) &#123; Finalizable f = new Finalizable(); if ((i % 100_000) == 0) &#123; System.out.format("After creating %d objects, %d are still alive.%n", new Object[] &#123;i, Finalizable.aliveCount.get() &#125;); &#125; &#125; &#125;&#125; finalizer的生存周期转自http://blog.2baxb.me/archives/974 在创建对象时，如果对象override了finalize()方法，jvm会同时创建一个Finalizer对象 所有Finalizer对象组成了一个双向链表 所有Finalizer对象都有一个名为queue的成员变量，指向的都是Finalizer类的静态Queue。 cms gc执行到mark阶段的最后时，会把需要gc的对象加入到Reference的pending list中。 有一个专门的高级别线程Reference Handler处理pending list，把pending list中的对象取出来，放到这个对象所指的Reference Queue中，对于Finalizer对象来说，这个queue指向Finalizer类的静态Queue。 Finalizer类有一个专门的线程负责从queue中取对象，并且执行finalizer引用的对象的finalize函数。 Java引用类型可参见http://benjaminwhx.com/2016/09/10/%E8%AF%A6%E8%A7%A3java-lang-ref%E5%8C%85%E4%B8%AD%E7%9A%844%E7%A7%8D%E5%BC%95%E7%94%A8/https://www.ibm.com/developerworks/cn/java/j-lo-langref/http://www.importnew.com/20468.htmlhttp://www.infoq.com/cn/articles/cf-java-garbage-references]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MAT(Memory Analyzer Tool)基本使用]]></title>
      <url>%2F2017%2F03%2F24%2FMAT-Memory-Analyzer-Tool-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[MAT Memory Analyzer Tool 基本使用简介分析和理解我们应用中内存的分布是一件极具挑战的事情。一个逻辑错误就有可能导致OutOfMemory。dump内存的方式很单：jmap -dump:format=b,file=path pid注意操作时要有正确的用户权限。本篇旨在介绍分析中涉及到的一些概念和操作方法，实际案例分析放在下篇介绍。 内存泄漏指由于疏忽或错误造成程序未能释放已经不再使用的内存。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，导致在释放该段内存之前就失去了对该段内存的控制，从而造成了内存的浪费。 Histogram 当我们用MAT工具(用的eclipse插件)打开dump文件，MAT首先给我们一个应用占用内存的预览。 中间的饼图像我们直观展示了retained size最大的对象。这意味着如果可以处理好com.cxd.jvm.mat.Controller$1 @ 0x7ffa741c8 allocator1 这个对象，我们可以腾出6.6M的内存，它占用了应用总内存的90%以上。进一步查看这个对象的一些信息我们可以使用Histogram。 这个Histogram被实例化类的名字，数量，占用的内存，默认按照内存占用降序。像char[]，String，Object[]这些看不出来有什么问题，为了更好的组织Histogram，我们可以按照包或者classLoader分组查看。 直方图还可以使用正则表达式过滤，例如我们只关心自己包下的类：.*com.cxd.jvm.* 过滤后，清楚的看到有超过15W的Listener实例存活在应用中。同时我们看到了每个对象对内存的使用情况。有两个维度的计算，Shallow Heap 和 Retained Heap。Shallow Heap是一个对象持有引用占用的内存，并不包含其引用对象所占用的内存，可以理解成对象本身的大小，Shallow Heap对实际分析没有多大用处。常规对象（非数组）的Shallow Size由其成员变量的数量和类型决定。数组的Shallow Size由数组元素的类型（对象类型、基本类型）和数组长度决定。 1234567//"Shallow size" of this obj == 24 Bytespublic final class String &#123;//8 Bytes header private char value[]; //4 Bytes private int offset; //4 Bytes private int count; //4 Bytes private int hash = 0; //4 Bytes&#125; Retained HeapRetained Heap是一个对象被GC回收时，能够释放其所有引用的Shallow Heap的总和。比如：一个ArrayList持有100,000个元素并且所有元素仅被这个ArrayList持有，每个元素16bytes，那么当该ArrayList被GC后将会释放16 x 100,000 + X，X是ArrayList的Shallow Heap。Retained Heap是Retained Set中所有对象大小的总和，一个对象的Retained Set是当该对象被GC后所要释放对象的集合。 Retained Heap有两种计算方式，一种是quick approximation（快速近似），一种是precise retained size（精确计算）。 通过精确计算可以看到各个Allocator占用了太多的内存，虽然它的Shallow Heap只有64bytes。那么我们只要管控好Controller，内存也就得到了控制。 Dominator TreeDominator Tree由对象的引用图转换而来，它可以让我们清楚的看出大块内存消耗和对象间的依赖保活关系。在对象图中，如果从某个节点（或者根节点）开始到达Y的路径都要经过X，那么X Dominator Y。另外，如果X是路径最短的Dominator，那么X Immediate Dominator Y。 通过Dominator来分析我们的项目。 我们可以明确的看到Allocator便是罪魁祸首，它下面的ArrayList持有大量Listener。 The objects belonging to the sub-tree of x (i.e. the objects dominated by x ) represent the retained set of x .If x is the immediate dominator of y , then the immediate dominator of x also dominates y , and so on.The edges in the dominator tree do not directly correspond to object references from the object graph.注意： 一个对象是X的子树（即：X Dominator 这个对象），那么，这个对象在X的retained set中； 如果X（Allocator） immediate dominator Y（Listener），那么，X的dominator（Controller）也dominator Y。换句话说，dominator具有向上传递性。 The edges in the dominator tree do not directly correspond to object references from the object graph.（dominator tree中的边不直接对应于对象图中的对象引用） Path to GC RootsDominator Tree对我们分析有帮助，但是它是向上找的一个过程，我们并不能知道Dominator的Dominator。Path to GC Roots这时候对我们会很有帮助。实操中需要结合使用。我们看下例子中Listener的GC Root： 通常在排查内存泄漏的时候，我们会选择exclude all phantom/weak/soft etc.references，意思是：查看排除虚引用/弱引用/软引用等的引用链。因为这些引用的对象可以直接被GC给回收，我们要看的就是某个对象否还存在Strong引用链（在导出HeapDump之前要手动出发GC来保证），如果有，则说明可能存在内存泄漏，然后再去排查具体引用。 查看的时候要和左边框中的一些信息结合起来，他提供了更加详细的介绍。 GC Root 定义如下（官网摘录）：A garbage collection root is an object that is accessible from outside the heap. The following reasons make an object a GC root: System ClassClass loaded by bootstrap/system class loader. For example, everything from the rt.jar like java.util.* . JNI LocalLocal variable in native code, such as user defined JNI code or JVM internal code. JNI GlobalGlobal variable in native code, such as user defined JNI code or JVM internal code. Thread BlockObject referred to from a currently active thread block. ThreadA started, but not stopped, thread. Busy MonitorEverything that has called wait() or notify() or that is synchronized. For example, by calling synchronized(Object) or by entering a synchronized method. Static method means class, non-static method means object. Java LocalLocal variable. For example, input parameters or locally created objects of methods that are still in the stack of a thread. Native StackIn or out parameters in native code, such as user defined JNI code or JVM internal code. This is often the case as many methods have native parts and the objects handled as method parameters become GC roots. For example, parameters used for file/network I/O methods or reflection. FinalizableAn object which is in a queue awaiting its finalizer to be run. UnfinalizedAn object which has a finalize method, but has not been finalized and is not yet on the finalizer queue. UnreachableAn object which is unreachable from any other root, but has been marked as a root by MAT to retain objects which otherwise would not be included in the analysis. Java Stack FrameA Java stack frame, holding local variables. Only generated when the dump is parsed with the preference set to treat Java stack frames as objects. UnknownAn object of unknown root type. Some dumps, such as IBM Portable Heap Dump files, do not have root information. For these dumps the MAT parser marks objects which are have no inbound references or are unreachable from any other root as roots of this type. This ensures that MAT retains all the objects in the dump. List ObjectList objects with （以Dominator Tree的方式查看）incoming references 引用到该对象的对象outcoming references 被该对象引用的对象 Show objects by class （以class的方式查看）incoming references 引用到该对象的对象outcoming references 被该对象引用的对象 Common Memory Anti-PatternsMAT使用Anti-Patterns给我们提供报告。这些报告对我们排查内存泄漏、优化low hanging fruit非常有帮助。 Heap Dump Overview给我们提供了系统属性、内存消耗排行等信息 Leak Suspects分析出可能存在的内存泄漏，供我们参考，通常这个功能可以帮我们直接找到问题所在 Java Collections我们可以通过Java Collections查看Map Collision Ratio(Map碰撞比率=碰撞的实体/Hash表中所有实体)、Collection Fill Ratio(集合填充率=size/capacity)、Array Fill Ratio(集合填充率)。但这种方式只能查看那些具有预分配内存能力的集合。 填充率可以作为优化的一个参考，ArrayList填充率低说明我们当初对List的初始化大小预估有误，或者HashMap的冲突较大就说明我们的Key选的有问题或者hash算法需要改进等。我们还可以通过Java Collections-&gt;Hash Entries查看key value。 Threads and Stacksdump出的文件包含了JVM运行时的所有信息，当然MAT也就可以帮我们分析出其中的线程和栈信息。 Exporting your results在我们分析完成之后，可以将我们的分析导出，分享给大家。导出有三种格式：html、cvs、txt。注意：导出的内容是你当前打开的分析窗口，如果你当前MAT没有任何分析窗口，导出的文件便为空。比如：下图中，我导出的内容就只有线程概览。 Object Query LanguageTODO 单独一篇来讲 参考整理自http://eclipsesource.com/blogs/2013/01/21/10-tips-for-using-the-eclipse-memory-analyzer/ MAT官方文档]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo源码 SPI实现之ExtensionLoader]]></title>
      <url>%2F2017%2F03%2F07%2FDubbo%E6%BA%90%E7%A0%81-SPI%E5%AE%9E%E7%8E%B0%E4%B9%8BExtensionLoader%2F</url>
      <content type="text"><![CDATA[Dubbo SPISPI 全称为 (Service Provider Interface) ，JDK也默认提供了SPI的一种实现，不过对比Dubbo的实现，JDK的实现就非常简单。 简单说下JDK默认的SPI用法。 定义Service接口 增加Service实现类 META-INF/services目录下建立以接口包全名命名的文件，文件中写入实现类的包名+类名 用Java提供的ServiceLoader来加载实现 看下如何使用ServiceLoader进行加载 123456789101112131415/*** com.cxd.spi.SayHello文件内容如下：* com.cxd.spi.impl.TomSayHello* com.cxd.spi.impl.JerrySayHello**/public class SPIMain &#123; public static void main(String[] args) &#123; ServiceLoader&lt;SayHello&gt; sayHellos = ServiceLoader.load(SayHello.class); Iterator&lt;SayHello&gt; sayHelloIterator = sayHellos.iterator(); while (sayHelloIterator.hasNext()) &#123; SayHello sayHello = sayHelloIterator.next(); sayHello.say(); &#125; &#125;&#125; ServiceLoader的实现也是比较简单，说下过程，不再列出源码。ServiceLoader根据传入的class去约定的目录下找到相应的文件逐行读取，然后用当前线程的ClassLoader加载文件中定义的实现类，通过class.newInstance()创建实例对象。ServiceLoader通过返回迭代器的方式让我们遍历所有的借口实现。 Dubbo整体思路也是如此，但是Dubbo SPI实现的功能就比较强大了。SPI通过定义文件实现，但是文件格式并没有局限，Dubbo中使用key=value的形式来进行定义，这也是dubbo能够灵活支持多种协议以及实现良好扩展性的关键所在。 在Dubbo里面使用ExtensionLoader来加载扩展点（即：接口的具体实现），每类接口Dubbo都有默认的实现，当然我们也可以根据自己的业务需要来定义自己的扩展，而扩展的方式也非常简单，SPI的方式给Dubbo提供了框架极好的扩展性。 下面我们主要来看ExtensionLoader，它是Dubbo对SPI实现的核心，也是Dubbo的核心。 每个定义的SPI的接口都会构建一个ExtensionLoader实例，ExtensionLoader采用工厂模式，以静态方法向外提供ExtensionLoader的实例。实例存储在ExtensionLoader内部静态不可变变量中。 12//ExtensionLoader.javaprivate static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt;(); 外部使用时调用：ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension()；getExtensionLoader方法创建ExtensionLoader实例，getAdaptiveExtension方法会加载扩展点中的实现类，并创建或者选择适配器。 读取SPI注解的value值，如果value不为空则作为缺省的扩展点名 依次读取指定路径下的扩展点META-INF/dubbo/internal/META-INF/dubbo/META-INF/dubbo/services/ getAdaptiveExtension方法最终调用loadFile来完成对SPI文件的读取解析。 loadFile方法逐行读取SPI文件内容并进行解析 实现类上是否含有@Adaptive注解，如果有，则将其作为适配器缓存到cachedAdaptiveClass，并进入下一行配置的解析，一个SPI只能有一个适配器，否则会报错； 如果实现类上没有@Adaptive注解，那么看其是否存在以当前获取接口类型为入参的构造器，如果有，则将其作为包装器(wrapper)存入cachedWrapperClasses变量； 如果实现类既没有@Adaptive注解，也不是包装器，那它就是扩展点的具体实现 判断扩展实现上是否有@Activate注解，如果有，将其缓存到cachedActivates(一个类型为Map的变量)中，然后将其key作为扩展点的名字，放入cachedClasses(一个类型为Holder]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[服务器Load高简单排查]]></title>
      <url>%2F2017%2F02%2F27%2F%E6%9C%8D%E5%8A%A1%E5%99%A8Load%E9%A3%99%E9%AB%98%E6%8E%92%E6%9F%A5%E6%96%B9%E6%B3%95%2F</url>
      <content type="text"><![CDATA[服务器Load飙高排查方法线上碰到CPU利用率高或者Load高的时候，排查的顺序。 拿到进程PID：ps -ef | grep java 或者 jps dump应用栈信息：jstack PID &gt; PID.stack top查看导致高CPU的进程: top 后键入 x 默认按照CPU使用率排序进程，键入c可看到commond 查看导致高CPU利用率的线程信息：top -Hp PID 查看CPU利用率高线程的栈信息，stack文件中线程号为16进制，需要top出来的线程号进行转换：printf ‘%x\n’ ThreadPID 大神有整理出脚本来简化以上操作步骤，可以直接揪出指定进程中CPU使用率较高的java线程，详情移步：查找繁忙的java线程 两个常用命令：dump内存：jmap -dump:format=b,file=/home/admin/PID.bin PID 一般dump出的文件比较大，建议压缩后传输gzip fileName 远程拷贝参考scp 结尾附上查找繁忙的java线程脚本源码，用于快速排查Java的CPU性能问题(top us值过高)，自动查出运行的Java进程中消耗CPU多的线程，并打印出其线程栈，从而确定导致性能问题的方法调用。 12345678910111213show-busy-java-threads.sh# 从 所有的 Java进程中找出最消耗CPU的线程（缺省5个），打印出其线程栈。show-busy-java-threads.sh -c &lt;要显示的线程栈数&gt;show-busy-java-threads.sh -c &lt;要显示的线程栈数&gt; -p &lt;指定的Java Process&gt;############################### 注意：############################### 如果Java进程的用户 与 执行脚本的当前用户 不同，则jstack不了这个Java进程。# 为了能切换到Java进程的用户，需要加sudo来执行，即可以解决：sudo show-busy-java-threads.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147#!/bin/bash# @Function# Find out the highest cpu consumed threads of java, and print the stack of these threads.## @Usage# $ ./show-busy-java-threads.sh## @author Jerry Leereadonly PROG=`basename $0`readonly -a COMMAND_LINE=("$0" "$@")usage() &#123; cat &lt;&lt;EOFUsage: $&#123;PROG&#125; [OPTION]...Find out the highest cpu consumed threads of java, and print the stack of these threads.Example: $&#123;PROG&#125; -c 10Options: -p, --pid find out the highest cpu consumed threads from the specifed java process, default from all java process. -c, --count set the thread count to show, default is 5 -h, --help display this help and exitEOF exit $1&#125;readonly ARGS=`getopt -n "$PROG" -a -o c:p:h -l count:,pid:,help -- "$@"`[ $? -ne 0 ] &amp;&amp; usage 1eval set -- "$&#123;ARGS&#125;"while true; do case "$1" in -c|--count) count="$2" shift 2 ;; -p|--pid) pid="$2" shift 2 ;; -h|--help) usage ;; --) shift break ;; esacdonecount=$&#123;count:-5&#125;redEcho() &#123; [ -c /dev/stdout ] &amp;&amp; &#123; # if stdout is console, turn on color output. echo -ne "\033[1;31m" echo -n "$@" echo -e "\033[0m" &#125; || echo "$@"&#125;yellowEcho() &#123; [ -c /dev/stdout ] &amp;&amp; &#123; # if stdout is console, turn on color output. echo -ne "\033[1;33m" echo -n "$@" echo -e "\033[0m" &#125; || echo "$@"&#125;blueEcho() &#123; [ -c /dev/stdout ] &amp;&amp; &#123; # if stdout is console, turn on color output. echo -ne "\033[1;36m" echo -n "$@" echo -e "\033[0m" &#125; || echo "$@"&#125;# Check the existence of jstack command!if ! which jstack &amp;&gt; /dev/null; then [ -z "$JAVA_HOME" ] &amp;&amp; &#123; redEcho "Error: jstack not found on PATH!" exit 1 &#125; ! [ -f "$JAVA_HOME/bin/jstack" ] &amp;&amp; &#123; redEcho "Error: jstack not found on PATH and $JAVA_HOME/bin/jstack file does NOT exists!" exit 1 &#125; ! [ -x "$JAVA_HOME/bin/jstack" ] &amp;&amp; &#123; redEcho "Error: jstack not found on PATH and $JAVA_HOME/bin/jstack is NOT executalbe!" exit 1 &#125; export PATH="$JAVA_HOME/bin:$PATH"fireadonly uuid=`date +%s`_$&#123;RANDOM&#125;_$$cleanupWhenExit() &#123; rm /tmp/$&#123;uuid&#125;_* &amp;&gt; /dev/null&#125;trap "cleanupWhenExit" EXITprintStackOfThreads() &#123; local line local count=1 while IFS=" " read -a line ; do local pid=$&#123;line[0]&#125; local threadId=$&#123;line[1]&#125; local threadId0x="0x`printf %x $&#123;threadId&#125;`" local user=$&#123;line[2]&#125; local pcpu=$&#123;line[4]&#125; local jstackFile=/tmp/$&#123;uuid&#125;_$&#123;pid&#125; [ ! -f "$&#123;jstackFile&#125;" ] &amp;&amp; &#123; &#123; if [ "$&#123;user&#125;" == "$&#123;USER&#125;" ]; then jstack $&#123;pid&#125; &gt; $&#123;jstackFile&#125; else if [ $UID == 0 ]; then sudo -u $&#123;user&#125; jstack $&#123;pid&#125; &gt; $&#123;jstackFile&#125; else redEcho "[$((count++))] Fail to jstack Busy($&#123;pcpu&#125;%) thread($&#123;threadId&#125;/$&#123;threadId0x&#125;) stack of java process($&#123;pid&#125;) under user($&#123;user&#125;)." redEcho "User of java process($user) is not current user($USER), need sudo to run again:" yellowEcho " sudo $&#123;COMMAND_LINE[@]&#125;" echo continue fi fi &#125; || &#123; redEcho "[$((count++))] Fail to jstack Busy($&#123;pcpu&#125;%) thread($&#123;threadId&#125;/$&#123;threadId0x&#125;) stack of java process($&#123;pid&#125;) under user($&#123;user&#125;)." echo rm $&#123;jstackFile&#125; continue &#125; &#125; blueEcho "[$((count++))] Busy($&#123;pcpu&#125;%) thread($&#123;threadId&#125;/$&#123;threadId0x&#125;) stack of java process($&#123;pid&#125;) under user($&#123;user&#125;):" sed "/nid=$&#123;threadId0x&#125; /,/^$/p" -n $&#123;jstackFile&#125; done&#125;ps -Leo pid,lwp,user,comm,pcpu --no-headers | &#123; [ -z "$&#123;pid&#125;" ] &amp;&amp; awk '$4=="java"&#123;print $0&#125;' || awk -v "pid=$&#123;pid&#125;" '$1==pid,$4=="java"&#123;print $0&#125;'&#125; | sort -k5 -r -n | head --lines "$&#123;count&#125;" | printStackOfThreads]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK源码 AQS]]></title>
      <url>%2F2017%2F02%2F14%2FJDK%E6%BA%90%E7%A0%81-AQS%2F</url>
      <content type="text"><![CDATA[AbstractQueueSynchronizer笔记在开始介绍之前我先来简单理解一下为什么会产生AQS。在我们应用内不可避免的会发生对一些资源的抢占，那么如何处理线程之间对资源的争夺呢？在Java SE 5 之前JDK可以使用synchronized来串行化对资源的操作，synchronized可以隐式的获取和释放锁，但是带来的不便就是不够灵活，可扩展性没有显式获取和释放锁的自主控制性强，另外synchronized是完全互斥的，没法达到诸如共享锁、读写锁的效果。对资源的竞争可以抽象为对变量状态的竞争，这正是AQS实现的基本原理，当然，AQS的实现是复杂的。AQS（AbstractQueueSynchronizer）俗称同步器，是JDK中用来构建同步组件的基础框架，比如JDK中已经实现的可重入锁（ReentrantLock）就是基于AQS实现的，它的关键方法在实现中使用了unsafe的CAS操作来提高性能。AQS采用模版方法的设计模式，屏蔽了同步状态管理、线程排队、等待与唤醒等底层操作，实现者只需要实现AQS定义的抽象方法即可快速实现自己的同步需求。 需要实现的模版接口以下列出的接口方法，并非需要全部实现，按照自己对同步器的要求选择相应的进行实现。以下方法AQS默认抛出UnsupportedOperationException。 1234567891011121314151617181920212223242526/******************独占式同步状态 start****************/protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125;protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125;/******************独占式同步状态 end*****************//******************共享式同步状态 start****************//***返回值大于等于0表示获取成功**/protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125;protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException();&#125;/******************共享式同步状态 end****************//******************获取同步状态模式 start**************/protected boolean isHeldExclusively() &#123; throw new UnsupportedOperationException();&#125;/******************获取同步状态模式 end**************/ 关键属性 属性类型及名称 描述 volatile int state 竞争资源的抽象。代表资源的占用状态。 volatile Node head 同步队列用来保存获取状态失败的线程数据结构，指向队列头部 volatile Node tail 同上，指向队列尾部 结合具体的一个实现（ReentrantLock）来看AQS。ReentrantLock中的公平锁和非公平锁便是AQS独占锁的一种实现，从ReentrantLock默认的非公平锁入手，因为他是ReentrantLock的默认锁。 123456789101112class X &#123; private final ReentrantLock lock = new ReentrantLock(); // ... public void m() &#123; lock.lock(); // block until condition holds try &#123; // ... method body &#125; finally &#123; lock.unlock() &#125; &#125;&#125; 上面是使用ReentrantLock的基本方式，当我们调用lock()方法时，发生了些什么事呢？123456789101112131415161718static final class NonfairSync extends Sync &#123; /** *直接加锁，不理会当前是否有其他线程在排队 *如果失败，则进入自旋状态，在自旋中检查当前线程是否应当挂起 **/ final void lock() &#123; //compareAndSetState/acquire/setExclusiveOwnerThread父类实现模版方法 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; //模版方法（子类实现，根据要实现锁的类性复写对应模版方法） protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; compareAndSetState由AQS提供，采用CAS的方式对state设值，保证操作的原子性。如果设置成功，则将当前线程作为排他线程；如果抢占式获取失败则进入等待队列，即acquire(1)。我们看下acquire的实现。12345678910AbstractQueuedSynchronizerpublic final void acquire(int arg) &#123; /** *1.尝试再次获取锁，成功-&gt;业务代码 *2.失败-&gt;将自己加入等待队列尾部，自旋获取锁，获取成功则返回，否则直到满足挂起条件把自己挂起 **/ if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 前面已经列出tryAcquire是需要子类实现的方法，我们在NonfairSync中看到正是如此，NonfairSync中tryAcquire方法调用了其父类Sync的nonfairTryAcquire。1234567891011121314151617181920212223242526ReentrantLock$Syncfinal boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); //获取当前资源状态，表格“关键属性”中列出的state值 int c = getState(); //如果为0，表明当前时刻没有线程占有竞争资源 if (c == 0) &#123; //尝试再次获取 if (compareAndSetState(0, acquires)) &#123; //获取成功-&gt;设置当前线程为占有线程 setExclusiveOwnerThread(current); return true; &#125; &#125; //如果当前线程为占有线程 //ps：可重入锁的特点 else if (current == getExclusiveOwnerThread()) &#123; //增加重入次数，最大值为Integer.MAX_VALUE int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 如果获取还是失败，就需要将当前线程加入等待队列的尾部，等待队列是一个FIFO双向队列。123456789101112131415161718192021222324252627282930313233343536373839AbstractQueuedSynchronizer /** FIFO同步队列* +------+ prev +-----+ +-----+*head | | &lt;----&gt; | | &lt;----&gt; | | tail* +------+ next +-----+ +-----+**/private Node addWaiter(Node mode) &#123; //默认为addWaiter(Node.EXCLUSIVE)排他模式 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //如果快速入队失败，则进入到完整入队过程 enq(node); return node;&#125;//不断CAS将Node安全追加到队列尾部private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize //注意初始化队列头部Node if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 简单说下Node的数据结构 属性 描述 int waitStatus 等待状态。字段的具体描述见下表（因为MD换行无法设置格式） Node prev 前驱节点 Node next 后继节点 Node nextWaiter Condition等待队列中的后继节点。如果该节点是Condition的，那么该节点表示等待在该Condition的下一个节点；如果不是，那么表示当前队列的默认mode（SHARED/EXCLUSIVE） Thread thread 当前节点包装的线程 waitStatus状态 值 描述 CANCELLED 1 由于在同步队列中等待的线程等待超时活着中断，需要从同步队列中取消等待，节点进入该状态将不会变化 SIGNAL -1 后继节点的线程处于等待状态，当当前节点的线程如果释放了同步状态活着取消，将会通知后继节点，使后继接待你的线程得以运行 CONDITION -2 节点在对应的Condition等待队列中，当其他线程对Condition调用了signal()方法后，该节点将会从等待队列中转移到同步队列中，准备开始对状态的竞争 PROPAGATE -3 表示下一次共享式同步状态获取将会无条件被传播下去（阅读ReentrantReadWriteLock可以看到运用） initial 0 Node非Condition下的初始态 我们看到addWaiter方法在队列最后追加了一个初始态的排他Node，完成此步骤后当前线程并没有直接被挂起，这是AQS和synchronized的不用点也是其高效的体现，我们知道线程的挂起和恢复是需要CPU进行上下文切换，这是一个相对耗时的操作，AQS在一个线程满足挂起条件前会不停的尝试获取锁，避免上下文的切换。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; //死循环获取锁，每次换醒后重新竞争获取锁，避免假唤醒 for (;;) &#123; //获取当前节点的前一个节点 final Node p = node.predecessor(); //如果前节点为头节点，再次尝试获取 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //获取成功后，设置当前节点为头节点，注意设置setHead细节,此处不再贴出代码 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //获取失败判断当前线程是否应当挂起，如果满足挂起条件则进行挂起 //挂起parkAndCheckInterrupt比较简单，直接调用LockSupport.park(this); //被唤醒后会返回当前线程的中断状态，然后在循环中继续竞争锁 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;/*** 只有当前一个节点的状态为Node.SIGNAL时返回true，即：应当挂起。**/private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //前一个节点的等待状态waitStatus int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. * 前一个节点已经设置为释放锁要通知随后的节点，可以安全挂起。 */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. * 前一个节点已经是取消状态，移除并且找到最近一个非取消状态的节点 */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. * 前节点等待状态此时已定为初始态（0）或者PROPAGATE，我们需要一个 * 通知，所以需要将前节点设置为Node.SIGNAL，但是当前节点还不应该 * 被挂起，被挂起前应当确定当前线程确实不能够获取锁 */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 至此，一个竞争失败的线程就被安全挂起，等待其他线程释放锁后把它唤醒，被唤醒后继续未竟事业。我们再来看下AQS锁释放的过程，还是以ReentrantLock为入口。12345ReentrantLockpublic void unlock() &#123; //ReentrantLock.unlock直接调用非公平锁的release方法，该方法是AQS实现的模版方法。 sync.release(1);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445AbstractQueuedSynchronizerpublic final boolean release(int arg) &#123; //AQS先调用由子类ReentrantLock实现的的tryRelease方法，如果释放成功，则唤醒后续节点 if (tryRelease(arg)) &#123; Node h = head; //如果头节点不为空并且等待状态不是初始态（0），则唤醒后续节点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125;private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. * 如果当前节点等待状态是负数（比如-1，需要换醒后续节点） * 尝试改变头节点等待状态，改变失败或者已经被其他线程改变也没有关系 * 因为它总会被设置为正常的状态并且被移除出队列 */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. * 找出正常的节点并且唤醒 */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; //如果下个节点不存在或者已被取消，则找出最近的等待状态小于0的节点 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; //唤醒后续节点 if (s != null) LockSupport.unpark(s.thread);&#125; 12345678910111213141516ReentrantLock$NonfairSyncprotected final boolean tryRelease(int releases) &#123; //因为当前是可重入锁，state值实际保存了当前线程的重入次数，释放的时候需要依次释放 int c = getState() - releases; //非锁持有线程释放锁会抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; //如果c为0，表明当前线程已经完全释放锁 free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 至此，排他锁的一种获取和释放就结束了。实际上AQS中还有Condition锁（称之为锁也有些不恰当），每个Condition自己又维护了一个等待队列，Condition等待队列中的Node满足条件会被转移到AQS维护的队列中来完成锁的竞争。感兴趣的同学可以看ReentrantReadWriteLock的实现，ReentrantReadWriteLock就是基于AQS的该特性实现的。 从网上摘抄过来一段对AQS的总结作为结束。 首先，AQS并不关心“是什么锁”，对于AQS来说它只是实现了一系列的用于判断“资源”是否可以访问的API,并且封装了在“访问资源”受限时将请求访问的线程的加入队列、挂起、唤醒等操作， AQS只关心“资源不可以访问时，怎么处理？”、“资源是可以被同时访问，还是在同一时间只能被一个线程访问？”、“如果有线程等不及资源了，怎么从AQS的队列中退出？”等一系列围绕资源访问的问题，而至于“资源是否可以被访问？”这个问题则交给AQS的子类去实现。 这是典型的将规则和操作分开的设计思路：规则子类定义，操作逻辑因为具有公用性，放在父类中去封装。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[test4j导致Load飙高排查]]></title>
      <url>%2F2016%2F11%2F18%2Ftest4j%E5%AF%BC%E8%87%B4Load%E9%A3%99%E9%AB%98%E6%8E%92%E6%9F%A5%2F</url>
      <content type="text"><![CDATA[记一次test4j导致CPU飙高的事故在使用Jenkins构建工程时出现服务器Load不断飙升的现象，导致构建无法正常进行，查看构建日之后发现一些应用处出现OOM的状况。于是，我就开始查找原因的漫漫长征路。首先简单了解下test4j初始化过程(忽略读取相关配置及之前)。1234Test4jCore-&gt;CoreModule:1.initSingletonInstance()CoreModule-&gt;ConfigurationLoader:2.loading()\n加载系统信息\n模块信息\n配置信息（比如：数据库）\n等CoreModule-&gt;ConfigHelper:3.logLevel()\n设置打印消息级别CoreModule-&gt;CoreModule:4.new CoreModule() CoreModule时序列图1234CoreModule-&gt;ModulesLoader:1.load()\n加载test4j模块并进行初始化(init)\n初始化Module管理器，主要管理Module监听器note right of ModulesLoader:相关模块参见test4j-default.propertiesCoreModule-&gt;CoreModule$CoreModuleListener:2.new CoreModule$CoreModuleListener()CoreModule-&gt;3.Module:afterInit() 上面简单列出test4j的初始化流程，那么这次故障原因在哪产生的呢？不着急，容我慢慢道来。 事故现场：在maven执行test生命周期的过程中，发现cpu利用率不断升高，甚至达到700%，load也随之不断飙升。 排查点一：业务需要大量计算。纵观所有单元测试，没有大量数据计算，那么业务本身原因也就排除。 排查点二：load飙高，是否有大量IO等待。查看stack及各个子线程cpu使用率后，确实有一些IO等待（redis读取等待），此点Mark。 排查点三：IO不会造成高cpu使用率，那么最可能的就是GC了。果不其然，4个GC线程cpu使用率均在100%左右。 排查点四：既然GC这么高，会不会是heap给的太小，但查看程序执行日之后基本排除此种可能，因为发现每个测试类开始test4j都会对spring重新初始化。 排查到第四点就有些兴奋了，test4j是有参数可以设定spring容器行为的，@SpringContext注解中，shared属性默认为fasle，即：spring容器在测试类之间并不共享。那么改掉它，重新跑。竟然好了！那么为什么采用默认的shared值会有问题呢？ 排查到这里基本可以确定：1.test4j配置有问题；2.test4j自身的BUG 随后查看了test4j的源码，尼玛！！share属性在程序中竟然写死为ture！！test4j一直就是在以共享spring容器的方式运行！！看到这里基本上就可以确定是test4j的问题了，毕竟这个项目最后一次更新停留在了两年前！！ 让我们重新审视test4j的启动，发现还并没有涉及到对spring的操作，因为是对spring的多次初始化，所以我们的目光可以聚焦在对SpringModule的处理上。 在test4j中每个Module均包含一个内部监听类，test4j会在不同的测试生命周期点通知到监听类，以便各个Module做出响应的行为。 下面是SpringModule的监听类部分源码： 12345678910111213141516SpringModule.javapublic void beforeClass(Class testClazz) &#123; SpringModuleHelper.resetDumpReference(); SpringInitInvoker.invokeSpringInitMethod(TestContext.currTestedObject()); //每次切换测试类，都会init，内部是怎么实现的呢？看下段源码 Test4JSpringContext springContext = SpringModuleHelper.initSpringContext(testClazz, contextFactory); MessageHelper.warn("SpringModuleHelper.initSpringContext " + SpringTestedContext.getSpringContext()); SpringTestedContext.setSpringContext(springContext);&#125;Overridepublic void afterClass(Object testedObject) &#123; //释放当前测试类Spring SpringTestedContext.removeSpringContext();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970SpringModuleHelper.javapublic static Test4JSpringContext initSpringContext(Class testClazz, ApplicationContextFactory contextFactory) &#123; //首先会从test4j自定义的上下文查找spring上下文，没找到进行创建 Test4JSpringContext springContext = SpringTestedContext.getSpringContext(); if (springContext != null) &#123; return springContext; &#125; //找出配置@SpringContext SpringContext annotation = AnnotationHelper.getClassLevelAnnotation(SpringContext.class, testClazz); Class declaredAnnotationClazz = AnnotationHelper.getClassWithAnnotation(SpringContext.class, testClazz); if (annotation == null) &#123; return null; &#125; //spring容器是否共享，程序默认为false boolean share = annotation.share(); Test4JSpringContext context = null; if (share) &#123; //SHARED_SPRING_CONTEXT以@SpringContext被注解类为key，来实现spring容器共享 context = SHARED_SPRING_CONTEXT.get(declaredAnnotationClazz); &#125; if (context == null) &#123; //注意：BUG即将诞生！！！！！！！ context = newSpringContext(testClazz, contextFactory, annotation); &#125; if (share) &#123; SHARED_SPRING_CONTEXT.put(declaredAnnotationClazz, context); &#125; //将springContext设置回测试上下文 SpringTestedContext.setSpringContext(context); return context;&#125;private static Test4JSpringContext newSpringContext(Class testClazz, ApplicationContextFactory contextFactory, SpringContext annotation) &#123; long startTime = System.currentTimeMillis(); String[] locations = annotation.value(); boolean allowLazy = annotation.allowLazy(); Test4JSpringContext springContext = contextFactory.createApplicationContext(Arrays.asList(locations), false, allowLazy); //设置Context共享方式，BUG也由此产生了。 springContext.setShared(annotation.share()); //test4j对spring进行了封装，内部调用spring方法初始化 springContext.refresh(); long duration = System.currentTimeMillis() - startTime; MessageHelper.warn(String.format("take %d ms to init spring context for test obejct[%s]", duration, testClazz.getName())); return springContext;&#125;/** * 释放测试类的spring容器 * * @param springContext * AbstractApplicationContext实例，这里定义为Object是方便其它模块脱离spring依赖 */public static void closeSpringContext(Object springContext) &#123; if (springContext == null) &#123; return; &#125; if (!(springContext instanceof Test4JSpringContext)) &#123; String error = String.format("there must be something error, the type[%s] object isn't a spring context.",springContext.getClass().getName()); throw new RuntimeException(error); &#125; Test4JSpringContext context = (Test4JSpringContext) springContext; //这个方法 if (context.isShared() == false) &#123; context.destroy(); MessageHelper.warn("close spring context for class:" + TestContext.currTestedClazzName()); &#125;&#125; 123456789101112public class Test4JSpringContext extends ClassPathXmlApplicationContext &#123; private boolean shared; /** * 设置是否共享spring * * @param share */ public void setShared(boolean share) &#123; //哈哈哈，作者写了一个低级BUG出来，当你没使用共享方式的时候，恭喜你，你惨了！继续看代码！ this.shared = true; &#125;&#125; 此时BUG的全貌出现了，大家仔细看，test4j中默认的shared为false，也就是默认不共享，但是在为Test4JSpringContext设置shared时却写死为true了。我们还记得test4j的每个Module都有一个内部监听类来处理关心的测试中的各个生命周期，在每个测试类开始前（beforeClass），SpringModule负责spring容器的创建（如果需要），在测试结束后（afterClass），负责容器的销毁（如果需要）。 那么问题就在这里，当我们使用默认的shared时，每个测试开始都会创建一个spring容器，这是正常的，因为我们并没有共享spring容器，但是，当测试结束时，本应该根据shared值销毁spring容器，却因为BUG，从Test4JSpringContext中取出的值为true，作孽啊，test4j认为我们是共享的，便保留了当前的spring容器，于是乎，就出现了车祸现场！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring源码 AOP代理流程]]></title>
      <url>%2F2016%2F10%2F29%2FSpring%E6%BA%90%E7%A0%81-AOP%E4%BB%A3%E7%90%86%E6%B5%81%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[AOP是spring中重要的一个组件，今天看了下AOP代理生成的过程，做了简单的记录，留作日后查看。 spring在完成对bean的装配后，在暴露到工厂前，会对进行实例化。 在这个过程中可以看到spring对bean生命周期控制的几个用户可以定制的步骤：BeanPostProcessor.postProcessBeforeInitialization－&gt;InitializingBean.afterPropertiesSet-&gt;BeanPostProcessor.postProcessAfterInitialization我们可以通过实现这几个接口来实现对bean不同阶段的一个定制，spring的AOP就通过BeanPostProcessor.postProcessAfterInitialization阶段介入。可以看出spring面向组件编程的思想。 spring会扫描BeanPostProcessor实现，在此进行处理。我们关注对注解方式实现的Aspect。 如果当前bean需要被代理，则会生成代理 bean，对我们真正的bean进行包装。 这里会从所有的advice中匹配出适合当前bean的advice，如果找到这些advice，就需要该 bean进行封装，即：创建代理。 下面看下，spring筛选advice的过程。找出合适的advisor和advice。但该方法并无实际操作，而是直接调用了其他方法。 首先列出spring中所有advice，然后匹配能够应用的。 此处advice分了两类进行遍历匹配，不知道为什么Advisor会分为两类，客官有知道的请指教（后面也会再看这个问题）。使用注解的aspect不属IntroductionAdvisor。 取出切入点，做最后的判断。 真正的决策者出现了，看看spring到底是怎么来断定该Advice是否符合当前的bean。可以看到，spring为了判断该bean是否能够应用该advice，查了当前bean实现的所有接口，但最终判断还是根据当前实例的某个实现方法是否满足匹配规则（比如：实例的某个复写方法上加上了自定义Aspect注解），如果满足，就认为该bean需要加入该advice。即：该类需要做代理类进行封装。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring源码 Autowired与Resource]]></title>
      <url>%2F2016%2F10%2F19%2FSpring%E6%BA%90%E7%A0%81-Autowired%E4%B8%8EResource%2F</url>
      <content type="text"><![CDATA[最近项目中发现对Spring中的Autowired和JSR-250 定义的Resource认知还是比较模糊，网上的大多的解释也比较笼统，没能解释清楚我的疑问，于是自己动手，丰衣足食，总结如下。先来一段官方的解释，其实官方的解释意境很清楚了。If you intend to express annotation-driven injection by name, do not primarily use @Autowired, even if is technically capable of referring to a bean name through @Qualifier values. Instead, use the JSR-250 @Resource annotation, which is semantically defined to identify a specific target component by its unique name, with the declared type being irrelevant for the matching process. As a specific consequence of this semantic difference, beans that are themselves defined as a collection or map type cannot be injected through @Autowired, because type matching is not properly applicable to them. Use @Resource for such beans, referring to the specific collection or map bean by unique name. @Autowired applies to fields, constructors, and multi-argument methods, allowing for narrowing through qualifier annotations at the parameter level. By contrast, @Resource is supported only for fields and bean property setter methods with a single argument. As a consequence, stick with qualifiers if your injection target is a constructor or a multi-argument method.除了注解使用的地方不同外，比如：Autowired可以用在多参数的方法上等而Resource就只能用在变量、set方法上等，这个不再赘述。 主要关注其实现的解释。 Autowired网上大多解释是按照类型进行装配，给人一种只会按照类型匹配的误解，其实不然，当Autowired遇到候选类型有多个实例但实际需要注入的不是集合类型（List）或者Map的时候，默认会按照变量名称对候选类型进行筛选，此时如果没找到就会抛出异常。下图是Autowired确定候选的代码。 Resource网上大多也简单解释为按照名称装配，当Resource没有在单例池中找到指定名称的bean，就会在bean定义池中找bean定义，然后去创建这个bean实例（即：调用beanFactory的doGetBean方法）。当然，不管其过程怎样，在返回bean实例前还是要对bean的类型进行检查，如果不是想要的类型，还是会抛出异常。代码片段如下，可以看到，在从beanFactory中拿bean实例的时候还是传入了类型，供确定bean实例用。 在返回bean实例前，对bean类型进行检查。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IO模型]]></title>
      <url>%2F2016%2F10%2F17%2FIO%E6%A8%A1%E5%9E%8B%2F</url>
      <content type="text"><![CDATA[IO模型对IO的变成模型一直比较模糊，分不清楚什么同步阻塞，同步非阻塞等概念，对理解一些网络编程框架造成不少的困扰，花时间理了一下，有理解不到位的地方，烦请客官留言。 Unix编程中将IO模型分为5种： 阻塞IO 非阻塞IO IO复用 信号驱动IO 异步IO 首先，当应用发起一个IO操作，分为两个步骤： 发起IO请求：IO请求一般需要请求特殊资源（如磁盘、RAM、文件），当资源被上一个使用者使用没有被释放时，IO请求就会被阻塞，直到能够使用这个资源。 真正的IO操作：真正进行数据传输 阻塞和非阻塞的区别就在发起IO请求这步进行区分：应用程序发起IO请求后是否能立即返回 不能立即返回的称为阻塞IO：即资源不可用时，IO请求一直阻塞，直到反馈结果（有数据或超时）。 立即返回的称为非阻塞IO：资源不可用时，IO请求离开返回，返回数据标识资源不可用。 同步和 异步的区别在真正IO操作这步进行区分：在将数据从内核拷贝到应用缓冲区期间是否阻塞 不阻塞的称为异步IO：操作系统帮应用做完IO操作再将结果返回给应用(应用发送或接收数据后立刻返回，数据写入OS缓存，由OS完成数据发送或接收，并返回成功或失败的信息给应用) 阻塞的称为同步IO：实际IO读写阻塞应用进程(应用阻塞在发送或接收数据的状态，直到数据成功传输或返回失败) 综上，前4种属于同步IO，最后一种是异步IO。即： 阻塞IO（同步阻塞IO） 非阻塞IO （同步非阻塞IO） IO复用 （同步非阻塞IO） 信号驱动IO （同步非阻塞IO） 异步IO （异步IO）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis源码 Parameters JDBC Type]]></title>
      <url>%2F2016%2F09%2F19%2FMybatis%E6%BA%90%E7%A0%81-Parameters-JDBC-Type%2F</url>
      <content type="text"><![CDATA[Mybatis Parameters JDBC TypeMybatis的sqlmap中Parameters的jdbcType参数可以不设置，Parameters 官方文档中解释: The JDBC Type is required by JDBC for all nullable columns, if null is passed as a value. You can investigate this yourself by reading the JavaDocs for the PreparedStatement.setNull() method.Mybatis在处理参数具体类型时从TypeHandlerRegistry中获取具体的TypeHandler。 12345678910111213141516171819202122232425262728293031323334353637/*** parameter where子句后具体某个参数入参* jdbcType sqlmap中声明的jdbcType，如：where id = #&#123;id,jdbcType=VARCHAR&#125;**/ private TypeHandler&lt;? extends Object&gt; resolveTypeHandler(Object parameter, JdbcType jdbcType) &#123; TypeHandler&lt;? extends Object&gt; handler; if (parameter == null) &#123; handler = OBJECT_TYPE_HANDLER; &#125; else &#123; //参数的运行时类型 handler = typeHandlerRegistry.getTypeHandler(parameter.getClass(), jdbcType); if (handler == null || handler instanceof UnknownTypeHandler) &#123; handler = OBJECT_TYPE_HANDLER; &#125; &#125; return handler; &#125; private &lt;T&gt; TypeHandler&lt;T&gt; getTypeHandler(Type type, JdbcType jdbcType) &#123; //TYPE_HANDLER_MAP是jdbc类型到java数据类型映射，详见下图 //TYPE_HANDLER_MAP中每个类型都会包含类似这条记录"null" -&gt; "class java.lang.Float"（null为key-&gt;java类型为value） //也就是说只要入参运行时类型确定，handler就确定 Map&lt;JdbcType, TypeHandler&lt;?&gt;&gt; jdbcHandlerMap = TYPE_HANDLER_MAP.get(type); TypeHandler&lt;?&gt; handler = null; //该步一定会拿到handler，除非参数类型Mybatis本身处理不了，并且没有自定义的handler if (jdbcHandlerMap != null) &#123; handler = jdbcHandlerMap.get(jdbcType); if (handler == null) &#123; handler = jdbcHandlerMap.get(null); &#125; &#125; if (handler == null &amp;&amp; type != null &amp;&amp; type instanceof Class &amp;&amp; Enum.class.isAssignableFrom((Class&lt;?&gt;) type)) &#123; handler = new EnumTypeHandler((Class&lt;?&gt;) type); &#125; // type drives generics here return (TypeHandler&lt;T&gt;) handler; &#125; 继续看了mysql.jdbc对null值的处理，发现其实这个jdbcType在设置值时根本没用到，可能是为了以后使用吧。直接上代码。123456789101112131415161718192021222324/** * Set a parameter to SQL NULL * * &lt;p&gt; * &lt;B&gt;Note:&lt;/B&gt; You must specify the parameters SQL type (although MySQL * ignores it) * &lt;/p&gt; * * @param parameterIndex * the first parameter is 1, etc... * @param sqlType * the SQL type code defined in java.sql.Types * * @exception SQLException * if a database access error occurs */ public void setNull(int parameterIndex, int sqlType) throws SQLException &#123; synchronized (checkClosed().getConnectionMutex()) &#123; setInternal(parameterIndex, "null"); //$NON-NLS-1$ this.isNull[parameterIndex - 1 + getParameterIndexOffset()] = true; this.parameterTypes[parameterIndex - 1 + getParameterIndexOffset()] = Types.NULL; &#125; &#125;]]></content>
    </entry>

    
  
  
</search>

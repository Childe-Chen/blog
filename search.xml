<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[思考延时队列]]></title>
      <url>%2F2019%2F03%2F18%2F%E7%AC%94%E8%AE%B0-%E7%94%B1rocketmq%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97%E6%80%9D%E8%80%83%E4%BB%BB%E5%8A%A1%E8%A7%84%E5%88%92%2F</url>
      <content type="text"><![CDATA[背景项目中存在以下场景需要延迟触发一些事件： 订单在未支付状态下30分钟后自动关闭； 订单超过15天未主动确认收货需要自动确认收货； 商品价格需要在不同的时间段生效不同的价格方案等。 以上场景下需要有一个相对平台化的服务来满足，而不必每个项目自己做定时任务去进行轮询。 解刨延迟/定时任务构成一个任务有两个要素：执行时间；执行逻辑。对任务规划者而言，并不关心任务执行逻辑，规划者只要在既定的时间触发该任务，但既然作为一个规划者，就必须具备任务的基本维护能力：新增，删除/取消，到期，查找。 那么一个想要实现规划者就必须考虑两件事：1.怎样即时发现时间到期；2.怎样提高任务的维护效率，即怎么存储任务来保证对任务的高效操作。 本文只关注延时队列中对任务的基本规划能力的实现方式，不涉及延时系统的设计讨论，系统层面的话题太大了。 Rocketmq延迟队列实现Rocketmq的定时队列通过一个叫做“SCHEDULE_TOPIC_XXXX”的Topic来实现，这个Topic用来处理需要被延迟发送的消息。在Rocketmq中延迟消息被分为几个延迟级别，每个延迟级别分别对应“SCHEDULE_TOPIC_XXXX”Topic下一个延迟队列，默认延迟级别为：”1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”。在Broker启动时，会启动相对应队列的线程来处理各个延迟队列的延迟消息。 盗用艾瑞克一次分享中的图来直观感受下延迟队列的实现。 Rocketmq处理通过消息体的扩展字段DELAY来区分Producer是否投递的是延迟消息，如果DELAY大于0，即确定是延迟消息，Broker会备份源消息的topic和queueId，并将其替换为对应延迟队列的信息，然后将修改后的消息落盘到commitLog，DefaultMessageStore#ReputMessageServiceReput线程将消息分发至对应Topic的消息队列（messageQueue），延迟队列被ScheduleMessageService消费，延迟消息到期后会被封装为一个新消息（恢复其源Topic及queueId等信息）再次走消息的投递流程到commitLog，然后被Reput到最初要投递的队列，在整个过程中ScheduleMessageService同时扮演了Consumer和Producer的角色，区分好这两种角色后再来看ScheduleMessageService这段代码会清楚不少。下面列出的代码有所删减改，目的是为了表达核心逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127// ScheduleMessageServicepublic void start() &#123; if (started.compareAndSet(false, true)) &#123; this.timer = new Timer("ScheduleMessageTimerThread", true); // 给不同级别的队列启动对应的任务线程 for (Map.Entry&lt;Integer, Long&gt; entry : this.delayLevelTable.entrySet()) &#123; Integer level = entry.getKey(); Long timeDelay = entry.getValue(); Long offset = this.offsetTable.get(level); if (null == offset) &#123; offset = 0L; &#125; if (timeDelay != null) &#123; this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME); &#125; &#125; this.timer.scheduleAtFixedRate(new TimerTask() &#123; @Override public void run() &#123; try &#123; // 定时持久化消费进度 if (started.get()) ScheduleMessageService.this.persist(); &#125; catch (Throwable e) &#123; log.error("scheduleAtFixedRate flush exception", e); &#125; &#125; &#125;, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval()); &#125;&#125;/*** ScheduleMessageService的内部类*/class DeliverDelayedMessageTimerTask extends TimerTask &#123; public void executeOnTimeup() &#123; // 找到对应的队列 ConsumeQueue cq = ScheduleMessageService.this.defaultMessageStore.findConsumeQueue(SCHEDULE_TOPIC, delayLevel2QueueId(delayLevel)); long failScheduleOffset = offset; // 如果队列不存在，DELAY_FOR_A_WHILE后重新尝试。todo: 什么情况下会出现队列为null呢？？？ if (cq == null) &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, failScheduleOffset), DELAY_FOR_A_WHILE); return; &#125; // 从指定位置拉取队列中的可用消息 SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(this.offset); if (bufferCQ != null) &#123; try &#123; long nextOffset = offset; int i = 0; ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); // 队列中的消息体大小均为CQ_STORE_UNIT_SIZE，依次进行遍历 for (; i &lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) &#123; long offsetPy = bufferCQ.getByteBuffer().getLong(); int sizePy = bufferCQ.getByteBuffer().getInt(); // 延迟消息的tagCode保存的是延时时间 long tagsCode = bufferCQ.getByteBuffer().getLong(); // omit tagsCode 校正 long now = System.currentTimeMillis(); // 交付时间计算 long deliverTimestamp = this.correctDeliverTimestamp(now, tagsCode); // 下次开始拉取消息的位置 nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); long countdown = deliverTimestamp - now; if (countdown &lt;= 0) &#123; // 如果到了交付时间，则从commitLog中拉取出消息 MessageExt msgExt = ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset( offsetPy, sizePy); if (msgExt != null) &#123; try &#123; // 封装称为一条新的消息，主要是将在topic、queueId、tagCode等替换为源消息的值 MessageExtBrokerInner msgInner = this.messageTimeup(msgExt); PutMessageResult putMessageResult = ScheduleMessageService.this.writeMessageStore .putMessage(msgInner); if (putMessageResult != null &amp;&amp; putMessageResult.getPutMessageStatus() == PutMessageStatus.PUT_OK) &#123; continue; &#125; else &#123; // reput失败的处理，主要是重设定时任务及持久化消费进度 return; &#125; &#125; catch (Exception e) &#123; //omit &#125; &#125; &#125; else &#123; // 重设定时任务及持久化消费进度 return; &#125; &#125; // end of for nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); // 重设定时任务及持久化消费进度 ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask( this.delayLevel, nextOffset), DELAY_FOR_A_WHILE); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; finally &#123; bufferCQ.release(); &#125; &#125; // end of if (bufferCQ != null) else &#123; // 校正消费偏移量 long cqMinOffset = cq.getMinOffsetInQueue(); if (offset &lt; cqMinOffset) &#123; failScheduleOffset = cqMinOffset; // omit error log &#125; &#125; &#125;&#125; 此种方式数据结构类似链表，但链表中的数据天然有序，为什么呢？因为消息的延迟时间是Broker落盘时间加上延迟级别对应的时间，落盘后的消息才会被ReputMessageServiceReput线程进行分发到指定的MessageQueue，而Reput线程是个单线程，整个过程FIFO，所以延迟队列天然有序。 我们再从任务的行为：新增，删除/取消，到期，查找，来看下Rocketmq延迟队列作为任务的优缺点。 因为Rocketmq的设计方式，注定其延迟队列只能支持特定延迟时间的特点； 因为Rocketmq并不是为延迟任务而生，所以它无法删除/取消一个定时任务； 生产一个延迟消息和生产一个普通消息的过程是一致的，因此新增一个延迟消息无非就是像broker进行消息投递，如果网络稳定，其时间消耗稳定; MessageQueue的天然有序，保证队列头的消息一定是最先到期的，所以到期任务的检索时间稳定； 消息的查找只可根据msgId查找或者消息key查找，msgId中包含消息的物理偏移量（类似MySql的主键）可直接定位消息，而key的查找是根据key的hashCode查找索引文件获得，可能或出现查出多条的情况，需要客户端自己根据key再次过滤，除了在控制台很少在Consumer端使用key发起查询。 个人认为虽然Rocketmq具备延迟的功能，但其主要目的是为了实现“至少投递一次”语义，因为一个延迟消息处理完成会被Rocketmq落盘两次，就只是因为topic和queueId不同，如果Rocketmq只用来处理延迟消息，那么其存储的数据量延迟消息的两倍。所以如果延迟消息量不是很大并且不需要灵活的延迟时间的话，Rocketmq不失为一种好的选择。 DelayQueue在JDK中带有定时/延迟特性的两个类：DelayQueue和ScheduledThreadPoolExecutor。这两个类名起的很好，见名知意。我们从这两个类的数据结构入手看下JDK这两个自带类如何实现任务的规划。 DelayQueue内部使用PriorityQueue来存储定时/延时任务，相当于是PriorityQueue的一种使用场景，主要特性是当队列为空或任务时间未到期时可让拉取线程进行等待。 PriorityQueue使用二叉堆来存储数据，这里不去深究二叉堆的定义，其特性是根节点一定是整个堆中最大/最小的点，这点是比较符合优先队列的特性，PriorityQueue的根节点queue[0]是最小的节点，称为最小堆。PS：二叉堆是完全二叉树或者是近似完全二叉树。 完全二叉树 满二叉树 总节点k $$2^{h-1}&lt;= k &lt;= 2^{h}-1$$ $$2^{h}-1$$ 树高h $$h=log_{2}k+1$$ $$h=log_{2}(k+1)$$ PriorityQueue用数组来实现二叉堆，queue[n]节点的两个子节点存储在queue[2*n+1]和queue[2*(n+1)]，使用指定的Comparator或节点本身实现比较接口Comparable来排序。站在DelayQueue的角色来看，PriorityQueue的排序关键字是到期时间，比较器Comparator/Comparable比较的就是延迟时间的大小。 PriorityQueue关键操作的平均时间复杂度：增加O(log(n))，查找O(n)，删除=查找+移除O(n) + O(log(n))，到期任务检索O(1)。PS：就二叉堆本身而言还有堆合并等操作，而且不同构造方式的时间复杂度也不相同，但不是这里的关注重点。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768// PriorityQueue /** * 队列 */ transient Object[] queue; /** * 队列中元素的数量。同时用来记录下一个元素的index。 */ private int size = 0; /** * 排序使用的比较器，可以不设置，默认使用元素的自然排序 */ private final Comparator&lt;? super E&gt; comparator; public boolean offer(E e) &#123; // omit check // 元素在数组中的index int i = size; // omit grow Capacity size = i + 1; if (i == 0) queue[0] = e; else // 构造堆结构 siftUp(i, e); return true; &#125; private void siftUp(int k, E x) &#123; // 是自定义比较器 if (comparator != null) siftUpUsingComparator(k, x); else siftUpComparable(k, x); &#125; private void siftUpUsingComparator(int k, E x) &#123; while (k &gt; 0) &#123; // 按照存储规则找到自己的父节点 int parent = (k - 1) &gt;&gt;&gt; 1; Object e = queue[parent]; // 如果待插入节点不小于父节点，说明位置正确，不再继续向上比较 // 最差循环次数为堆的高度 if (comparator.compare(x, (E) e) &gt;= 0) break; // 否则将父节点放在当前位置，继续向上比较 queue[k] = e; k = parent; &#125; // 进入队列 queue[k] = x; &#125; /** * 查找指定的节点 */ private int indexOf(Object o) &#123; if (o != null) &#123; // 因为实际存储结构为数组，所以此时需要进行遍历 // 因此时间复杂度为O(n) for (int i = 0; i &lt; size; i++) if (o.equals(queue[i])) return i; &#125; return -1; &#125; 在JDK中使用ScheduledThreadPoolExecutor同样使用了最小堆来规划任务，但与PriorityQueue不同，ScheduledThreadPoolExecutor对任务元素进行了优化，让任务本身持有自己在数组中的index，这样将取消操作时间复杂度降到了O(1)，但如果removeOnCancel参数配置为true时，取消操作会引起删除操作，此时就增加了堆的维护。该配置默认为false，这延迟了垃圾回收，会导致无谓的内存占用，前提是任务存在极大可能在开始前被取消。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// ScheduledThreadPoolExecutor内部类private class ScheduledFutureTask&lt;V&gt; extends FutureTask&lt;V&gt; implements RunnableScheduledFuture&lt;V&gt; &#123; /** 延迟时间，单位：纳秒 */ private long time; /** * 任务的重复时间，单位：纳秒。 * 正数表明固定速率执行。 * 负数说明固定延时时间执行。 * 0说明该任务不需重复。 */ private final long period; /** 任务本身，可通过reExecutePeriodic方法重新入队 */ RunnableScheduledFuture&lt;V&gt; outerTask = this; /** * 任务在延迟队列中的index，用来支持快速取消任务。 */ int heapIndex;&#125;static class DelayedWorkQueue extends AbstractQueue&lt;Runnable&gt; implements BlockingQueue&lt;Runnable&gt; &#123; // 数组初识长度 private static final int INITIAL_CAPACITY = 16; // 任务数组 private RunnableScheduledFuture&lt;?&gt;[] queue = new RunnableScheduledFuture&lt;?&gt;[INITIAL_CAPACITY]; private final ReentrantLock lock = new ReentrantLock(); // 队列中元素的数量。同时用来记录下一个元素的index。 private int size = 0; /** * leader是指等待在queue上的第一个线程，该线程等待时间为第一个任务到期的时间， * 其余的等待线程无限期等待，直到leader把其唤醒。此处为Leader-Follower模式，目的是减少不必要的等待时间。 * 更多释义参见远吗注释。 */ private Thread leader = null; /** * 当队列头部任务变得可用或者一个新线程称为leader是会在该条件上发出信号。 */ private final Condition available = lock.newCondition(); // 对数组的增加删除操作同PriorityQueue相似&#125; TimeWheel以上两种实现方式有一个共同点，他们并没有按照预想将任务和延迟时间分离，接下来我们要讨论的时间轮就是按照这个思路来实现任务的规划，看一下时间轮如何来存储和存储/规划任务。 网上盗图来直观感受下时间轮。 上图展示的一个多层时间轮，红线部分表示任务随时间流逝迁移的过程，直到最后被执行。 时间轮是对时钟的一个模拟，在时间轮中有以下几点需要注意： Tick，一次时间推进，每次推进会检查/执行超时任务。 TickDuration，时间轮推进的最小单元，每隔TickDuration会有一次Tick，它决定了时间轮的精确程度。 Bucket（TicksPerWheel），上图中的每一隔就是一个Bucket，表示一个时间轮可以有多少个Tick，它是存储任务的最小单元。 上层时间轮的TickDuration是下层时间轮的表示时间的最大范围，即：父TickDuration = 子TickDuration * 子Bucket梳理 Netty和Kafka使用时间轮来管理超时任务，因为具体场景不同实现也不同。 NettyNetty的时间轮用来管理网络连接的超时，实际应用过程中网络超时时间一般不会很长，Netty采用单时间轮来规划超时任务。 12345678910111213141516171819202122232425262728293031323334353637383940public class HashedWheelTimer implements Timer &#123; // 默认 100ms private final long tickDuration; // Bucket，使用数组实现，默认 512 private final HashedWheelBucket[] wheel; // 待加入时间轮的任务 private final Queue&lt;HashedWheelTimeout&gt; timeouts = PlatformDependent.newMpscQueue(); // 被取消的任务 private final Queue&lt;HashedWheelTimeout&gt; cancelledTimeouts = PlatformDependent.newMpscQueue(); // 新增一个任务 public Timeout newTimeout(TimerTask task, long delay, TimeUnit unit) &#123; // 计算超时时间 long deadline = System.nanoTime() + unit.toNanos(delay) - startTime; // 构建任务 HashedWheelTimeout timeout = new HashedWheelTimeout(this, task, deadline); // 添加到 timeouts 链表 timeouts.add(timeout); return timeout; &#125; // Bucket用双向链表组织数据 private static final class HashedWheelBucket &#123; // Used for the linked-list datastructure private HashedWheelTimeout head; private HashedWheelTimeout tail; &#125; // 超时任务结构 private static final class HashedWheelTimeout implements Timeout &#123; // 任务本身 private final TimerTask task; // 超时时间 private final long deadline; // 剩余轮询次数 long remainingRounds; // 被添加到的Bucket HashedWheelBucket bucket; &#125;&#125; 上面是Netty时间轮主要的数据结构，从源码中我们可以看出Netty为提升效率废了不少心思，比如：PlatformDependent.newMpscQueue()来特定解决多生产单消费的场景，有兴趣的可以看下，这不是本文重点。 前面我们说了，Netty是单时间轮，当规划的任务时间超过一圈怎么办呢？我们看到超时任务HashedWheelTimeout中有一个remainingRounds字段，这个字段记录了该任务在被遍历多少次时可以被过期，任务每被遍历一次该字段值减1，当其值不大于0时，表示可以被过期。 Netty使用数组 + 双向链表的方式来组织时间轮，对于添加/取消操作仅做了记录，真正的操作实际发生在下一个Tick。我们来看下Netty版的时间轮对任务规划的时间复杂度。 添加任务 通过newTimeout方法新增任务，Netty仅仅把任务放到timeouts链表的队尾，时间相对稳定，可看作O(1)。 取消任务 取消是HashedWheelTimeout任务本身提供的，在调用HashedWheelTimeout#cancel()方法后，Netty仅仅修改了任务状态并把任务放到了cancelledTimeouts链表的队尾，时间相对稳定，可看作O(1)。 删除任务 12345678void remove() &#123; // 当前任务被规划到的Bucket，如果不存在说明尚未被规划，直接忽略 HashedWheelBucket bucket = this.bucket; if (bucket != null) &#123; // 从bucket的链表中移除 bucket.remove(this); &#125;&#125; 外部不暴露该操作，发生在过期任务时，由HashedWheelTimeout任务本身提供，因为任务本身有记录当前的Bucket，所以删除操作等于是链表的一个删除操作，时间相对稳定，可看作O(1)。 查找任务 不存在该场景。 过期任务 1234567891011121314151617181920212223242526// 时间推进线程private final class Worker implements Runnable &#123; private long tick; public void run() &#123; do &#123; // 获取本次过期时间 final long deadline = waitForNextTick(); if (deadline &gt; 0) &#123; // 本次Bucket位置 int idx = (int) (tick &amp; mask); // 将 cancelledTimeouts 中任务从Bucket中删除 processCancelledTasks(); HashedWheelBucket bucket = wheel[idx]; // 将 timeouts 中的任务添加到对应的Bucket中 transferTimeoutsToBuckets(); // 遍历当前Bucket，执行当前Bucket中的过期任务 bucket.expireTimeouts(deadline); // 记录嘀嗒次数 tick++; &#125; &#125; while (WORKER_STATE_UPDATER.get(HashedWheelTimer.this) == WORKER_STATE_STARTED); &#125;&#125; 时间的推进是独立的一个线程在做，该线程同时也负责过期任务的执行等操作，可简单认为此步骤操作为O(n)，因为推进线程需要完全遍历timeouts、cancelledTimeouts与bucket链表，在遍历timeouts时，Netty为了避免任务过多，所以限制每次最多遍历10万个，也就是说，一个tick只能规划10万个任务，当任务量过大时，会存在超时任务执行时间延迟的现象。 我们上面有说到取消任务时，只是将任务放在了超时链表中，在下次发生时间推进时才会真正将被取消的任务从队列移除，这就导致空间的浪费，GC回收会至少延迟一个推进间隔（TickDuration）。 如今Netty在网络通信中的霸主地位不必多言，虽然Netty中时间轮的实现不是最好的但一定是满足了Netty这个特定场景的性能需要，即：没有最好的技术，只有适合的技术。这一点对平时开发设计也有借鉴意义。 KafkaKafka也使用数组 + 双向链表的方式来组织时间轮(Timer.scala)，只是有多个数组来表示多层时间轮而已，所以其对任务的增加/删除/取消操作实际也就是对双向链表的增删操作，时间复杂度与其一致，其到期任务的过程下面我们与Netty做比较来看。 上面关于Netty实现的一些比较蛇皮的地方，在Kafka中均得到了解决，并且Kafka中使用JDK中的DelayQueue来帮助做时间推进，使得一个线程可以轻松管理错层时间轮的时间推进。 我们先来看他规避了Netty中哪些不太合适的地方： Netty单层时间轮规划超过一轮的任务时使用remainingRounds来做控制，这就导致在一次推进中，当前Bucket下的任务并不是全部都是过期的，而Kafka使用多层时间轮，一个Bucket被某次推进选中，它下挂的任务行为完全一致，处理起来相对简单，Kafka目前也是由推进线程来遍历到期任务，但它也可以方便的使用fork/join方式来进一步提高处理效率。 Kafka虽然也由推进线程遍历到期Bucket下的任务，但任务的执行却交给专门的线程池来执行，自己仅将该Bucket下的所有任务重新走一遍添加逻辑，以便决定任务是交给线程池执行还是下降到下层时间轮。 Kafka既然是多层时间轮，那他是如何来推进每个时间轮的时间呢？Kafka在时间推进层面跳过了时间轮这一层，直接规划到时间轮下的Bucket，Kafka将所有Bucket放在DelayQueue中来简化时间推进的操作，这样多个时间轮的推进任务只需要一个线程便可完成！ 我们之前讲DelayQueue不太适合任务规划，但Kafka时间轮中的Bucket数量并不会很多，在数量不多的情况下DelayQueue性能还是不错的（应该是满足了Kafka的性能需求），所以此处选择了DelayQueue来实现时间的推进。还是应了这句话：没有最好的技术，只有适合的技术。 Kafka的时间轮实现更契合我对超时中心的认知，超时中心只关心时间是否到期并进行回调通知，并不关心和执行任务的情况，Kafka明确了角色分工，所以在海量数据下会更高效。 扩展文章拖的时间太久了，还有两个与定时任务相关的开源项目没来得及看，大家自行看下里面怎么实现定时功能的吧。 Quartz Scheduler 当当任务调度 总结这篇文章前后花了一个月的休息时间来做调研和整理，虽然文中有贴出部分源代码，但代码作者的巧妙构思完全不能被表达，还是建议去看源码。 正所谓：纸上得来终觉浅，绝知此事要躬行。 下面给出代码版本： Rocketmq release-4.5.0 Netty 4.1 Kafka 2.2 JDK 1.8.0_74 小生不才，以上如有描述有误的地方还望各位不吝赐教 !^_^！ 参考如何让快递更”快”？菜鸟自研定时任务调度引擎首次公开TimingWheel本质与DelayedOperationPurgatory核心结构Kafka技术内幕样章 层级时间轮Kafka解惑之时间轮（TimingWheel）你真的了解延迟队列吗定时器（Timer）的实现二叉堆动画展示二叉树]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[rocketmq-深入消费源码]]></title>
      <url>%2F2019%2F01%2F23%2Frocketmq-%E6%B7%B1%E5%85%A5%E6%B6%88%E8%B4%B9%E6%BA%90%E7%A0%81%2F</url>
      <content type="text"><![CDATA[对比看两种消费方式的实现：顺序消费与并发消费。这里对顺序消费只关注消费端，不关心producer与broker怎么处理顺序消息，假设架构及策略已保证消息的全局或者局部顺序性。通过构建假定前提，我们可以忽略本次讨论的非重点内容。以下仍以Push方式为例。 消费方式宏观上看rmq自身是一个生产-消费模式，在他各个角色的具体实现中也不乏生产-消费模式的使用。DefaultMQPushConsumerImpl中消息的拉取及拉取成功后的消费均采用生产-消费的方式进行组织（PullRequest、ConsumeRequest），消费的流程在之前rocketmq-消息重复分析一文中记录的很清楚，不再展开。不论是顺序还是并发消费，都使用ProcessQueue做为本地消息的存储介质，每个MessageQueue对应一个ProcessQueue，该关系保存在RebalanceImpl中，每次复杂均衡时可能发生改变。ProcessQueue内部用TreeMap&lt;Long, MessageExt&gt;来保存消息，key是消息的offset。TreeMap内部使用的红黑树，根据树的特性可知消息的本地存储是offset有序的，并发消费时DefaultMQPushConsumerImpl去拉取消息会根据offset(RebalanceImpl#getMaxSpan)的跨度判断是否限流。 并发关于并发消费的源码在rocketmq-消息重复分析中已有分析。 这里在强调下其ack机制的实现，ack是发送响应的过程，来确保消息的送达，在rmq实现中，为了确保消息“至少消费一次”语义，采用 offset + sendback 的方式来实现。 在并发消费下，不论消费成功还是失败offset都会记录为本次消费的最大一个offset，对于消费失败的消息，rmq的consumer会再次发回broker，如果此步骤也失败，降级为本地延迟消费，然后重复消费步骤。 顺序顺序分全局顺序和局部顺序。全局有序的话就一个队列一个消费者；局部有序情况下，按照某个业务为度将统一纬度的消息发送到指定队列（可以通过自定义发送策略实现），消费者顺序消费分配到的队列消息。PS：广播与集群略有差异，以下默认集群消费。 在rocketmq-消息重复分析中有谈到负载均衡的流程，在负载均衡完成的最后有这么一个操作： 1234567// RebalanceImpl// omit// Rebalance后，更新本地的queue信息，消费者提交PullRequest，从新队列拉取消息this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder);//omit 这方法的三个参数意义是：当前消费者分配到哪个topic下的哪些队列，当前消费者的消费方式是否为顺序。 下面的代码需要注意对isOrder的使用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// RebalanceImpl// 1. 删除已经不再订阅的messageQueue// omit// 2. 订阅新的messageQueue，并封装新的PullRequestList&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;();for (MessageQueue mq : mqSet) &#123; // 如果为新增messageQueue，需要添加到本地记录 if (!this.processQueueTable.containsKey(mq)) &#123; // 如果为顺序消费，并且锁messageQueue失败，则忽略该messageQueue if (isOrder &amp;&amp; !this.lock(mq)) &#123; log.warn("doRebalance, &#123;&#125;, add a new mq failed, &#123;&#125;, because lock failed", consumerGroup, mq); continue; &#125; // 删除之前的消费进度 this.removeDirtyOffset(mq); ProcessQueue pq = new ProcessQueue(); // 计算消费进度，参见 ConsumeFromWhere，该值在启动消费者时设置 long nextOffset = this.computePullFromWhere(mq); // 进行本地存根，若为新存根则发起PullRequest if (nextOffset &gt;= 0) &#123; ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq); if (pre != null) &#123; log.info("doRebalance, &#123;&#125;, mq already exists, &#123;&#125;", consumerGroup, mq); &#125; else &#123; log.info("doRebalance, &#123;&#125;, add a new mq, &#123;&#125;", consumerGroup, mq); PullRequest pullRequest = new PullRequest(); pullRequest.setConsumerGroup(consumerGroup); pullRequest.setNextOffset(nextOffset); pullRequest.setMessageQueue(mq); pullRequest.setProcessQueue(pq); pullRequestList.add(pullRequest); changed = true; &#125; &#125; else &#123; log.warn("doRebalance, &#123;&#125;, add new mq failed, &#123;&#125;", consumerGroup, mq); &#125; &#125;&#125;// 3. 提交PullRequest进行消息拉取// omit 我们看到在为顺序消费时，多了一步对messageQueue的加锁操作，看他做了些什么事情。 123456789101112131415161718192021222324252627282930313233343536// RebalanceImplpublic boolean lock(final MessageQueue mq) &#123; // 找到该messageQueue所在的broker，该broker必须是master并且必须是该messageQueue所在的broker FindBrokerResult findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), MixAll.MASTER_ID, true); if (findBrokerResult != null) &#123; LockBatchRequestBody requestBody = new LockBatchRequestBody(); requestBody.setConsumerGroup(this.consumerGroup); requestBody.setClientId(this.mQClientFactory.getClientId()); requestBody.getMqSet().add(mq); try &#123; // 请求broker锁定该messageQueue // broker在RebalanceLockManager中尝试锁定messageQueue，若锁定成功则保存MessageQueue与clientId的映射关系 // 一个messageQueue只能被一个client锁定，来确保一个messageQueue在顺序情况下只能被一个消费者订阅，保证消费的顺序性 Set&lt;MessageQueue&gt; lockedMq = this.mQClientFactory.getMQClientAPIImpl().lockBatchMQ(findBrokerResult.getBrokerAddr(), requestBody, 1000); for (MessageQueue mmqq : lockedMq) &#123; // 更新本地存根 ProcessQueue processQueue = this.processQueueTable.get(mmqq); if (processQueue != null) &#123; processQueue.setLocked(true); // 记录锁定时间 processQueue.setLastLockTimestamp(System.currentTimeMillis()); &#125; &#125; // 返回锁定结果 return lockedMq.contains(mq); &#125; catch (Exception e) &#123; log.error("lockBatchMQ exception, " + mq, e); &#125; &#125; return false;&#125; 在顺序消费的模式下，负载均衡时需要锁定队列来避免多个消费者同时订阅一个messageQueue的情况，并发消费模式不需要考虑这些问题。在消息的拉取时，顺序消费也略有不同。我们以Push方式为例来看。 12345678910111213141516171819202122232425// DefaultMQPushConsumerImpl// 检查messageQueue是否被锁定if (processQueue.isLocked()) &#123; // 如果是第一次拉取该messageQueue if (!pullRequest.isLockedFirst()) &#123; final long offset = this.rebalanceImpl.computePullFromWhere(pullRequest.getMessageQueue()); boolean brokerBusy = offset &lt; pullRequest.getNextOffset(); log.info("the first time to pull message, so fix offset from broker. pullRequest: &#123;&#125; NewOffset: &#123;&#125; brokerBusy: &#123;&#125;", pullRequest, offset, brokerBusy); if (brokerBusy) &#123; log.info("[NOTIFYME]the first time to pull message, but pull request offset larger than broker consume offset. pullRequest: &#123;&#125; NewOffset: &#123;&#125;", pullRequest, offset); &#125; pullRequest.setLockedFirst(true); pullRequest.setNextOffset(offset); &#125;&#125; else &#123; // 如果messageQueue未被锁定，等待一段时间再次尝试拉取，ConsumeMessageOrderlyService启动时会启动任务定时去锁定所有消费的messageQueue this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION); log.info("pull message later because not locked in broker, &#123;&#125;", pullRequest); return;&#125; 在MessageListenerOrderly接口中有这么一段注释A MessageListenerOrderly object is used to receive asynchronously delivered messages orderly. one queue,one thread。意思是顺序消费一个queue对应一个消费线程。因为要顺序消费，必然要保证前一个消费后才能消费后面一个，所以多线程在此处没有存在的必要性。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102// ConsumeMessageOrderlyService// 如果发生负载均衡当前消费者不再处理该messageQueue时，processQueue会被标记为删除if (this.processQueue.isDropped()) &#123; log.warn("run, the message queue not be able to consume, because it's dropped. &#123;&#125;", this.messageQueue); return;&#125;// 每个messageQueue对应一把锁，同一时刻只能有一个线程在消费一个messageQueuefinal Object objLock = messageQueueLock.fetchLockObject(this.messageQueue);synchronized (objLock) &#123; // 检查消费模式及锁的有效性 if (MessageModel.BROADCASTING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) || (this.processQueue.isLocked() &amp;&amp; !this.processQueue.isLockExpired())) &#123; final long beginTime = System.currentTimeMillis(); for (boolean continueConsume = true; continueConsume; ) &#123; if (this.processQueue.isDropped()) &#123; log.warn("the message queue not be able to consume, because it's dropped. &#123;&#125;", this.messageQueue); break; &#125; // 集群模式下检查是否上锁 if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; !this.processQueue.isLocked()) &#123; log.warn("the message queue not locked, so consume later, &#123;&#125;", this.messageQueue); ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; // 集群模式下检查锁是否过期 if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; this.processQueue.isLockExpired()) &#123; log.warn("the message queue lock expired, so consume later, &#123;&#125;", this.messageQueue); ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; // 消费循环时长不能超过MAX_TIME_CONSUME_CONTINUOUSLY long interval = System.currentTimeMillis() - beginTime; if (interval &gt; MAX_TIME_CONSUME_CONTINUOUSLY) &#123; ConsumeMessageOrderlyService.this.submitConsumeRequestLater(processQueue, messageQueue, 10); break; &#125; // 一次消费的消息数量，默认为1 final int consumeBatchSize = ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); // 从本地缓存获取消息 List&lt;MessageExt&gt; msgs = this.processQueue.takeMessags(consumeBatchSize); if (msgs.isEmpty()) &#123; break; &#125; final ConsumeOrderlyContext context = new ConsumeOrderlyContext(this.messageQueue); ConsumeOrderlyStatus status = null; ConsumeMessageContext consumeMessageContext = null; // omit hook long beginTimestamp = System.currentTimeMillis(); ConsumeReturnType returnType = ConsumeReturnType.SUCCESS; boolean hasException = false; try &#123; // 对processQueue加上消费锁，防止负载均衡时可能会发生争抢 this.processQueue.getLockConsume().lock(); if (this.processQueue.isDropped()) &#123; log.warn("consumeMessage, the message queue not be able to consume, because it's dropped. &#123;&#125;", this.messageQueue); break; &#125; // 参考 ConsumeOrderlyStatus status = messageListener.consumeMessage(Collections.unmodifiableList(msgs), context); &#125; catch (Throwable e) &#123; hasException = true; &#125; finally &#123; this.processQueue.getLockConsume().unlock(); &#125; // omit hook and stats preprocess // 抛出异常时 if (null == status) &#123; status = ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; // omit hook and stats // 处理消费结果 continueConsume = ConsumeMessageOrderlyService.this.processConsumeResult(msgs, status, context, this); &#125; &#125; else &#123; if (this.processQueue.isDropped()) &#123; log.warn("the message queue not be able to consume, because it's dropped. &#123;&#125;", this.messageQueue); return; &#125; // 挂起片刻再次尝试消费 ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 100); &#125;&#125; 再来看下怎么处理消费结果。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// ConsumeMessageOrderlyServicepublic boolean processConsumeResult( final List&lt;MessageExt&gt; msgs, final ConsumeOrderlyStatus status, final ConsumeOrderlyContext context, final ConsumeRequest consumeRequest ) &#123; boolean continueConsume = true; long commitOffset = -1L; if (context.isAutoCommit()) &#123; switch (status) &#123; case COMMIT: case ROLLBACK: log.warn("the message queue consume result is illegal, we think you want to ack these message &#123;&#125;", consumeRequest.getMessageQueue()); case SUCCESS: // 清空consumingMsgOrderlyTreeMap，并更新一些统计信息，返回下一个offset的起始 commitOffset = consumeRequest.getProcessQueue().commit(); break; case SUSPEND_CURRENT_QUEUE_A_MOMENT: // 检查消息是否已经超过最大消费次数 // 如果没有超过，本地继续尝试消费 // 如果超过，将消息发送到死信队列，不在处理 // 如果发送到死信队列失败，本地继续尝试消费 if (checkReconsumeTimes(msgs)) &#123; consumeRequest.getProcessQueue().makeMessageToCosumeAgain(msgs); this.submitConsumeRequestLater( consumeRequest.getProcessQueue(), consumeRequest.getMessageQueue(), context.getSuspendCurrentQueueTimeMillis()); continueConsume = false; &#125; else &#123; commitOffset = consumeRequest.getProcessQueue().commit(); &#125; break; default: break; &#125; &#125; else &#123; // omit &#125; // 更新消费偏移 if (commitOffset &gt;= 0 &amp;&amp; !consumeRequest.getProcessQueue().isDropped()) &#123; this.defaultMQPushConsumerImpl.getOffsetStore().updateOffset(consumeRequest.getMessageQueue(), commitOffset, false); &#125; return continueConsume;&#125; offset保存offset的持久化可以在本地也可以在远程（broker上，默认RemoteBrokerOffsetStore），offset并不是每次消费完成都会向broker发起持久化请求，有这么几个持久化入口： 定时任务，默认5S一次 每次去broker拉取消息时 消费者shutdown时 后记ProcessQueue中已offset为key做本地排序怎么能保证消息的顺序呢？很简单，因为broker是顺序写commitLog，所以后来消息的offset一定比先到的消息offset大。 在ProcessQueue中为顺序消费保留了一个consumingMsgOrderlyTreeMap字段，该字段保存某次消费的消息，为什么需要做这个字段呢？猜测只是为了应对批量消费的，即ConsumeMessageBatchMaxSize大于1时。 小生不才，以上如有描述有误的地方还望各位不吝赐教 !^_^！ 贴出的源码均基于release-4.3.2，为了更好的表达描述的重点，贴出的源代码会有所删减。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[rocketmq-消息重复分析]]></title>
      <url>%2F2019%2F01%2F13%2Frocketmq-%E6%B6%88%E6%81%AF%E9%87%8D%E5%A4%8D%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[场景描述有两个namesrv（namesrv1与namesrv2），某个topic分别在两个master上均分队列1，2，3。 当broker-ba的主从与namesrv1网络出现问题，namesrv2正常，此时namesrv出现不一致，当两个从属相同consumerGroup的消费者分别从两个namesrv获取broker信息时，按照均分的策略就会出现c1订阅队列1和2，c2订阅队列2。此时，消息便会重复被消费，而且出现了一个队列被多个消费者订阅现象。 出现这种情况是不是正常的呢？出现这种情况是否可以自动恢复呢？尝试从以下几个角度来分析，部署结构见下图（图中未给出namesrv）。 以下介绍均假设已经初步了解rocketmq，如果还不是很清楚，可以看下我的这边博客rocketmq-半入门级架构及核心流程概览。 部署结构在聊重复消费前，先大概了解下Broker的部署结构及其HA。 一个master 自己部署玩玩用，测试或者生产环境打算这么搞得，脑子一定上火长泡了。 一个master一个slave（同步或者异步复制） 测试环境可以使用，这种部署结构下可以基本保证应用的高可用。当master挂了或者磁盘损坏等异常情况下，采用同步复制方式的，消息不会丢失；采用异步复制的，除了哪些没来的及同步的消息，其他消息都有备份。 一个master多个slave（同步或者异步复制） 这种方式个人认为意义不是很大，因为这种情况下不可能开启同步方式来持久化消息，当master挂掉后rmq无法继续接受生产消息，只是多了一些消息的备份。 多个master多个slave（同步或者异步复制） 每个master对应一个slave，即有多对master-slave。多个master增加了集群对异常的容忍性，单个master的挂机不会影响topic下其他master上queue的写入，较之情况2更好。 “至少投递一次”语义rocketmq实现At least Once语义，即每个消息至少投递一次。consumer先pull消息到本地，消费完成后，才向服务器返回ack，如果没有消费一定不会ack 消息。实现上，采用不同的消费策略（ConsumeMessageConcurrentlyService/ConsumeMessageOrderlyService）时，对失败的处理也不一样。 从语义上看，消息被重复消费是允许出现的，不管到底是什么原因导致的。 语义实现以DefaultMQPushConsumerImpl为例，先来看下consumer拉取数据的大致流程。在consumer启动的最后一步，会调用this.mQClientFactory.rebalanceImmediately();来唤醒RebalanceService来进行首次Rebalance。在Rebalance之前consumer已经从namesrv那里获取了订阅topic的配置信息，Rebalance使用既定的分配策略计算出当前消费者可以订阅到哪些queue，分配完成后为所有订阅队列提交一个PullRequest到PullMessageService#pullRequestQueue中，消费线程拿到请求开始拉取数据。 123456789// PullMessageServiceprivate void pullMessage(final PullRequest pullRequest) &#123; // 根据分组信息获取消费实例 final MQConsumerInner consumer = this.mQClientFactory.selectConsumer(pullRequest.getConsumerGroup()); if (consumer != null) &#123; DefaultMQPushConsumerImpl impl = (DefaultMQPushConsumerImpl) consumer; impl.pullMessage(pullRequest); &#125;&#125; 最终还是将消费请求转回DefaultMQPushConsumerImpl进行处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190public void pullMessage(final PullRequest pullRequest) &#123; final ProcessQueue processQueue = pullRequest.getProcessQueue(); // 本地消费队列是否已经删除 if (processQueue.isDropped()) &#123; log.info("the pull request[&#123;&#125;] is dropped.", pullRequest.toString()); return; &#125; // 最后一次拉取时间 pullRequest.getProcessQueue().setLastPullTimestamp(System.currentTimeMillis()); try &#123; // 服务状态是否正常 this.makeSureStateOK(); &#125; catch (MQClientException e) &#123; log.warn("pullMessage exception, consumer state not ok", e); this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION); return; &#125; // 是否已经暂停从broker继续拉取消息，哪些情况下会暂停？ if (this.isPause()) &#123; log.warn("consumer was paused, execute pull request later. instanceName=&#123;&#125;, group=&#123;&#125;", this.defaultMQPushConsumer.getInstanceName(), this.defaultMQPushConsumer.getConsumerGroup()); // 延迟执行本次拉取请求 this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_SUSPEND); return; &#125; long cachedMessageCount = processQueue.getMsgCount().get(); long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024); // 本地尚未消费的消息数量已经大于预定的阈值 if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123; this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); if ((queueFlowControlTimes++ % 1000) == 0) &#123; log.warn( "the cached message count exceeds the threshold &#123;&#125;, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;", this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes); &#125; return; &#125; // 本溪尚未消费的消息总大小是否已经超过预定的阈值 if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) &#123; this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); if ((queueFlowControlTimes++ % 1000) == 0) &#123; log.warn( "the cached message size exceeds the threshold &#123;&#125; MiB, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;", this.defaultMQPushConsumer.getPullThresholdSizeForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes); &#125; return; &#125; if (!this.consumeOrderly) &#123; // 如果不是顺序消费，此时要判断最老消息和最新消息的跨度，如果跨度超过预定值，延缓拉取 // processQueue内部采用TreeMap来存消息，消息的offset为key，所以本地消费存储天然有序 if (processQueue.getMaxSpan() &gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) &#123; this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); if ((queueMaxSpanFlowControlTimes++ % 1000) == 0) &#123; log.warn( "the queue's messages, span too long, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, maxSpan=&#123;&#125;, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;", processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), processQueue.getMaxSpan(), pullRequest, queueMaxSpanFlowControlTimes); &#125; return; &#125; &#125; else &#123; // 忽略顺序消费处理 &#125; final SubscriptionData subscriptionData = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic()); // 订阅的信息，具体信息看SubscriptionData类 if (null == subscriptionData) &#123; this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION); log.warn("find the consumer's subscription failed, &#123;&#125;", pullRequest); return; &#125; final long beginTimestamp = System.currentTimeMillis(); // 拉到消息后的回掉处理 PullCallback pullCallback = new PullCallback() &#123; @Override public void onSuccess(PullResult pullResult) &#123; if (pullResult != null) &#123; pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), pullResult, subscriptionData); switch (pullResult.getPullStatus()) &#123; case FOUND: long prevRequestOffset = pullRequest.getNextOffset(); pullRequest.setNextOffset(pullResult.getNextBeginOffset()); long pullRT = System.currentTimeMillis() - beginTimestamp; DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullRT(pullRequest.getConsumerGroup(), pullRequest.getMessageQueue().getTopic(), pullRT); long firstMsgOffset = Long.MAX_VALUE; if (pullResult.getMsgFoundList() == null || pullResult.getMsgFoundList().isEmpty()) &#123; // 如果拉取的消息为空，立马开始下次拉取 // 为什么消息为空，但是状态是FOUND？因为存在tag过滤，broker根据tag的hash值做初步过滤，本地根据tag的字符串 // 做过滤，当出现hash冲突时，可能出现该种情况。 // 为什么broker要用hash值呢？可以看下broker怎么为一条消息做索引（即consumeQueue是如何设计的） // consumeQueue的每个元素是定长的，如果使用真实的tag值，无法做到定长，但hash值长度固定。 // consumeQueue可以当作是一个大数组，当知道数据的偏移（index）时，访问的时间复杂度是O(1) DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); &#125; else &#123; firstMsgOffset = pullResult.getMsgFoundList().get(0).getQueueOffset(); // 统计信息 DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullTPS(pullRequest.getConsumerGroup(), pullRequest.getMessageQueue().getTopic(), pullResult.getMsgFoundList().size()); // 将消息放到本地消费队列，内部为TreeMap结构存储 boolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList()); // 提交消费请求 DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest( pullResult.getMsgFoundList(), processQueue, pullRequest.getMessageQueue(), dispatchToConsume); if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) &#123; DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval()); &#125; else &#123; DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); &#125; &#125; break; case NO_NEW_MSG: case NO_MATCHED_MSG: // 没有拉取到新消息或者没有符合匹配信息的消息 pullRequest.setNextOffset(pullResult.getNextBeginOffset()); DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest); DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); break; case OFFSET_ILLEGAL: // 偏移量非法 break; default: break; &#125; &#125; &#125; @Override public void onException(Throwable e) &#123; if (!pullRequest.getMessageQueue().getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123; log.warn("execute the pull request exception", e); &#125; DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION); &#125; &#125;; boolean commitOffsetEnable = false; long commitOffsetValue = 0L; // 如果是集群消费方式，从RemoteBrokerOffsetStore获取消费本地消费的偏移量 if (MessageModel.CLUSTERING == this.defaultMQPushConsumer.getMessageModel()) &#123; commitOffsetValue = this.offsetStore.readOffset(pullRequest.getMessageQueue(), ReadOffsetType.READ_FROM_MEMORY); if (commitOffsetValue &gt; 0) &#123; commitOffsetEnable = true; &#125; &#125; // ...省略... try &#123; // 通过api向broker拉取消息 this.pullAPIWrapper.pullKernelImpl( pullRequest.getMessageQueue(), subExpression, subscriptionData.getExpressionType(), subscriptionData.getSubVersion(), pullRequest.getNextOffset(), this.defaultMQPushConsumer.getPullBatchSize(), sysFlag, commitOffsetValue, BROKER_SUSPEND_MAX_TIME_MILLIS, CONSUMER_TIMEOUT_MILLIS_WHEN_SUSPEND, CommunicationMode.ASYNC, pullCallback ); &#125; catch (Exception e) &#123; log.error("pullKernelImpl exception", e); this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION); &#125;&#125; 以上我们看到了consumer端如发起拉取及处理消息的流程，最终在callback中通过调用具体的消费服务的submitConsumeRequest方法来提交ConsumeRequest。此处以ConsumeMessageConcurrentlyService为例来看，方法的实现比较简单：将本次拉取的消费按照设置的批量消费批次大小（默认为1）进行划分，每个批次都为一个ConsumeRequest implements Runnable，然后提交至消费线程池，等待被消费。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128// ConsumeRequest in ConsumeMessageConcurrentlyServiceclass ConsumeRequest implements Runnable &#123; public void run() &#123; // ...omit check... MessageListenerConcurrently listener = ConsumeMessageConcurrentlyService.this.messageListener; ConsumeConcurrentlyContext context = new ConsumeConcurrentlyContext(messageQueue); ConsumeConcurrentlyStatus status = null; ConsumeMessageContext consumeMessageContext = null; // ...omit hook... long beginTimestamp = System.currentTimeMillis(); boolean hasException = false; ConsumeReturnType returnType = ConsumeReturnType.SUCCESS; try &#123; // 不清楚重新设置有何意义？[在这个视频中有提到](https://pan.baidu.com/s/19VDHbOnENzoGxUkhiYgj3Q) ConsumeMessageConcurrentlyService.this.resetRetryTopic(msgs); if (msgs != null &amp;&amp; !msgs.isEmpty()) &#123; for (MessageExt msg : msgs) &#123; // 设置开始消费时间 MessageAccessor.setConsumeStartTimeStamp(msg, String.valueOf(System.currentTimeMillis())); &#125; &#125; // 业务消费消息 status = listener.consumeMessage(Collections.unmodifiableList(msgs), context); &#125; catch (Throwable e) &#123; // omit log hasException = true; &#125; // 判断消费状态 long consumeRT = System.currentTimeMillis() - beginTimestamp; if (null == status) &#123; if (hasException) &#123; returnType = ConsumeReturnType.EXCEPTION; &#125; else &#123; returnType = ConsumeReturnType.RETURNNULL; &#125; &#125; else if (consumeRT &gt;= defaultMQPushConsumer.getConsumeTimeout() * 60 * 1000) &#123; returnType = ConsumeReturnType.TIME_OUT; &#125; else if (ConsumeConcurrentlyStatus.RECONSUME_LATER == status) &#123; returnType = ConsumeReturnType.FAILED; &#125; else if (ConsumeConcurrentlyStatus.CONSUME_SUCCESS == status) &#123; returnType = ConsumeReturnType.SUCCESS; &#125; // omit hook if (null == status) &#123; // omit log status = ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; // omit hook and stats if (!processQueue.isDropped()) &#123; // 处理消费结果进行ACK ConsumeMessageConcurrentlyService.this.processConsumeResult(status, context, this); &#125; else &#123; log.warn("processQueue is dropped without process consume result. messageQueue=&#123;&#125;, msgs=&#123;&#125;", messageQueue, msgs); &#125; &#125;&#125;public void processConsumeResult( final ConsumeConcurrentlyStatus status, final ConsumeConcurrentlyContext context, final ConsumeRequest consumeRequest ) &#123; int ackIndex = context.getAckIndex(); if (consumeRequest.getMsgs().isEmpty()) return; // stats data switch (status) &#123; case CONSUME_SUCCESS: if (ackIndex &gt;= consumeRequest.getMsgs().size()) &#123; ackIndex = consumeRequest.getMsgs().size() - 1; &#125; int ok = ackIndex + 1; int failed = consumeRequest.getMsgs().size() - ok; this.getConsumerStatsManager().incConsumeOKTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), ok); this.getConsumerStatsManager().incConsumeFailedTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), failed); break; case RECONSUME_LATER: ackIndex = -1; this.getConsumerStatsManager().incConsumeFailedTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), consumeRequest.getMsgs().size()); break; default: break; &#125; switch (this.defaultMQPushConsumer.getMessageModel()) &#123; case BROADCASTING: // omit break; case CLUSTERING: List&lt;MessageExt&gt; msgBackFailed = new ArrayList&lt;MessageExt&gt;(consumeRequest.getMsgs().size()); // 根绝ackIndex将失败消息发回到broker的retry队列 for (int i = ackIndex + 1; i &lt; consumeRequest.getMsgs().size(); i++) &#123; MessageExt msg = consumeRequest.getMsgs().get(i); boolean result = this.sendMessageBack(msg, context); if (!result) &#123; msg.setReconsumeTimes(msg.getReconsumeTimes() + 1); msgBackFailed.add(msg); &#125; &#125; // 发送到retry队列失败的，本地进行延时消费 if (!msgBackFailed.isEmpty()) &#123; consumeRequest.getMsgs().removeAll(msgBackFailed); this.submitConsumeRequestLater(msgBackFailed, consumeRequest.getProcessQueue(), consumeRequest.getMessageQueue()); &#125; break; default: break; &#125; // 更新消费offset long offset = consumeRequest.getProcessQueue().removeMessage(consumeRequest.getMsgs()); if (offset &gt;= 0 &amp;&amp; !consumeRequest.getProcessQueue().isDropped()) &#123; this.defaultMQPushConsumerImpl.getOffsetStore().updateOffset(consumeRequest.getMessageQueue(), offset, true); &#125;&#125; 我们看到在消费失败时，消息会被重新投递到retry队列或者本地再次消费，在这种设计下就保证了消息至少被消费一次。 消费分配策略以集群消费方式采用默认分配策略为例，看下如何做队列的分配。 目前看到的能够触发rebalance的入口有这么几个： consumer刚启动时，自己进行rebalance，其实这和情况2一致，自己启动意味着consumer数量变更； broker感知到consumer数量变化时，即有consumer的新增或者减少时，会推消息给相同group内的consumer; cosumer定时rebalance，默认20000毫秒。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// RebalanceImplprivate void rebalanceByTopic(final String topic, final boolean isOrder) &#123; switch (messageModel) &#123; case BROADCASTING: // omit break; case CLUSTERING: &#123; // topic下所有queue的集合， 注意！！！此处是从某个namesrv获取 Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic); // topic下某个consumerGroup中所有consumer集合，注意！！！此处是从某个broker获取 List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup); // omit check if (mqSet != null &amp;&amp; cidAll != null) &#123; List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;(); mqAll.addAll(mqSet); // 排序 Collections.sort(mqAll); Collections.sort(cidAll); // 默认 AllocateMessageQueueAveragely AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy; List&lt;MessageQueue&gt; allocateResult = null; try &#123; allocateResult = strategy.allocate(this.consumerGroup, this.mQClientFactory.getClientId(), mqAll, cidAll); &#125; catch (Throwable e) &#123; // omit log return; &#125; Set&lt;MessageQueue&gt; allocateResultSet = new HashSet&lt;MessageQueue&gt;(); if (allocateResult != null) &#123; allocateResultSet.addAll(allocateResult); &#125; // Rebalance后，更新本地的queue信息，消费者提交PullRequest，从新队列拉取消息 boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder); if (changed) &#123; // omit log // When rebalance result changed, should update subscription's version to notify broker. // 将订阅消息立马上报给所有broker，即立马发送心跳 this.messageQueueChanged(topic, mqSet, allocateResultSet); &#125; &#125; break; &#125; default: break; &#125;&#125; 123456789101112131415161718192021222324252627// AllocateMessageQueueAveragelypublic List&lt;MessageQueue&gt; allocate(String consumerGroup, String currentCID, List&lt;MessageQueue&gt; mqAll, List&lt;String&gt; cidAll) &#123; // omit check // 当前consumer在排序后consumer中的下标 int index = cidAll.indexOf(currentCID); // 一般情况下，messageQueue的数量不小于consumer的数量，如果messageQueue数量比consumer数量少，则会出现consumer饿死的情况。 int mod = mqAll.size() % cidAll.size(); // 1. 如果queue数量不大于cosumer数量 -&gt; 平均数量为1 // 2. 如果queue数量大于cosumer数量： // 能整除时 -&gt; 平均值 // 不能整除时 -&gt; 根据consumer在所有consumer中的排序位置确定是取平均值加1 还是 取平均值 int averageSize = mqAll.size() &lt;= cidAll.size() ? 1 : (mod &gt; 0 &amp;&amp; index &lt; mod ? mqAll.size() / cidAll.size() + 1 : mqAll.size() / cidAll.size()); // 确定开始位置 int startIndex = (mod &gt; 0 &amp;&amp; index &lt; mod) ? index * averageSize : index * averageSize + mod; int range = Math.min(averageSize, mqAll.size() - startIndex); for (int i = 0; i &lt; range; i++) &#123; result.add(mqAll.get((startIndex + i) % mqAll.size())); &#125; return result;&#125; 我们注意到rebalance时的cosumer列表和queue列表从不同的地方获取，这可能导致两者数据不一致，即使都从namesrv获取，因为namesrv之间没有强一致性，所以相互间数据也可能短暂不一致，这时consumer自己来做rebalance时的基础数据不一致，可能就会出现同一队列被多个consumer同时订阅的情况。可以把AllocateMessageQueueAveragely的分配代码自己捞出来做下测试。 CAP理论CAP理论不再赘述。从CAP理论中我们可知，一致性和可用性是矛盾的。根据rocketmq的设计理念及具体实现来看，比如：namesrv之间无通信；需要通信的节点间以oneway发送通知等，可以看出rocketmq是优先保证高可用特性的，所以，出现一致性问题在所难免。我们也知道cosumer有任务定时做rebalance，所以它可以保证只要在网络或者通信恢复正常后，整个集群的数据状态最终是一致的。 总结以上描述的场景只是rmq导致重复消费的某个特定场景，当然重复消费不至这些，比如：当某个consumer的消费consumeOffset在没有上报给远程服务（或者持久化）之前，宿主机的电源线被熊孩子给拔掉了，当其他consumer重新消费这个队列是，获取的consumeOffset便是落后的，于是也产生了消息的重复；又比如，ConsumeMessageConcurrentlyService模式下，部分为成功消费的消息会重新投递回broker，如果投递失败，本地尝试重新消费，这时消息也重复了。 我们以“又比如”描述的为基础来回顾下“至少消费一次”语义，在本地重新消费上次失败的消息时再次失败，并且此时jvm crash或者restart，那么这批消费失败的消息就不会再被消费，从这里也可以看出，rcoketmq不保证消息一定被正常消费，只保证“至少消费一次”。 书上得来终觉浅，绝知此事要躬行。 贴出的源码均基于release-4.3.2，为了更好的表达描述的重点，贴出的源代码会有所删减。 小生不才，以上如有描述有误的地方还望各位不吝赐教 !^_^！ 参考ZooKeeper和CAP理论及一致性原则 CAP 定理的含义]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[rocketmq-半入门级架构及核心流程概览]]></title>
      <url>%2F2018%2F11%2F19%2Frocketmq-%E6%9E%B6%E6%9E%84%E5%8F%8A%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B%E6%A2%B3%E7%90%86%2F</url>
      <content type="text"><![CDATA[一直在用rocketmq，对他的功能和大概流程略知一些，但是比较浮，经不起稍微的推敲。是时候进一步了解下这个NB的中间件了。 这里不再赘述它的那些特性，网上一大堆，这里主要按照自己想了解的一些方面作整理，贴出部分核心代码，意图通过表现各个角色间的交互，勾画大致架构，方便以后对每个要点各个深入。如果想要引导来阅读源代码，推荐rmq源码系列，写的很有诚意，本笔记中也部分参考引用其文章。 部署结构（逻辑结构/物理结构）消息中间件的整体看起来像我们相互邮寄明信片。李雷（Producer）通过邮局公告（Namesrv）找到邮局的地址，然后去邮局（Broker）把明信片（Message）发送给韩梅梅（Consumer）。 物理结构 Producer 消息生产者，负责产生消息，一般由业务系统负责产生消息。 Consumer 消息消费者，负责消费消息，一般是后台系统负责异步消费。 Broker 消息中转角色，负责存储消息，转发消息，一般也称为 Server。 Namesrv 注册中心，管理协调角色，维护其他角色信息。 逻辑结构逻辑结构里面把所有角色都集群化了，集群化后就要牵扯到集群消费。于是，基于以上的角色，又衍生出其他的概念。 Producer Group 一类 Producer 的集合名称，这类 Producer 通常发送一类消息，且发送逻辑一致。 Consumer Group 一类 Consumer 的集合名称，这类 Consumer 通常消费一类消息，且消费逻辑一致。 角色实现及其交互按照逻辑/物理部署结构，各个角色间怎么通信？怎么保活？数据怎么备份？ rmq自己对Netty进行了包装（Facade），方便各个角色使用，在工程的remoting子工程中。 namesrv(Name Server)与brokernamesrv与broker是实现后续一切的基础，producer和consumer的信息传递需要broker来中转，那么找到或者说确定一个broker便是第一步了。 namesrv(Name Server)namesrv是很轻量的服务，简单、可集群横向扩展、无状态。他是整个mq的管家（像是Dubbo的服务发现），管理其他角色，如果没有它，整个mq将难以开展工作。 简单看下namesrv启动时的行为。它的核心代码在工程的namesrv包下，代码量很少。 namesrv的故事开始于NamesrvStartup的main方法，它主要来解析配置参数，根据配置装填并初始化和启动NamesrvController。NamesrvController贯连整个Namesrv的业务功能，通过Netty向外暴露服务，主要负责： 管理Topic和Broker的注册信息 管理KV的配置（持久化） 1234567891011121314151617181920212223242526272829303132// NamesrvControllerpublic boolean initialize() &#123; // 管理KV的配置（并持久化） this.kvConfigManager.load(); // 暴露服务 this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.brokerHousekeepingService); // netty执行线程池 this.remotingExecutor = Executors.newFixedThreadPool(nettyServerConfig.getServerWorkerThreads(), new ThreadFactoryImpl("RemotingExecutorThread_")); // 注册服务处理器 this.registerProcessor(); // kv信息打印及broker存活检测任务 this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; NamesrvController.this.routeInfoManager.scanNotActiveBroker(); &#125; &#125;, 5, 10, TimeUnit.SECONDS); this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; NamesrvController.this.kvConfigManager.printAllPeriodically(); &#125; &#125;, 1, 10, TimeUnit.MINUTES); // 省略TSL配置部分&#125; RouteInfoManager相当于是管家的账本，里面保存着关于topic、broker的具体信息，这些信息全部保存在内存中。其维护的信息如下。 1234567891011121314151617181920212223242526//RouteInfoManagerprivate final HashMap&lt;String/* topic */, List&lt;QueueData&gt;&gt; topicQueueTable;/*** BrokerData &#123;* private String cluster;* private String brokerName;* private HashMap&lt;Long/* brokerId */, String/* broker address */&gt; brokerAddrs;* &#125;**/private final HashMap&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;private final HashMap&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;/*** BrokerLiveInfo &#123;* private long lastUpdateTimestamp;* private DataVersion dataVersion;* private Channel channel;* private String haServerAddr;&#125;**/private final HashMap&lt;String/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;private final HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable; 那么，这些信息从哪里来呢？且慢，我们先看下broker。 brokerbroker就是例子中邮局，邮局要具备什么能力呢？ 接收信件 保存信件，保证除不可抗因素外，信件不丢失 投递信件 高效工作，信件快速接受及送达 信件投递失败的处理 信件投递可回溯追踪（当然，邮局不能看内容了） 向管家（namesrv）汇报自己的运营状态 以上这些其实也就是broker要做的事情，只不过它不存在隐私一说罢了。当然他还需要有其他的特性。 支持消息的不同投递模型：Publish/Subscribe，集群分组消费等 高可用，无单点 消息有序 消息过滤 分布式事务 broker的主要源码放在broker目录下，broker（其他模块）的启动模型与namesrv一致，BrokerStartup解析配置，并根据配置装备BrokerController，然后初始化BrokerController并启动（start）。进行初始化时的主要启动一堆定时任务、存储（MessageStore）和Netty配置（注册Processor）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// BrokerControllerpublic boolean initialize() throws CloneNotSupportedException &#123; boolean result = this.topicConfigManager.load(); // 消费者消费信息 result = result &amp;&amp; this.consumerOffsetManager.load(); // 订阅组 result = result &amp;&amp; this.subscriptionGroupManager.load(); // 过滤器 result = result &amp;&amp; this.consumerFilterManager.load(); // 省略messageStore相关处理 result = result &amp;&amp; this.messageStore.load(); if (result) &#123; // 暴露服务，启动两个Server，小端口和VIPChannel有关 this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.clientHousekeepingService); NettyServerConfig fastConfig = (NettyServerConfig) this.nettyServerConfig.clone(); fastConfig.setListenPort(nettyServerConfig.getListenPort() - 2); this.fastRemotingServer = new NettyRemotingServer(fastConfig, this.clientHousekeepingService); // 省略创建各Processor的Executor // 注册Processor this.registerProcessor(); // 持久化消费信息 this.scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; BrokerController.this.consumerOffsetManager.persist(); &#125;, 1000 * 10, this.brokerConfig.getFlushConsumerOffsetInterval(), TimeUnit.MILLISECONDS); // 持久化过滤器信息 this.scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; BrokerController.this.consumerFilterManager.persist(); &#125;, 1000 * 10, 1000 * 10, TimeUnit.MILLISECONDS); // 设置namesrv地址，如果没有设置，则从一个web服务fetch if (this.brokerConfig.getNamesrvAddr() != null) &#123; this.brokerOuterAPI.updateNameServerAddressList(this.brokerConfig.getNamesrvAddr()); &#125; else if (this.brokerConfig.isFetchNamesrvAddrByAddressServer()) &#123; this.scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; BrokerController.this.brokerOuterAPI.fetchNameServerAddr(); &#125;, 1000 * 10, 1000 * 60 * 2, TimeUnit.MILLISECONDS); &#125; if (BrokerRole.SLAVE == this.messageStoreConfig.getBrokerRole()) &#123; // 同步topic、consumerOffset、订阅组等信息到Salve this.scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; BrokerController.this.slaveSynchronize.syncAll(); &#125;, 1000 * 10, 1000 * 60, TimeUnit.MILLISECONDS); &#125; else &#123; // 如果是Master则定时打印与Salve的差异 &#125; // 省略TSL设置及事物初始化 &#125;&#125;public void start() throws Exception &#123; // 省略 启动初始化的那些服务 // 向所有namesrv注册自己 this.registerBrokerAll(true, false, true); // 定时向所有namesrv注册自己 this.scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister()); &#125;, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)), TimeUnit.MILLISECONDS);&#125;public synchronized void registerBrokerAll(final boolean checkOrderConfig, boolean oneway, boolean forceRegister) &#123; // 封装broker上的topic信息 TopicConfigSerializeWrapper topicConfigWrapper = this.getTopicConfigManager().buildTopicConfigSerializeWrapper(); // 调用API向namesrv注册 doRegisterBrokerAll(checkOrderConfig, oneway, topicConfigWrapper);&#125; 此时，我们可以看到的交互，每个broker启动时会先对namesrv寻址，然后把自己的信息注册到所有的namesrv上，并定时维护（心跳），namesrv维护的关于broker的信息来源于此，为了应对不同的场景需要，namesrv把数据封装成不同的结构，方面维护。namesrv关于请求的处理在DefaultRequestProcessor中，透过其processRequest方法我们可以明确其要承担的全部责任，比如：broker注册/注销，增删改查topic路由，KV信息维护等。broker注册的信息包括但是不限于以下内容。 12345678910111213141516171819202122232425262728&#123; "topicConfigSerializeWrapper": &#123; "topicConfigTable":&#123; "topic_?":&#123; "defaultReadQueueNums":"16", "defaultWriteQueueNums":"16", "topicName":"", "readQueueNums":"", "writeQueueNums":"", "perm":"", "topicFilterType":"", "topicSysFlag":"", "order":"" &#125;, &#125;, "dataVersion":&#123; "timestamp":"xxxx", "counter":"xxxx" &#125; &#125;, "filterServerList":[ "",//filterServerAddr ], "clusterName":"", "brokerAddr":"", "brokerName":"", "brokerId":""&#125; namesrv与producer公告（namesrv）维护好了，李雷（producer）就可以通过它来获取邮局（broker）的信息了。 先来看下producer的启动时主要做了些什么事情，producer的主要代码放在工程的client子工程下的producer包中。抛开事务不谈，我们的入口在DefaultMQProducer的start方法上。下面列出启动时我们关心的业务，启动流程时序图，网上也不少了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445// DefaultMQProducerImplpublic void start(final boolean startFactory) throws MQClientException &#123; switch (this.serviceState) &#123; case CREATE_JUST: this.serviceState = ServiceState.START_FAILED; // groupName合法性校验 this.checkConfig(); // MixAll.CLIENT_INNER_PRODUCER_GROUP 用来发送消费者消费失败的消息到重试队列 if (!this.defaultMQProducer.getProducerGroup().equals(MixAll.CLIENT_INNER_PRODUCER_GROUP)) &#123; // 如果不是内部构建的 this.defaultMQProducer.changeInstanceNameToPID(); &#125; // MQClientManager 以 clientId（ip@pid） 维度保证 MQClientInstance 的单例 this.mQClientFactory = MQClientManager.getInstance().getAndCreateMQClientInstance(this.defaultMQProducer, rpcHook); // 向 MQClientInstance 注册自己 boolean registerOK = mQClientFactory.registerProducer(this.defaultMQProducer.getProducerGroup(), this); if (!registerOK) &#123; this.serviceState = ServiceState.CREATE_JUST; throw new MQClientException("..."); &#125; // Just for testing or demo program this.topicPublishInfoTable.put(this.defaultMQProducer.getCreateTopicKey(), new TopicPublishInfo()); if (startFactory) &#123; // 启动MQClientInstance mQClientFactory.start(); &#125; this.serviceState = ServiceState.RUNNING; break; case RUNNING: case START_FAILED: case SHUTDOWN_ALREADY: throw new MQClientException("..."); default: break; &#125; // 向broker发送心跳&amp;&amp;上传filter信息 this.mQClientFactory.sendHeartbeatToAllBrokerWithLock();&#125; 这里我们需要说下rmq中client（Producer、Consumer和Admin）的基本结构，不同角色的client通过Composite一个MQClientInstance的方式封装各自不同的逻辑，所以他们的启动流程大概一致，Consumer的复杂一些，但主流程无差别： 通过clientId获取MQClientInstance实例 自己角色特有的逻辑 向MQClientInstance注册自己 启动MQClientInstance，如果MQClientInstance已启动则返回 通过MQClientInstance方法同步更新自己角色需要的信息 按照以上总结我们着重看下MQClientInstance的start做了些什么。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// MQClientInstancepublic void start() throws MQClientException &#123; switch (this.serviceState) &#123; case CREATE_JUST: this.serviceState = ServiceState.START_FAILED; // If not specified,looking address from name server if (null == this.clientConfig.getNamesrvAddr()) &#123; this.mQClientAPIImpl.fetchNameServerAddr(); &#125; // Start request-response channel // 启动remotingClient，开启与外部交互的通道 this.mQClientAPIImpl.start(); // Start various schedule tasks this.startScheduledTask(); // Start pull service // push模式下拉消息服务 this.pullMessageService.start(); // Start rebalance service // 开启负载均衡消费队列服务 this.rebalanceService.start(); // Start push service // 上个代码片段提到的 CLIENT_INNER_PRODUCER_GROUP 对应的Producer this.defaultMQProducer.getDefaultMQProducerImpl().start(false); this.serviceState = ServiceState.RUNNING; break; case START_FAILED: throw new MQClientException("The Factory object[" + this.getClientId() + "] has been created before, and failed.", null); case RUNNING: case SHUTDOWN_ALREADY: default: break; &#125;&#125;private void startScheduledTask() &#123; // 如果没有配置namesrv的地址，默认从web服务定时抓取 if (null == this.clientConfig.getNamesrvAddr()) &#123; this.scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; MQClientInstance.this.mQClientAPIImpl.fetchNameServerAddr(); &#125;, 1000 * 10, 1000 * 60 * 2, TimeUnit.MILLISECONDS); &#125; // 从namesrv（NamesrvController）获取topic的路由信息 this.scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; MQClientInstance.this.updateTopicRouteInfoFromNameServer(); &#125;, 10, this.clientConfig.getPollNameServerInterval(), TimeUnit.MILLISECONDS); // 和broker的交互 this.scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; // 清理已离线的Broker MQClientInstance.this.cleanOfflineBroker(); // 向所有Broker发送心跳，心跳中带有consumer相关信息：clientId，Subscription等 MQClientInstance.this.sendHeartbeatToAllBrokerWithLock(); &#125;, 1000, this.clientConfig.getHeartbeatBrokerInterval(), TimeUnit.MILLISECONDS); // 持久化消费偏移量（持久化到远程或者本地） this.scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; MQClientInstance.this.persistAllConsumerOffset(); &#125;, 1000 * 10, this.clientConfig.getPersistConsumerOffsetInterval(), TimeUnit.MILLISECONDS); // 调整push方式下的拉取线程数 this.scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; MQClientInstance.this.adjustThreadPool(); &#125;, 1, 1, TimeUnit.MINUTES);&#125; MQClientInstance启动时会启动一个从namesrv定时搜集本地所有订阅（consumer）的和发送（producer）的topic，然后依次通过mQClientAPIImpl.getTopicRouteInfoFromNameServer(topic, 1000 * 3)来进行更新topic的路由信息。 问题：负载均衡怎么做的？ namesrv与consumer正如上文说的那样，Producer和Consumer都组合了MQClientInstance，而MQClientInstance来完成其和namesrv的交互，所以它的过程和producer是一致的，他们需要维护的信息也是一致的。 producer与brokerproducer与broker的交互有以下几个关注点：producer支持发送消息的方式？发送失败producer怎么处理？broker怎么处理producer的消息？ 消息发送producer发送方式有SYNC、ASYNC、ONEWAY，这些方式定义在CommunicationMode中，但是这块从DefaultMQProducer定义的send方法命名中没有明确区分同步和异步，在我当前的版本中ASYNC的实现存在问题（It will be removed at 4.4.0 cause for exception handling and the wrong Semantics of timeout.）。 我们以最简单的入口（DefaultMQProducer#send(Message)）大致看下producer的发送流程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// DefaultMQProducerImplprivate SendResult sendDefaultImpl( Message msg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout ) &#123; // 省略合法性检查 final long invokeID = random.nextLong(); long beginTimestampFirst = System.currentTimeMillis(); long beginTimestampPrev = beginTimestampFirst; // 选择发送topic信息，此步骤数据由·MQClientInstance·中启动的定时任务维护 TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123; boolean callTimeout = false; MessageQueue mq = null; Exception exception = null; SendResult sendResult = null; // 同步模式下，总发送次数确定，默认失败重试2次，也就是共尝试发送3次 int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; for (; times &lt; timesTotal; times++) &#123; String lastBrokerName = null == mq ? null : mq.getBrokerName(); // 选择本次发送的队列 MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName); if (mqSelected != null) &#123; mq = mqSelected; try &#123; beginTimestampPrev = System.currentTimeMillis(); long costTime = beginTimestampPrev - beginTimestampFirst; if (timeout &lt; costTime) &#123; callTimeout = true; // 超时中断 break; &#125; // 封装信息，并调用ClientAPI发送出去 sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, topicPublishInfo, timeout - costTime); endTimestamp = System.currentTimeMillis(); // 更新本次borker可用性，如果sendLatencyFaultEnable开启 this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false); // 如果SYNC模式下发送失败进行重试，ASYNC和ONEWAY模式下直接返回null &#125; catch (Exception e) &#123; // 根据不同的异常类型确认处理方式：重试、中断、返回 // 更新本次borker可用性，如果sendLatencyFaultEnable开启 this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, true); &#125; &#125; else &#123; // 没有可用队列不进行发送 break; &#125; &#125; // 省略异常处理 &#125; // 省略异常处理&#125; 那么发送消息的怎么确认发送队列呢？sendLatencyFaultEnable是什么？ 先通过topic找到对应的topicPublishInfo，顾名思义topicPublishInfo里面维护了该topic相关的broker和队列信息，在没有开启sendLatencyFaultEnable情况下（默认），按照递增取模的方式选择即将要发送的队列，如果开启了sendLatencyFaultEnable，再取模后还需要判断当前队列的broker是否可用。上面代码中我们可以看到发送消息后，不管成功还是失败都会更新一个叫做Item的状态，这个Item指的就是broker，rmq根据此次消耗的时间来更新该broker不可用的时间，以此达到对不稳定broker的规避。具体代码可看·MQFaultStrategy·。 消息接收上面说到BrokerController时，我们未贴出关于broker的NettyServer关于Processor的注册部分。在这部分中，注册了不同的Processor： SendMessageProcessor 处理client发送的消息 PullMessageProcessor 处理client来拉取消息 QueryMessageProcessor 处理对消息的查询 EndTransactionProcessor 处理事务消息 … 这些Processor分别处理不同的RequestCode。我们这次关心的是SendMessageProcessor。 处理的流程比较简单，这里只列出基本流程，可从SendMessageProcessor#processRequest看起。 检查broker是否可以对外提供服务（是否到了配置的对外服务时间） 消息合法性校验、broker是否可写、消息写入队列是否存在等检查 如果是消费失败重试消息则处理其是否要进入死信队列 转换请求信息封装为MessageExtBrokerInner 将MessageExtBrokerInner发给MessageStore进行持久化 处理MessageStore返回的结果，并根据结果用BrokerStatsManager做统计更新 封装相应信息并返回。 consumer与broker韩梅梅终于要收到信了。和现实一样，要么邮递员送给你，要么你自己上邮局去取信。这两种方式对应了rmq中的两种去消息方式：push（DefaultMQPushConsumer）和pull（DefaultMQPullConsumer）。这两种方式在定义上是有区别的，但实现上实际都是pull，只是对pull的处理不同。说到这里就不得不提长轮询了，pull方式我们客户端需要自己起一个线程定时去broker拉取信息，当broker没有消息可消费时立刻返回；push方式与pull流程一致，但是broker对其请求处理不同，当broker此刻无消息可消费时，broker会hold住当前请求，直到有消息返回或者到了超时时间返回。戳这里（–&gt;长轮询–&lt;和–&gt;长轮询进阶–&lt;）更深入了解长轮询，感谢伟大的互联网让信息容易共享。 此处以push模式下的MessageListenerConcurrently消费策略来梳理下获取消息的流程。DefaultMQPushConsumer相比DefaultMQProducerImpl多启动了几个服务：负载均衡服务（consumer平均分配队列）、维护offset服务、消息消费服务（consumeMessageService）。 12345678910111213141516// DefaultMQPushConsumerpublic synchronized void start() throws MQClientException &#123; // 省略配置检查及服务的启动 // 更新订阅topic信息 this.updateTopicSubscribeInfoWhenSubscriptionChanged(); // 每个topic随机选取一个broker检查subscription语法是否正确，请求code：RequestCode.CHECK_CLIENT_CONFIG this.mQClientFactory.checkClientInBroker(); // 向broker发送心跳，心跳携带client相关信息 this.mQClientFactory.sendHeartbeatToAllBrokerWithLock(); // 进行负载均衡，默认策略为`AllocateMessageQueueAveragely`，调整完后发起第一个pullRequest this.mQClientFactory.rebalanceImmediately();&#125; consumer定时拉取服务是在MQClientInstance中启动的一个叫做pullMessageService（PullMessageService）的定时服务，这个服务监听在一个pullRequestQueue队列上，当有拉取请求时，根据PullRequest选取对应分组的DefaultMQPushConsumerImpl进行拉取。 123456789public class PullRequest &#123; private String consumerGroup; private MessageQueue messageQueue; private ProcessQueue processQueue; private long nextOffset; private boolean lockedFirst = false; // ...&#125; PullRequest中有两个Queue，messageQueue是指要从broker哪个队列拉数据，ProcessQueue是拉数据成功后存放数据的队列。有了processQueue便可以做一些简单的流控，目前可以根据processQueue的消息数量或者消息的大小来决定是否停止本次拉取，并设置下次拉取的延迟而不是立即开始下次拉取。如果流控通过，consumer开始通过pullAPIWrapper向broker拉去信息，拉取成功后提交一个消费任务（默认非CONSUME_MESSAGE_DIRECTLY，如果此时线程池等待队列已满，任务延迟提交），消费任务回掉我们注册的listener，消息至此投递完成。 投递完成后，消费的结果怎么处理？我们刚提到ProcessQueue可以进行流控，那么合适出队以消费的消息？消费失败又需要做什么处理？这里不在展开，可见ConsumeMessageConcurrentlyService类中。 除了怎么去消费消息外，对consumer而言还有另外一个需要解决的问题：怎么给采用CLUSTERING方式的消费群组成员平均分配队列？答案在AllocateMessageQueueAveragely中，该策略保证消息队列被平均分配给同消费组内的消费者（图片来源）。 消息存储数据的落盘、存储、数据结构、目录结构这些请戳–&gt;broker的数据持久化&lt;– 源代码入口 CommitLog#putMessage(final MessageExtBrokerInner msg)重要的一些基础 MappedFile-Java、Java NIO、Btree 此处贴上一张关于broker数据结构及流转的图，更直观来看他的数据结构流向（图片来源）。 broker与broker（HA）broker有这几种角色ASYNC_MASTER、SYNC_MASTER、SLAVE，消息肯定都是写到MASTER上的，然后同步给SLAVE。 同步的方式分为SYNC和ASYNC两种： ASYNC，消息写完后就直接返回，后台线程去做同步的操作; SYNC，等到同步完成后返回。 这两种方式也称作异步复制和同步双写。HA的整个过程只在store模块做的，是基于JDK的nio来写的，没有依赖remoting模块。 除此之外，broker启动时，如果当前broker是SLAVE，则会启动一个定时任务来同步topic等信息。 1234567// SlaveSynchronizepublic void syncAll() &#123; this.syncTopicConfig(); this.syncConsumerOffset(); this.syncDelayOffset(); this.syncSubscriptionGroupConfig();&#125; 结语以上只是对整体架构和主流成的简单认知，关于其中的细节问题，就需要我们带着疑问去看源码了。 问题：怎么处理定时消息？消费失败的消息怎么处理？链接是否像dubbo那样复用？broker的数据结构是怎样的？broker怎么保证存储高吞吐?broker怎么过滤消息？ “古人学问无遗力，少壮工夫老始成。纸上得来终觉浅，绝知此事要躬行。” – 陆游《冬夜读书示子聿》 以上贴出源代码基于incubator-rocketmq release-4.3.2版本，为了方便均有删减改，但不影响实际流程。 小生不才，以上如有描述有误的地方还望各位不吝赐教 !^_^！ 参考资料RocketMQ 原理简介 rocketmq 用户指南 RocketMQ 最佳实践 译-apache-rocketmq用户指南 誓嘉(rmq作者)文档 RocketMQ 运维指令 rmq源码系列 RocketMQ源码学习(三)-Broker(与Producer交互部分) Java NIO-阅读笔记及总结 深入浅出MappedByteBuffer rmq数据结构转换图片来源]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JMH(Java Microbenchmark Harness)笔记]]></title>
      <url>%2F2018%2F10%2F23%2F%E7%AC%94%E8%AE%B0-JMH-Java-Microbenchmark-Harness%2F</url>
      <content type="text"><![CDATA[看开源项目时，时不常遇到一个叫做benchmark的目录，此时脑子停滞，一眼带过，最近一次看到就顺手问了下谷大哥，发现benchmark还是个挺有意思的东西。 基准测试是什么基准测试是指通过设计科学的测试方法、测试工具和测试系统，实现对一类测试对象的某项性能指标进行定量的和可对比的测试。例如，对计算机CPU进行浮点运算、数据访问的带宽和延迟等指标的基准测试，可以使用户清楚地了解每一款CPU的运算性能及作业吞吐能力是否满足应用程序的要求；再如对数据库管理系统的ACID（Atomicity, Consistency, Isolation, Durability, 原子性、一致性、独立性和持久性）、查询时间和联机事务处理能力等方面的性能指标进行基准测试，也有助于使用者挑选最符合自己需求的数据库系统。通过基准测试我们可以了解某个软件在给定环境下的性能表现，对使用者而言可以用作选型的参考，对开发者而言可以作为后续改进的基本参照。 JMH是什么JMH（Java Microbenchmark Harness）是Java用来做基准测试一个工具，该工具由openJDK提供并维护，测试结果可信度较高，该项目官方还在持续更新中。 下面只是JMH简单描述，正所谓“纸上得来终觉浅，绝知此事要躬行”，要想全面了解还得读完官方给出的Demo或者看我的翻译注解版本的官方Demo。 已经给标题加链接，直接戳标题即可闪现到例子。官方例子有37个，这里只列出了梗概。 举个例子功能入门第一课，Hello World！ 12345678910111213141516171819public class JMHSample_01_HelloWorld &#123; @Benchmark public void wellHelloThere() &#123; // this method was intentionally left blank. &#125; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() // 指明本次要跑的类 .include(JMHSample_01_HelloWorld.class.getSimpleName()) // fork JVM的数量 .forks(1) .build(); new Runner(opt).run(); &#125;&#125; 看下输出： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# JMH version: 1.21# VM version: JDK 1.8.0_74, Java HotSpot(TM) 64-Bit Server VM, 25.74-b02# VM invoker: /Library/Java/JavaVirtualMachines/jdk1.8.0_74.jdk/Contents/Home/jre/bin/java# VM options: -javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=51264:/Applications/IntelliJ IDEA.app/Contents/bin -Dfile.encoding=UTF-8# 预热配置# Warmup: 5 iterations, 10 s each# 检测配置# Measurement: 5 iterations, 10 s each# 超时配置# Timeout: 10 min per iteration# 测试线程配置# Threads: 1 thread, will synchronize iterations# 基准测试运行模式# Benchmark mode: Throughput, ops/time# 当前测试的方法# Benchmark: com.cxd.benchmark.JMHSample_01_HelloWorld.wellHelloThere# 运行过程的输出# Run progress: 0.00% complete, ETA 00:01:40# Fork: 1 of 1# Warmup Iteration 1: 2924740803.993 ops/s# Warmup Iteration 2: 2916472711.387 ops/s# Warmup Iteration 3: 3024204715.897 ops/s# Warmup Iteration 4: 3051723946.668 ops/s# Warmup Iteration 5: 2924014544.301 ops/sIteration 1: 2909665054.710 ops/sIteration 2: 2989675862.826 ops/sIteration 3: 2965046292.629 ops/sIteration 4: 3020263765.220 ops/sIteration 5: 2929485177.735 ops/s# 当前方法测试结束的报告Result &quot;com.cxd.benchmark.JMHSample_01_HelloWorld.wellHelloThere&quot;: 2962827230.624 ±(99.9%) 171803440.922 ops/s [Average] (min, avg, max) = (2909665054.710, 2962827230.624, 3020263765.220), stdev = 44616808.022 CI (99.9%): [2791023789.702, 3134630671.547] (assumes normal distribution)# Run complete. Total time: 00:01:41REMEMBER: The numbers below are just data. To gain reusable insights, you need to follow up onwhy the numbers are the way they are. Use profilers (see -prof, -lprof), design factorialexperiments, perform baseline and negative tests that provide experimental control, make surethe benchmarking environment is safe on JVM/OS/HW level, ask for reviews from the domain experts.Do not assume the numbers tell you what you want them to tell.# 所有benchmark跑完后的最终报告Benchmark Mode Cnt Score Error UnitsJMHSample_01_HelloWorld.wellHelloThere thrpt 5 2962827230.624 ± 171803440.922 ops/s 上面的报告显示，我们用1个线程对吞吐量测量，测量和预热分别迭代了5次，最终得出的Score（ops/s）是2962827230.624 ± 171803440.922，测量过程中没有出现Error。 测试控制测试输出结果中开头的配置项都是我们可以通过注解、编程或者命令行的方式来控制的。它可以具体到每个benchmark。 @Fork 需要运行的试验(迭代集合)数量。每个试验运行在单独的JVM进程中。也可以指定(额外的)JVM参数。 @Measurement 提供真正的测试阶段参数。指定迭代的次数，每次迭代的运行时间和每次迭代测试调用的数量(通常使用@BenchmarkMode(Mode.SingleShotTime)测试一组操作的开销——而不使用循环) @Warmup 与@Measurement相同，但是用于预热阶段 @Threads 该测试使用的线程数。默认是Runtime.getRuntime().availableProcessors() 测试维度通过JMH提供的工具我们可以轻松的的获得某个功能的吞吐量、平均运行时间、冷启动等指标的数据。 这些输出结果通过@BenchmarkMode注解来控制，它的值定义在枚举类org.openjdk.jmh.annotations.Mode中。 @BenchmarkMode接受的参数是一个Mode数据，也就是说，我们可以指定一个或者多个Mode，测试时会把我们指定的模式依次运行，打印出结果。 12345678910111213141516171819202122232425262728293031323334353637383940public enum Mode &#123; /** * &lt;p&gt;Throughput: operations per unit of time.&lt;/p&gt; * * 计算一个时间单位内操作数量 */ Throughput("thrpt", "Throughput, ops/time"), /** * &lt;p&gt;Average time: average time per per operation.&lt;/p&gt; * * 计算平均运行时间 */ AverageTime("avgt", "Average time, time/op"), /** * &lt;p&gt;Sample time: samples the time for each operation.&lt;/p&gt; * * 计算一个方法的运行时间(包括百分位) */ SampleTime("sample", "Sampling time"), /** * &lt;p&gt;Single shot time: measures the time for a single operation.&lt;/p&gt; * * 方法仅运行一次(用于冷测试模式) * 或者特定批量大小的迭代多次运行(具体查看的“`@Measurement“`注解)——这种情况下JMH将计算批处理运行时间(一次批处理所有调用的总时间) */ SingleShotTime("ss", "Single shot invocation time"), /** * Meta-mode: all the benchmark modes. * 所有模式依次运行 */ All("all", "All benchmark modes"), ; // 省略...&#125; 数据的共享测试的时候，我们可能需要向测试方法传入若干参数，这些参数还可能需要不同的隔离级别：每个线程单独一份还是每个benchmark一份还是一组线程共享等。 这些参数有以下要求： 有无参构造函数(默认构造函数) 是公共类 内部类应该是静态的 该类必须使用@State注解 参数必须是对象，因为@State被定义为ElementType.TYPE，即：可以用来注解类、接口或者枚举。 @State接受单个配置值Scope。 1234567891011121314151617181920212223242526public enum Scope &#123; /** * &lt;p&gt;Benchmark state scope.&lt;/p&gt; * * 运行相同测试的所有线程将共享实例。 * 可以用来测试状态对象的多线程性能(或者仅标记该范围的基准)。 */ Benchmark, /** * &lt;p&gt;Group state scope.&lt;/p&gt; * * 实例分配给每个线程组(查看后面的测试线程组) */ Group, /** * &lt;p&gt;Thread state scope.&lt;/p&gt; * * 实例将分配给运行给定测试的每个线程。 * */ Thread,&#125; 数据的准备数据的准备像极了JUnit和TestNG的方式，即：在测试开始前后分别进行处理。在JMH中对应到@Setup和@TearDown，我们可以在被进行标记的方法中对数据进行处理，并且处理的耗时不被记入正常测试的时间，也就是说不会影响我们测试结果。 @Setup和@TearDown分别接受单个配置值Level。 12345678910111213141516171819202122232425public enum Level &#123; /** * Trial level: to be executed before/after each run of the benchmark. * * 在每个benchmark之前/之后运行 */ Trial, /** * Iteration level: to be executed before/after each iteration of the benchmark. * * 在一次迭代之前/之后(一组调用)运行 */ Iteration, /** * Invocation level: to be executed for each benchmark method execution. * * 每个方法调用之前/之后 * 该方式较为复杂，在没有搞清楚之前，不要使用。 */ Invocation, ;&#125; 测试线程组我们可以通过指定线程组的的方式来模拟一些场景，比如：生产-消费。这种场景下生产消费的线程数量往往是不一致的，通过@Group和@GroupThreads我们可以很轻松的制造出这种场景。 具体的使用说明例子中说的很详细 —-传送门—-&gt; JMHSample_15_Asymmetric 编译器的控制我们知道编译器在编译时会做一些优化，这个例子展示了如何用@CompilerControl来控制编译对方法内敛优化的控制。 12345678910111213141516171819202122232425262728293031323334353637383940414243public @interface CompilerControl &#123; /** * Compilation mode. */ enum Mode &#123; /** * Insert the breakpoint into the generated compiled code. */ BREAK("break"), /** * Print the method and it's profile. */ PRINT("print"), /** * Exclude the method from the compilation. * 不编译该方法 —— 用解释替代。 */ EXCLUDE("exclude"), /** * Force inline. * 要求编译器内嵌该方法。 */ INLINE("inline"), /** * Force skip inline. * 该方法不能被内嵌。用于测量方法调用开销和评估是否该增加JVM的inline阈值 */ DONT_INLINE("dontinline"), /** * Compile only this method, and nothing else. * 仅编译被注解的方法，其他的不编译。 */ COMPILE_ONLY("compileonly"),; &#125;&#125; 基准测试中建议编译器还有其他一些优化行为，常见的包括（更多参见）：死代码消除（DCE）、方法内敛（method inline）、循环优化、常量折叠。 方法内敛可以用上面提到的注解做控制，但更多的需要我们在些测试时采用一些小技巧规避，比如：DCE可以根据情况采用Blackhole消费输出结果。 测试前后较重的处理放在@Setup和@TearDown中 注意DCE（死代码消除） 不出现循环被编译器优化，具体建议参考JMHSample_34_SafeLooping 测试必须为fork，fork是分离出来子进程进行测试，@fork(2)含义为顺次（one-by-one）fork出子进程来测试 使用@fork多次fork测试，减少运行间差异 多线程测试时参考JMHSample_17_SyncIterations 对非循环方法需要测量冷启动的时间消耗，参考JMHSample_26_BatchSize 可以通过profiler获得基准测试时JVM的相关信息，比如栈、gc、classloader。参考JMHSample_35_Profilers 在使用profiler时遇到no tty present and no askpass program specified错误是因为帐号并没有开启sudo免密导致的。 通过以下步骤可解决，但测试完成后安全起见建议删除：sudo visudo；在文件最后追加 userName ALL=(ALL) NOPASSWD:ALL 知识点记录编译优化常见的编译器优化包括（更多参见）：死代码消除（DCE）、方法内敛（method inline）、循环优化、常量折叠。 方法内敛许多优化手段都试图消除机器级跳转指令（例如，x86架构的JMP指令）。跳转指令会修改指令指针寄存器，因此而改变了执行流程。相比于其他汇编指令，跳转指令是一个代价高昂的指令，这也是为什么大多数优化手段会试图减少甚至是消除跳转指令。内联是一种家喻户晓而且好评如潮的优化手段，这是因为跳转指令代价高昂，而内联技术可以将经常调用的、具有不容入口地址的小方法整合到调用方法中。Listing 3到Listing 5中的Java代码展示了使用内联的用法。 Listing 3. Caller method123int whenToEvaluateZing(int y) &#123; return daysLeft(y) + daysLeft(0) + daysLeft(y+1);&#125; Listing 4. Called method123456int daysLeft(int x)&#123; if (x == 0) return 0; else return x - 1;&#125; Listing 5. Inlined method123456789int whenToEvaluateZing(int y)&#123; int temp = 0; if(y == 0) temp += 0; else temp += y - 1; if(0 == 0) temp += 0; else temp += 0 - 1; if(y+1 == 0) temp += 0; else temp += (y + 1) - 1; return temp;&#125; 在Listing 3到Listing 5的代码中，展示了将调用3次小方法进行内联的示例，这里我们认为使用内联比跳转有更多的优势。 如果被内联的方法本身就很少被调用的话，那么使用内联也没什么意义，但是对频繁调用的“热点”方法进行内联在性能上会有很大的提升。 此外，经过内联处理后，就可以对内联后的代码进行进一步的优化，正如Listing 6中所展示的那样。 Listing 6. After inlining, more optimizations can be applied12345int whenToEvaluateZing(int y)&#123; if(y == 0) return y; else if (y == -1) return y - 1; else return y + y - 1;&#125; unrolled loop 循环展开12for (i = 1; i &lt;= 60; i++) a[i] = a[i] * b + c; 可以如此循环展开： 123456for (i = 1; i &lt;= 20; i+=3)&#123; a[i] = a[i] * b + c; a[i+1] = a[i+1] * b + c; a[i+2] = a[i+2] * b + c;&#125; 分支预测底层对循环中判断的优化。简单理解，对执行的循环判断做采样，根据采样来预测下一个判断会走到哪个分支中。 参考这篇文章—-&gt;深入理解CPU的分支预测(Branch Prediction)模型&lt;—-做进一步了解。 小生不才，以上如有描述有误的地方还望各位不吝赐教 !^_^！ 参考资料编译器的优化方法内敛什么是基准测试JMH官方DemoJHM官网JMH简介-译文 —-&gt; 英文原文]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[丢了眠的精神病]]></title>
      <url>%2F2018%2F08%2F28%2F%E6%9D%82%E5%AE%B6-%E4%B8%A2%E4%BA%86%E7%9C%A0%E7%9A%84%E7%B2%BE%E7%A5%9E%E7%97%85%2F</url>
      <content type="text"><![CDATA[失眠这件事已经扰了我很久，看样子还要随我走很长时间。翻到以前失眠时随手拼凑的梦话，觉得有意思，原来失眠逼得我作文不写谎话，想起那些年为完成作文编的故事，唉！实在是对不起小明、小红等等这些素未谋面的伙伴，原谅我吧。 三分自留地（2015-4-6 14:10）年后杭城的雨来的过于任性，去年回杭时同样是落雨，不过后来很快也就停了，今年不然，断续了个把月直到清明，还在淅淅沥沥的让人看不到头。 周末瞎逛的路上，惊异发现路边无名小花开的一片耀眼，与其说是看到，不如说是嗅到，鼻炎还是带来一点好处，那花香使我头痛，这才有心去寻得竹林边的无名花儿。哦，细雨是带着春来了，惊雷也是唤这春来了，一静一动，提醒我这愚钝的精神病。开始不再厌烦无止境的雨天，反倒生出怜惜，盼着她多呆些日子。也开始留心路过的景象：舞动的柳絮很长了，浓郁的冬青中杂了淡色的新生叶子，架子上趴着的藤条用新绿羞涩遮住骨感的身躯······春雨的洗礼，世界挂满晶莹的水珠，映射给我满眼生机。幸万物生，福苍生得，自然的福气。美景住进心里三分自留地，这不过是一瞬的事情。 一个人溜达到了还是无聊的，宅习惯了，外出的目的性较强，漫无边境的闲走，难以接受。往回走到住处，天已经黑下来。精神病又要失眠了。 睡觉，是件颇为不易的事情，常常没有合入正常人的节奏，落上半拍，往往不在点上。失眠这事我琢磨了有一阵子，到现在还在冥想，得不出些结论，又或得出点门道，翻个身就一股脑还给灵感先生，思维一丝不挂，就剩下清醒。 楼下不足20米，便是吵杂的街道，这街道从公路边一路延伸到社区深处，街两边紧凑排开一家家小店：卖饭的、卖肉的、卖菜的······街道有着正常人的律动：日出而作日入而息。恰恰我是个喜好失眠的人，又偏偏喜寂，所以爱上这午夜的街道。夜里的街道并不死寂，总有些店家在夜里开着，也有些店家招牌的霓虹灯彻夜亮着，时不时还会有匆匆夜路的过客，脚步踢踏出不属于静夜的节奏，这画面给昏黄路灯添了活力和色彩。街边时常会有通宵的烧烤和关东煮，能在凌晨下去吃点喜欢且热乎的东西，知足满满溢出三分自留地，失眠带来的焦灼被这满足冲淡不少。 拉开窗帘，摘掉耳机，玻璃窗早又泛起白色雾气，雾气凝结成珠，划破密闭的空气。雨滴随风轻打着窗子，像是湖边长椅上相互依偎恋人的情思轻语，连绵曼妙，似有若无般令我羡慕不已。 人间轻灵的四月天！心中这片三分自留地，你觉得到吗？ 精神病睡前史（2015-1-2 21:17）屋子在五楼，两扇大窗子，看上去敞亮，一扇向东，一扇面北。夏天阳光满屋，冬天丁点阳光不见，向东的窗子一大早有太阳，一般头天晚上拉上帘子，面北那扇，因为距另一幢房阳台极近，一举一动看的清楚，索性拉上帘子不再打开。东窗下一张桌子，凌乱放些书和日用品，除了前月买的两本书，别的大半年没动过，完全无视在桌角冷宫，陪伴他们的是冲动消费的一盆仙人掌，直到现在我还不确定它是否塑料制品。屋中两张小床，垂直了桌子放着，一张三合板材质，床板在刚搬进来的时候就已经有问题了，终于还是破了个洞，还一张是两长凳支起的一个中间编有麻网的临时床。冬天用临时的，夏天就睡在三合板床上。 三合板床尾是洗手间，勉强容下一人，马桶边上有个只出室温水的淋浴头，夏天可冲凉，冬天就是个麻烦的摆设。临时床尾摆一箱子，一米来高，没什么大用，衣服不多，常穿的就那几件，箱子取来麻烦，都随手扔在没用的那张床上。周一到周六，常乱的有种新秩序，周日实在看不过，提着性子收拾一手，周而复始，再懒些时，一两周不管也常有。 箱子靠边墙上有个插孔，是这个屋子的要害，全靠它照明、烧水甚至煮饭，插孔下依次摆开电磁炉、烧水壶、落地灯。 电磁炉除了偶尔嘴馋并且碰上勤快的时候涮些丸子、羊肉什么的，没别的大用，也属冲动消费之列。 吊顶上的唯一饰品—电棒，也与上月中旬罢工，房东给我一个落地灯凑合，也就是上面提到的那个，哪个神经病会冲动到去买个落地灯，还是工用的。本来说要修，就目前形势来看，房东多半是忘了，不过，那落地灯我还是很喜欢的，虽然这灯没有开关挺麻烦，但习惯也就好了，看中的是那灯给屋子渲染出不可言语的氛围，像小时候打麦场晚上亮灯那样，两张床变成了麦秆剁，躺上去，吊顶上夏夜被我摁死在上面的飞虫当做是夜空星点，塞上耳机屏蔽楼下嘈杂，熟悉的律动，只一瞬，睡前的精神病旅程便开始了。 睡前迷离，脑海浮想联翩，尽是些云深不知处，当时已惘然的闲篇，闲篇里自导众演，人物故事相互穿插，纷扰杂乱，最终裹成一团，飞到另一个世界去了，恍如回望云天里的仙阙，又像捉住了一个荒诞的古代的梦。原来，记忆力差强人意，似睡半醒间的意识完全留不住，就算留下些，身陷其中的又有几个说的清呢，就算说得清，又有几个讲得全呢。自然，精神病入睡前的世界也就不可言喻，是好是坏，只能自知，不为外人所道。 老话讲：演戏的是疯子，看戏的是傻子。傻子，准备睡了吗！ 痴人呓语（2014-11-21 01:14）时间和空间组成原生态的生活，时间承载着空间，空间赋予时间存在的意义。给空间打上时间戳，埋藏给下一个自己，收到的便是憧憬；给空间打上时间戳，邮寄给上一个自己，送达的称为回忆；给空间打上时间戳，赠阅给现在的自己，得到的叫做现实。于是，我在现实中憧憬那些回忆的点滴，在回忆中回忆回忆中的自己。穷其根本，实则自己愚弄自己，纷扰的逻辑不过想掩饰不堪一击的脆弱神经。 不懂星座之类云云，只迷信“因果报应总有时”，做不得一些违背意愿的事情，那让我感到恶心，通俗来讲就是个性，就是矫情，就是一种病，还病得不轻，得治！ 俗话讲“人活一口气“，着实不敢与之苟同，时间你我本都一样，若再追求同款主打空间，为了那口气活着（虽然我也不十分清楚到底是什么），实在觉得别扭，那岂不是要千篇一律，节制到没有新意。真是懒！没有境界的瞎懒！ 失眠到头疼，东拉西扯，满篇尽是胡扯，供消遣娱乐。 2014年11月21日凌晨一点于杭州 执迷于此（2014-8-8 22:24）突然想写点东西，恰巧刚刚闪现了她，就叫《执迷于此》吧。 很随意的躺在床上，想着谁，捋一捋有关谁的点滴，若干年前溜进我生活的谁，穿插着青少年的记忆，谁让我习惯了写日记，谁让我痴迷上看传记，那个谁终究是个回忆，而谁，依然在这里，我有个担心，害怕有天谁会随谁悄然无息，我明白是应该说服自己，不可能的事情不要再提，我问我自己：我能做到吗？我会泰然吗？我会祝愿吗？我告诉自己：一切随它去。 那年夏天毕业，一支火柴烧掉与日记相关的瞬息，流星雨响起，浮现出懵懂脸庞，对白羞涩言语：我喜欢你。哦，对不起，原来，那是在信里。 暖暖在秋天，无意穿插之中，现在仍旧延续，幼稚脑袋思考人生哲理，逗趣逗趣太逗趣。千篇一律，思恋如一，寸守约定，愿你如你所愿，盼你如你所盼，当幸福来敲门，海枯石烂。 躲藏在人群中，怀揣着对谁的感觉，像窝藏了赃物的窃贼，不敢表露，送谁满天繁星，甘愿做不起眼的配角，就算老天把主角换作是我，又能够演出怎样的幸福呢，只让你看到眼泪流过之后，笑着的我。 尴尬至极，言语到此为止，到此为始，先就这样吧，谁知道什么时候又想起来，然后又继续写下去。 神仙熬不过时间轮。现在便可继续。 别乡之余，总有惊喜不期而遇，哥哥们逗比风趣，是哪个酷爱喊畜生，哪个鄙夷这个就不是这么玩的，又是哪个常态处于3/4节拍拜拜而去，还有哪个愤骂不离他娘地，如斯随年流去，往事依稀，渐爱这座城市，我开始静心倾听，找出一个人的狂欢，那是美丽的孤单。 执迷于此，千言万语，无非一句：他娘地，畜生，都是畜生，这个就不是这么玩的，拜拜。 想这样（2010-11-26 21:39）从深秋到初冬，北方没有落下一滴雨。漫步在诺大的湖边，枯委柳树的树皮就像是老农民粗糙到裂缝的手。突然想，能不能这样：冬风从南刮来，那么北方冬天不再寒冷；花儿在十二月怒放，那么北方冬天不再肃杀；雪花融化成雨滴，那么北方冬天不再严寒… …这仅仅是“我想”！多么羡慕南飞雁，成群的飞向南方，那里温暖的阳光照耀大地，没有寒冷与北风，似乎是舒适的摇篮爱抚着新生命。呵呵，有点喜欢南方了，但更喜欢的还是北方，棱角分明的季节，总是给人们意想不到的天气，北方人一年里体验的最为充实：春天，积雪融尽，树木初露嫩芽，草色遥看近却无；夏天，深绿欲滴的叶子，尽情媲美的花朵儿，展现着生命的激情与活力；秋天，金黄色的季节，温和贴身的秋风送来一阵阵稻香，收获了；冬天，雪片毫不留情的洒向人间，覆盖整个大地，银装素裹。 多好的北方，虽然没有大海的深邃，却有着黄河的秉性。我喜欢！ 我，想这样、 你呢… …]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[内存伪共享测试及Java对像内存估算]]></title>
      <url>%2F2018%2F08%2F17%2F%E7%AC%94%E8%AE%B0-%E4%BC%AA%E5%85%B1%E4%BA%AB%E6%B5%8B%E8%AF%95%E5%8F%8AJava%E5%AF%B9%E5%83%8F%E5%86%85%E5%AD%98%E4%BC%B0%E7%AE%97%2F</url>
      <content type="text"><![CDATA[引入之前每次入门Disruptor对此部分总是泛泛看过，主要关注点在如何应用上，急于按照文档完成第一个Demo，怠慢了其实现的核心思想及其要解决的主要问题，导致虽然入门过几次Disruptor，仍对其认识十分浅薄。最近有空再次入门Disruptor时，不出意外的又遇到了难以规避的问题–内存的伪共享。 前车之鉴，后事之师。这次花了一些时间先去了解下久闻其名的伪共享。 Java对象内存估算要想先搞清楚伪共享问题，就先需要搞清楚使用的语言（Java）对实例对象的内存布局以及如何来检测估算实例的内存占用。 InstrumentationInstrumentation是Java SE5开始引入的，我们可以通过它来检测Java对象的大小，当然这只是Instrumentation强大功能之一，还可以通过Instrumentation增加自定义类转换器，对Class进行增强或者替换，只是我们在这里并不关心。 找到了检测工具后怎么去使用呢？ 首先，要获取Instrumentation实例。Instrumentation由虚拟机来实例化和维护的，可以通过两种方式来获取： 当JVM以指示一个代理类的方式启动时，将传递给代理类的premain方法一个Instrumentation实例。 当JVM提供某种机制在JVM启动之后某一时刻启动代理时，将传递给代理代码的agentmain方法一个Instrumentation实例。 这里通过方法一来做。 步骤1. 创建一个用来检测对象大小的工具类，并在该类中声明实现premain方法； 1234567891011121314151617public class ObjectSizeUtil &#123; private static Instrumentation inst; public static void premain(String agentArgs, Instrumentation instP) &#123; inst = instP; &#125; public static long shallowSizeOf(Object o) &#123; if(inst == null) &#123; throw new IllegalStateException("Can not access instrumentation environment.\n" + "Please check if jar file containing SizeOfAgent class is \n" + "specified in the java's \"-javaagent\" command line argument."); &#125; return inst.getObjectSize(o); &#125;&#125; 步骤2. 利用javaagent方式启动来获取Instrumentation实例。这里以IDEA为例使用maven插件的方式来配置javaagent。 插件名 功能简介 maven-jar-plugin maven 默认打包插件，用来创建 project jar，可参考下一些开源软件项目对该插件的使用，比如：dubbo maven-shade-plugin 用来打可执行包，包含依赖，以及对依赖进行取舍过滤，可参考下一些开源软件项目对该插件的使用，比如：dubbo maven-assembly-plugin 支持定制化打包方式，更多是对项目目录的重新组装，可参考下一些开源软件项目对该插件的使用，比如：dubbo 1234567891011121314151617181920212223 &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;transformers&gt; &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt; &lt;manifestEntries&gt; &lt;Premain-Class&gt;com.cxd.jvm.jml.ObjectSizeUtil&lt;/Premain-Class&gt; &lt;/manifestEntries&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 配置完成后使用maven进行打包。 步骤3. 在启动脚本中增加代理类路径，我的是-javaagent:/Users/childe/Documents/workspace/goodGoodStudy/target/childe-1.0-SNAPSHOT.jar 完成上面的操作后，基本工具就完成了，接下来就使用Instrumentation来帮助我们获取对象内存大小。 对象大小检测在估算内存大小时，会遇到类似Retained heap和Shallow heap两个概念，Shallow heap表示一个实例自身占用堆空间的大小，而Retained Heap不仅包含自身占用堆空间还包括自身引用其他对象的Shallow heap。在MAT中Retained Heap是一个对象被GC回收时，能够释放其所有引用的Shallow Heap的总和。 在开始检测前，先回顾下Java中元类型的大小。 类型 大小（字节byte） byte 1 short 2 int 4 long 8 float 4 double 8 char 2 boolean 大小没有明确指定，和虚拟机具体实现有关 一个类的实例对象在内存中这么分布：对象头 + 实例数据 + 填充。对象头里面保存了对象相关的诸如GC标记、锁标记等一些必要信息，实例数据就是对象的各个属性，填充是为了让对象的大小为8的倍数。 在开启指针压缩（-XX:+UseCompressedOops）的情况下，测试了一些元类型的大小。 12345678910111213141516171819202122// 64位机器上reference类型占用8个字节，开启指针压缩后占用4个字节private static void primitiveTest() &#123; int integer = 90; // int 自身4byte // +UseCompressedOops Integer shallowSizeOf : 16 = 12(head) + 4(instance data) retainedSizeOf : 16 System.out.println("Integer shallowSizeOf : " + ObjectSizeUtil.shallowSizeOf(integer) + " retainedSizeOf : " + ObjectSizeUtil.retainedSizeOf(integer)+ "\n"); long a = 100L; // long 自身8byte // +UseCompressedOops Long shallowSizeOf : 24 = 12(head) + 8(instance data) + 4(padding) retainedSizeOf : 24 System.out.println("Long shallowSizeOf : " + ObjectSizeUtil.shallowSizeOf(a) + " retainedSizeOf : " + ObjectSizeUtil.retainedSizeOf(a)+ "\n"); byte b = 1; // byte 自身1byte // +UseCompressedOops byte shallowSizeOf : 16 = 12(head) + 1(instance data) + 3(padding) retainedSizeOf : 16 System.out.println("byte shallowSizeOf : " + ObjectSizeUtil.shallowSizeOf(b) + " retainedSizeOf : " + ObjectSizeUtil.retainedSizeOf(b)+ "\n"); char c = '2'; // char 自身2byte // +UseCompressedOops char shallowSizeOf : 16 = 12(head) + 2(instance data) + 2(padding) retainedSizeOf : 16 System.out.println("char shallowSizeOf : " + ObjectSizeUtil.shallowSizeOf(c) + " retainedSizeOf : " + ObjectSizeUtil.retainedSizeOf(c)+ "\n");&#125; 当然，还有array、reference、String（特别的）类型内存大小的测试，这里不一一列出，全部代码-&gt;请戳这里-&lt;。 伪共享缓存说到伪共享就不得不提一下CPU和高速缓存。我们知道，CPU的计算速度时远远大于磁盘的读写速度的，为了缓解两者之间的速度差，就有了内存，CPU计算时需要的数据先放到内存中，CPU直接操作内存的数据而不是操作磁盘，内存又分成几部分：一级缓存（L1）、二次缓存（L2）、三级缓存（L3）、主存（Main Memory）。 如图所示，越靠近CPU的缓存速度越快，容量就越小。当CPU执行运算的时候，它先去L1查找所需的数据，再去L2，然后是L3（被单个插槽上的所有CPU核共享），最后如果这些缓存中都没有，所需的数据就要去主内存拿。走得越远，运算耗费的时间就越长。所以如果在做一些很频繁的事，就要确保数据在L1缓存中。 缓存行数据在缓存系统中是以缓存行（cache line）为单位存储的。缓存行是2的整数幂个连续字节，一般为32-256个字节。最常见的缓存行大小是64个字节。当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。 如上图，为了简化问题，把缓存表示成了一块。线程0和线程1会用到不同变量，它们在内存中彼此相邻，并驻留在同一高速缓存行。高速缓存行被加载到CPU0和CPU1的高速缓存中（灰色箭头）。尽管这些线程修改的是不同变量（红色和蓝色箭头），高速缓存行仍会无效(MSEI协议)，并强制内存更新以维持高速缓存的一致性。 那么，伪共享的存在到底对我们的程序有多大影响呢？我们做个-&gt;测试（戳我看源码）&lt;-看下。 以下测试数据环境：123456CPU 2.7 GHz Intel Core i5内存 8 GB 1867 MHz DDR3java version &quot;1.8.0_74&quot;Java(TM) SE Runtime Environment (build 1.8.0_74-b02)Java HotSpot(TM) 64-Bit Server VM (build 25.74-b02, mixed mode) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public final class FalseSharing implements Runnable &#123; /** * 每改变一次，要重新编译一次，不然跑出的时间差别不准确 */ public final static int NUM_THREADS = 1; public final static long ITERATIONS = 500L * 1000L * 1000L; private final int arrayIndex; private static VolatileLong[] longs = new VolatileLong[NUM_THREADS]; static &#123; for (int i = 0; i &lt; longs.length; i++) &#123; longs[i] = new VolatileLong(); &#125; &#125; public FalseSharing(final int arrayIndex) &#123; this.arrayIndex = arrayIndex; &#125; public static void main(final String[] args) throws Exception &#123; final long start = System.nanoTime(); runTest(); System.out.println("duration = " + (System.nanoTime() - start)); &#125; private static void runTest() throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; @Override public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; longs[arrayIndex].value = i; &#125; &#125; /** * 从不断上升的测试所需时间中能够明显看出伪共享的影响。没有缓存行竞争时，我们几近达到了随着线程数的线性扩展。 * 这并不是个完美的测试，因为我们不能确定这些VolatileLong会布局在内存的什么位置。它们是独立的对象。 * 但是经验告诉我们同一时间分配的对象趋向集中于一块。 * 所以你也看到了，伪共享可能是无声的性能杀手。 */ public final static class VolatileLong &#123; // 8byte public volatile long value = 0L; // 40byte comment out // 0. NUM_THREADS = 1 duration = 4587.402.329 // 1. NUM_THREADS = 2 duration = 5249.820.613 // 2. NUM_THREADS = 3 duration = 6329.667.147 // 3. NUM_THREADS = 4 duration = 7743.024.530 public long p1, p2, p3, p4, p5; // 无填充时 // 0. NUM_THREADS = 1 duration = 8213.558.562 // 0. NUM_THREADS = 2 duration = 15874.759.369 // 0. NUM_THREADS = 3 duration = 27350.752.730 // 0. NUM_THREADS = 4 duration = 27435.461.116 &#125;&#125; 上面代码在disruptor用户手册中文翻译中有所描述，查看了网络上的一些关于伪共享的文章，测试代码大同小异，但VolatileLong这个类中，网上大多写的是填充6个long类型的属性，但经过计算和测试，基于上述代码环境时填充5个才是合适的，大家在做实验的时候注意一下自己的环境问题，这也是为什么文章开头先介绍计算对象大小的原因。 在VolatileLong类的注解中我贴出了自己跑的几组数据，得出的结论和我们的分析时一致的，伪共享随着竞争的加剧，表现的更加明显。 总结在Java8之后，新增了注解@sun.misc.Contended，来避免伪共享的问题，在JDK的源码中也可以搜寻到她的身影，像我们常用的Thread和ConcurrentHashMap中都有使用该注解。 那么是不是我们编码时要特别关注伪共享这个问题呢？个人认为除非是真的是要追求卓越的性能表现，大可不必在普通的业务应用中过分考虑该问题。首先，这个问题很隐蔽，难以从系统层面上通过工具来探测伪共享事件；其次，做测试之前我也强调了自己的测试环境，这个问题实际上和环境也有一定的关系；另外，缓存资源是很珍贵的，这些事情我们毕竟不专业，如果滥用就造成了浪费；最后，像Intel这类的厂商在做设计时必然会对此类问题做优化。所以呢，我们只要在真正需要时去考虑这些问题就行了。 终于把Disruptor一大优势-避免伪共享的基础了解完了，可以继续了解它在RingBuffer中精巧的无锁设计了！ 小生不才，以上如有描述有误的地方还望各位不吝赐教 !^_^！ 参考disruptor用户手册中文翻译 软件包 java.lang.instrument 的描述 JVM源码分析之javaagent原理完全解读 Instrumentation新功能 java对象内存分布（Java Memory Layout） 怎样精确计算一个对象的内存大小 避免并发线程之间的假共享 扩展infoQ上《maven实战》作者关于Maven的介绍 Maven实战（七）——常用Maven插件介绍（上）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo源码-网络通信之提供者消费者通信]]></title>
      <url>%2F2018%2F05%2F29%2FDubbo%E6%BA%90%E7%A0%81-%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E4%B9%8B%E6%8F%90%E4%BE%9B%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E9%80%9A%E4%BF%A1%2F</url>
      <content type="text"><![CDATA[引入之前简单看过Dubbo基于SPI的“微核+插件”形式的架构模式，Dubbo因为这种架构模式使得扩展十分简单，另外Dubbo的框架分层十分清晰，看起源码来相对轻松不少。 在使用Dubbo时突然想到几个问题，Dubbo默认使用tcp长链接，消费者们可能同时发起调用，提供者是怎样处理这些请求的？消费者和生产者之间链接如何复用？消费者和提供者之间几个长链接？要搞清楚这几个问题要从Dubbo的exchange和transport层来找答案。 exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec Dubbo在这两层提供了不同的实现，信息交换层默认的是自定义协议dubbo，传输层默认使用Netty。下面的一些探讨以Dubbo的默认配置为基础进行，可能因为Dubbo版本不同其中一些类名或者方法名称不一致，但不影响对其本身的理解。可借由具体实现更好的理解Dubbo的抽象分层。 网络通信模型 Client表示应用具体的某个服务引用，每个服务的引用可根据提供者的配置（connections）建立多个链接。 Dubbo协议缺省每服务每提供者每消费者使用单一长连接。 在NettyServer中区分Boss和Woker的角色，Boss负责建立新链接，Woker负责链接建立后的IO工作，Woker的数量可由配置指定。 Dispatcher部分Dubbo按照不同场景提供了几种不同的实现，也可根据自身业务特点进行扩展。 all（默认） 所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等。 direct 所有消息都不派发到线程池，全部在IO线程上直接执行。 message 只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在IO线程上执行。 execution 只请求消息派发到线程池，不含响应，响应和其它连接断开事件，心跳等消息，直接在IO线程上执行。 connection 在IO线程上，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池。 上面提到的线程池指执行业务调用的线程池，此线程池可自行配置，默认为FixedThreadPool，大小为200，拒绝策略为AbortPolicyWithReport，队列为SynchronousQueue（不是很了解，后面再深入了解下）。上图中从ChannelEventRunner之后进入线程池。 服务启动Dubbo在解析service标签时会向外暴露服务，同时会检查打开网络服务。下图是dubbo服务暴露的时序图（摘自dubbo官网）。 在export阶段，会调用相应协议的export方法去完成invoker到exporter转化同时根据url（如下）中的address打开本地网络通信服务，默认启动netty服务。 123URL内容dubbo://10.1.87.93:20880/com.xx.IAdminUserLoginService?accesslog=/Users/childe/logs/access.log&amp;anyhost=true&amp;application=dmall-provider&amp;connections=4&amp;default.delay=-1&amp;default.retries=0&amp;default.service.filter=-monitor,-exception&amp;default.timeout=10000&amp;delay=-1&amp;dubbo=2.5.9&amp;generic=false&amp;interface=com.xx.IAdminUserLoginService&amp;loadbalance=roundrobin&amp;logger=slf4j&amp;methods=checkUser,getUserById,getUserByAccount&amp;monitor=dubbo%3A%2F%2Fzk1.daily.com%3A2181%2Fcom.alibaba.dubbo.registry.RegistryService%3Fapplication%3Ddmall-provider%26backup%3Dzk2.daily.com%3A2181%2Czk3.daily.com%3A2181%26dubbo%3D2.5.9%26file%3D%2FUsers%2Fchilde%2F.dubbo%2FDDD-soa.cache%26logger%3Dslf4j%26owner%3Dmazha%26pid%3D21874%26protocol%3Dregistry%26refer%3Ddubbo%253D2.5.9%2526interface%253Dcom.alibaba.dubbo.monitor.MonitorService%2526pid%253D21874%2526timestamp%253D1528104644722%26registry%3Dzookeeper%26timestamp%3D1528104644709&amp;owner=childe&amp;pid=21874&amp;revision=1.0.28&amp;side=provider&amp;timestamp=1528104644712&amp;uptime=1528104644716&amp;version=1.0.0.fsm.chen 启动netty服务的代码如下，分别有boss和worker线程池供netty来完成新链接的建立及网络IO。在创建NioServerSocketChannelFactory时我们可以通过Dubbo的配置（dubbo:protocol 中iothreads）来指定IO的线程数量。默认数量为CPU可用核数加1，但不能超过32个。 12345678910111213141516171819202122232425262728//NettyServerprotected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory("NettyServerBoss", true)); ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory("NettyServerWorker", true)); ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS)); bootstrap = new ServerBootstrap(channelFactory); //Dubbo采用组合的形式来组织自身Handler，在此部分断点可清楚的看到其最终组合出来的handler都包含了哪些 //NettyHandler-&gt;NettyServer(本身实现了Channelhandler接口)-&gt;MultiMessageHandler //-&gt;HeartbeatHandler-&gt;AllChannelhandler(根据选择的Dispatcher方式决定)-&gt;DecodeHandler //-&gt;HeaderExchangeHandler-&gt;DubboProtocol$XX(内部匿名实现了Channelhandler) final NettyHandler nettyHandler = new NettyHandler(getUrl(), this); channels = nettyHandler.getChannels(); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; public ChannelPipeline getPipeline() &#123; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this); ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast("decoder", adapter.getDecoder()); pipeline.addLast("encoder", adapter.getEncoder()); pipeline.addLast("handler", nettyHandler); return pipeline; &#125; &#125;); // bind channel = bootstrap.bind(getBindAddress());&#125; Provider完成一次业务请求操作流程如下： 接收数据-&gt;AllChannelHandler-&gt;ChannelEventRunner-&gt;DecodeHandler-&gt;HeaderExchangeHandler-&gt;DubboProtocol::reply-&gt;Invoker::invoke-&gt;Impl 除了IO及具体业务的执行过程，一次处理最重要的就是数据的交换啦，即：请求数据根据协议转成对应的数据结构，业务相应数据也要根据协议进行转换。 下面这段代码起的便是承上启下的作用，在这个步骤中，根据Request的信息构造出Response，并调用具体协议的reply实现获取业务相应数据。 在构造Response时回写入了Request的ID和Version。这是channel复用的关键。每个channel的Request都有一个唯一的ID，类型为long。 12345678910111213141516171819202122232425262728//HeaderExchangeHandlerResponse handleRequest(ExchangeChannel channel, Request req) throws RemotingException &#123; Response res = new Response(req.getId(), req.getVersion()); if (req.isBroken()) &#123; Object data = req.getData(); String msg; if (data == null) msg = null; else if (data instanceof Throwable) msg = StringUtils.toString((Throwable) data); else msg = data.toString(); res.setErrorMessage("Fail to decode request due to: " + msg); res.setStatus(Response.BAD_REQUEST); return res; &#125; // find handler by message class. Object msg = req.getData(); try &#123; // handle data. Object result = handler.reply(channel, msg); res.setStatus(Response.OK); res.setResult(result); &#125; catch (Throwable e) &#123; res.setStatus(Response.SERVICE_ERROR); res.setErrorMessage(StringUtils.toString(e)); &#125; return res;&#125; 服务引用Consumer启动时会从注册中心拉取订阅的Provider信息，并建立和Provider的链接，时序图如下（摘自dubbo官网）： Consumer的一次调用时序: DubboInvoker::doInvoke-&gt;NettyClient-&gt;AbstractClient::send-&gt;AbstractPeer-&gt;HeaderExchangeChannel::send-&gt;DefaultFuture::send-&gt;NettyChannel::send-&gt;DefaultFuture::received Consumer每发起一次调用时会构建出本次调用的Request，每个Request有唯一的ID。Dubbo中用AtomicLong实现ID，短时间内不会重复，所以可作为唯一标识。 1234567891011121314151617181920//HeaderExchangeChannelpublic ResponseFuture request(Object request, int timeout) throws RemotingException &#123; if (closed) &#123; throw new RemotingException(this.getLocalAddress(), null, "Failed to send request " + request + ", cause: The channel " + this + " is closed!"); &#125; // create request. // 无参构造方法中生成一个ID Request req = new Request(); req.setVersion("2.0.0"); req.setTwoWay(true); req.setData(request); DefaultFuture future = new DefaultFuture(channel, req, timeout); try &#123; channel.send(req); &#125; catch (RemotingException e) &#123; future.cancel(); throw e; &#125; return future;&#125; 123456789101112//Requestprivate static final AtomicLong INVOKE_ID = new AtomicLong(0);public Request() &#123; mId = newId();&#125;private static long newId() &#123; // getAndIncrement() When it grows to MAX_VALUE, it will grow to MIN_VALUE, and the negative can be used as ID return INVOKE_ID.getAndIncrement();&#125; Consumer发起调用后，使用DefaultFuture将异步变成同步，等待Provider的返回。当Provider有数据写回，我们将其转换为Response后，通过ID就可以知道通知哪个DefaultFuture来进行后续的处理了。这样就完成了channel的复用。 1234567891011121314151617//DefaultFuturepublic static void received(Channel channel, Response response) &#123; try &#123; DefaultFuture future = FUTURES.remove(response.getId()); if (future != null) &#123; future.doReceived(response); &#125; else &#123; logger.warn("The timeout response finally returned at " + (new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSS").format(new Date())) + ", response " + response + (channel == null ? "" : ", channel: " + channel.getLocalAddress() + " -&gt; " + channel.getRemoteAddress())); &#125; &#125; finally &#123; CHANNELS.remove(response.getId()); &#125;&#125; 疑问回答 消费者和提供者之间长链接？ 缺省是长链接，也可以使用其他的（自定义）的通讯方式。 消费者和提供者之间几个长链接？ 缺省每服务每提供者每消费者使用单一长连接，如果数据量较大，可以使用多个连接。 消费者和提供者之间连接如何复用？ 请求和应答消息使用同一个ID作为唯一标识来区分同一个链接内的不同请求。 官网释疑的几个问题 为什么要消费者比提供者个数多? 因 dubbo 协议采用单一长连接，假设网络为千兆网卡，根据测试经验数据每条连接最多只能压满 7MByte(不同的环境可能不一样，供参考，PS：1024Mbit=128MByte)，理论上 1 个服务提供者需要 20 个服务消费者才能压满网卡。 为什么dubbo协议不能传大包？ 因 dubbo 协议采用单一长连接，如果每次请求的数据包大小为 500KByte，假设网络为千兆网卡，每条连接最大 7MByte(不同的环境可能不一样，供参考)，单个服务提供者的 TPS(每秒处理事务数)最大为：128MByte / 500KByte = 262。单个消费者调用单个服务提供者的 TPS(每秒处理事务数)最大为：7MByte / 500KByte = 14。如果能接受，可以考虑使用，否则网络将成为瓶颈。 为什么采用异步单一长连接? 因为服务的现状大都是服务提供者少，通常只有几台机器，而服务的消费者多，可能整个网站都在访问该服务，比如 Morgan 的提供者只有 6 台提供者，却有上百台消费者，每天有 1.5 亿次调用，如果采用常规的 hessian 服务，服务提供者很容易就被压跨，通过单一连接，保证单一消费者不会压死提供者，长连接，减少连接握手验证等，并使用异步 IO，复用线程池，防止 C10K 问题。 小生不才，以上如有描述有误的地方还望各位不吝赐教 !^_^！ 参考及扩展链接netty之boss-workerC10K问题Dubbo框架设计dubbo协议]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[状态机选型简记]]></title>
      <url>%2F2018%2F04%2F28%2F%E7%8A%B6%E6%80%81%E6%9C%BA%E9%80%89%E5%9E%8B%E7%AE%80%E8%AE%B0%2F</url>
      <content type="text"><![CDATA[背景业务中涉及到一些关于单据的操作，每种单据单据都会有自己的状态，单据的一些行为受限于当前订单的状态，单据的状态直接用常量表示，业务进行前的检查部分通过if判断来检测当前单据是否可以流转到目标状态。 痛点业务发展的比较快，某些单据状态不停的增加，每一次增加都需要改动业务中使用到状态的相关代码，更糟的的是这些代码可能遍布于多个类的多个方法中（散弹枪一样），不仅增加发布的风险也同时增加了测试的回归任务。 目的单据的状态及状态转换与业务解耦，避免散弹一样的效果。 涉及到的知识点了解以下几个知识点有助于我们更好的理解状态机，也相当于是调研状态机是否满足我们最核心的需求。 FSM1有限状态机（英语：finite-state machine，缩写：FSM）又称有限状态自动机，简称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。 状态存储关于过去的信息，就是说：它反映从系统开始到现在时刻的输入变化。转移指示状态变更，并且用必须满足确使转移发生的条件来描述它。动作是在给定时刻要进行的活动的描述。有多种类型的动作： 进入动作（entry action）：在进入状态时进行 退出动作：在退出状态时进行 输入动作：依赖于当前状态和输入条件进行 转移动作：在进行特定转移时进行 FSM（有限状态机）可以使用上图那样的状态图（或状态转移图）来表示。此外可以使用多种类型的状态转移表。下面展示最常见的表示：当前状态（B）和条件（Y）的组合指示出下一个状态（C）。完整的动作信息可以只使用脚注来增加。包括完整动作信息的FSM定义可以使用状态表。 当前状态→ 条件↓ 状态A 状态B 状态C 条件X … … … 条件Y … 状态C … 条件Z … … … 状态图的基本概念2状态图（Statechart Diagram）主要用于描述一个对象在其生存期间的动态行为，表现为一个对象所经历的状态序列，引起状态转移的事件（Event），以及因状态转移而伴随的动作（Action）。一般可以用状态机对一个对象的生命周期建模，状态图用于显示状态机（State Machine Diagram），重点在与描述状态图的控制流。 状态图有以下几类元素构成： 状态（States） 转移（Transitions） 动作（State Actions） 自身转移（Self-Transitions） 组合状态（Compound States） 进入节点（Entry Point） 退出节点（Exit Point） 历史状态（History States） 并发区域（Concurrent Regions） 警备条件（Guard condition） 网上介绍状态图的文章很多，给出两篇我认为不错的，里面对状态图介绍的比较详尽，内容不多。 UML建模之状态图-中文 状态机图-英文 状态模式在之前设计模式-行为模式之State的博文中有详细的介绍，不再赘述。 开源的状态机实现状态机是上述对状态图定义的实现，下面几种实现遵循基本的定义，但实现的完善度不尽相同。学习时Demo放在GitHub上，需要可取。 spring-statemachinespring-statemachine的优点官网中介绍的很清楚，不赘述，但在简单看了介绍和实现后基本就放弃了，原因如下： 天生依赖spring，目前最新版本的依赖到Spring框架5.0.X，而我需要引入状态机的工程目前还停留在4.2.X。 状态机实例较重，在官方文档给出的Demo中，推荐注解的形式注入状态机，这样难以随用随new。 关于上一点，其给出了采用工厂的方式解决，但根据单据的业务场景来看，缓存这些实例意义并不大。 squirrel-foundation特点 代码量适中，扩展和维护相对而言比较容易 StateMachine轻量 StateMachine实例创建开销小，本身不支持单例复用，状态机的生命周期清晰 切入点丰富 支持exit、transition、entry基本动作，转换过程留有足够的切入点。 下面是一个状态转换的过程，可以看到我们有很多可以切入的点来记录或者改变状态机的行为。比较蛋疼的是，在状态机初始化时，squirrel把初始化状态当作一个事件发布，导致会多出来一个相应的事件记录。 1234567891011121314//第一行为初始化状态机为OffHook时，注册事件处理器所打印15:59:09.570 [main] WARN com.cxd.squirrel.StateMachineSquirrel - Entry State OffHook//以下是一个完整的状态转换过程15:59:09.574 [main] WARN com.cxd.squirrel.StateMachineSquirrel - beforeTransitionBegin15:59:09.581 [main] WARN com.cxd.squirrel.MyCondition - 自定义转换条件 isSatisfied MyContext&#123;no='yes'&#125;15:59:09.581 [main] WARN com.cxd.squirrel.StateMachineSquirrel - beforeActionInvoked15:59:09.581 [main] WARN com.cxd.squirrel.StateMachineSquirrel - exit State OffHook15:59:09.581 [main] WARN com.cxd.squirrel.StateMachineSquirrel - afterActionInvoked15:59:09.582 [main] WARN com.cxd.squirrel.StateMachineSquirrel - beforeActionInvoked15:59:09.582 [main] WARN com.cxd.squirrel.StateMachineSquirrel - callMethod Transition...15:59:11.586 [main] WARN com.cxd.squirrel.StateMachineSquirrel - afterActionInvoked15:59:11.587 [main] WARN com.cxd.squirrel.StateMachineSquirrel - Entry State Ringing15:59:11.588 [main] WARN com.cxd.squirrel.StateMachineSquirrel - afterTransitionCompleted15:59:11.589 [main] WARN com.cxd.squirrel.StateMachineSquirrel - afterTransitionEnd 支持异步 事件处理机制上squirrel和Spring-statemachine比较相似，将事件处理与产生分离，使用deque交互，通过这种方式可以支持异步，采用生产-消费的方式，让线程责任更加明确。 在我们的业务场景中所有关于单据状态流转的操作都是用户通过移动端发起，需要同步响应操作结果，所以异步在我的场景中不适用。 鸡肋 过于便利的设计 squirrel在设计上为了足够的便利，在注册事件处理方法时通过传入方法名来实现，框架在处理时从状态机实现类中去找这些方法，通过动态的方式调用。 1builder.onEntry(States.OffHook).callMethod("entry"); 个人认为这种方式不是很好，不具有强制约束性，编译期间难以发现错误，也不知道自定义方法的签名到底是怎样。 框架的约定性太强 123方法名为transitFrom[SourceStateName]To[TargetStateName]On[EventName]，参数名为[MyState, MyState, MyEvent, MyContext]的方法会被添加到transition “A-(GoToB)-&gt;B”的action列表中。当状态机从’A’到’B’且触发的event为GoToB的时候，该方法会被调用。 这是框架的一个约定，个人认为作为一个框架不应该有这种画蛇添足的约定，对于框架而言，这太过于约定了。 难以理解的异步处理方式 看了下异步处理的过程，Spring-statemachine在把事件塞进队列后仅是提交了异步任务到Executor，业务线程便立刻返回，这和我理解的异步是一致的。 12345678910111213AbstractStateMachine#sendEventInternalprivate boolean sendEventInternal(Message&lt;E&gt; event) &#123; //...省略... //此处是一个扩展，用户可自行加业务逻辑决定是否接受当前event boolean accepted = acceptEvent(event); //在此方法中创建了一个Runnable并提交到Executor stateMachineExecutor.execute(); if (!accepted) &#123; notifyEventNotAccepted(buildStateContext(Stage.EVENT_NOT_ACCEPTED, event, null, getRelayStateMachine(), getState(), null)); &#125; return accepted;&#125; 而squirrel在把事件塞进队列后还需要等待消费线程消费完毕，不知道此时异步的意义体现在哪里。 另外所有的事件处理默认均有同一个线程来处理，如果用得到异步这种方式，请务必通过扩展方式定义自己的线程池。 squirrel有依赖较低版本Guava中被注解为@Beta的方法，使用时务必注意框架本身对其他开源工具的引用。 1234567891011121314151617181920212223242526272829303132333435363738AbstractExecutionService#doExecuteprivate void doExecute(String bucketName, List&lt;ActionContext&lt;T, S, E, C&gt;&gt; bucketActions) &#123; final Map&lt;ActionContext&lt;T, S, E, C&gt;, Future&lt;?&gt;&gt; futures = Maps.newHashMap(); for (int i=0, actionSize = bucketActions.size(); i&lt;actionSize; ++i) &#123; final ActionContext&lt;T, S, E, C&gt; actionContext = bucketActions.get(i); //...省略... Future&lt;?&gt; future = SquirrelConfiguration.getExecutor().submit(new Runnable() &#123; @Override public void run() &#123; StateMachineContext.set(instance, isTestEvent); try &#123; actionContext.run(); &#125; finally &#123; StateMachineContext.set(null); &#125; &#125; &#125;); futures.put(actionContext, future); //...省略... &#125; for(Entry&lt;ActionContext&lt;T, S, E, C&gt;, Future&lt;?&gt;&gt; entry : futures.entrySet()) &#123; final Future&lt;?&gt; future = entry.getValue(); final ActionContext&lt;T, S, E, C&gt; actionContext = entry.getKey(); try &#123; logger.debug("Waiting action \'"+actionContext.action.toString()+"\' to finish."); if(actionContext.action.timeout()&gt;=0) &#123; future.get(actionContext.action.timeout(), TimeUnit.MILLISECONDS); &#125; else &#123; future.get(); &#125; logger.debug("Action \'"+actionContext.action.toString()+"\' finished."); &#125; catch (Exception e) &#123; //...省略... &#125; &#125;&#125; sateless4j特点 sateless4j是C#版本FSM的Java实现，代码量很少，不到30个类。 StateMachine轻量，比squirrel创建实例代价还要小。 支持基本的事件迁移，exit/entry action、guard、dynamic permit(根据自定义的condition来控制状态的迁移)。 鸡肋因为状态迁移模型设计过于简单，导致本身的扩展点太少。 小结作出决定时我的考量： 上手速度（越简单越快速） 和现有框架的兼容（只需要做代码的变动，不涉及到框架层面） 改动代码少 社区的活跃度 是否有公司在使用 使用状态机到那种地步：仅做状态判断？状态机是否和业务关联？持久化？ 是否引用其他开源项目？被引用的项目是否稳定？是否使用其中明确被告知不稳定的方法或者类？ 至此，我需要再次回顾我最初的诉求：管理状态的转换，避免散弹式的效果。结合考量点，其实sateless4j和squirrel都满足我现在的要求，但我只是想方便管理单据状态的转换，并不想基于这些状态的特性更多的改动工程中的代码，所以决定使用sateless4j。PS：一般PS都是重点啦。朋友的项目中已经在使用sateless4j。 小生不才，以上如有描述有误的地方还望各位不吝赐教 !^_^！ 参考及引用 有限状态机FSM UML建模之状态图 中文版squirrel文档-部分 英文版squirrel文档-全 别人的选型记录]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-行为模式之Visitor]]></title>
      <url>%2F2018%2F02%2F02%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%BC%8F%E4%B9%8BVisitor%2F</url>
      <content type="text"><![CDATA[意图Visitor是行为模式的一种，允许你在不改变要操作对象类的情况下定义一个新操作。 问题你的团队正在开发一款地理信息结构地图的app。图的节点不仅表示城镇也有其他诸如景点，行业等信息。节点间通过道路关联。在引擎中，每个节点都是一个对象，他们的类型由他们自己的类来表示。 你接到一个任务，要把地图导出为XML。乍看之下很容易实现。你需要为每个类型的节点添加一个导出方法，然后遍历地图并为每个节点执行导出方法。这个方法不仅简单而且优雅，因为你可以使用多态来避免和具体的节点类耦合。 但不幸的是，系统架构师不允许修改已存在的node类。这些代码已经在生产环境，没有人希望冒着风险修改他。 另外，他质疑节点类中的XML导出是否有意义。这些类的主要工作是和地理数据协作。导出行为放在这里看起来很不合适。 还有另一个拒绝的原因。在此之后，市场部门的人可能会要求你导出其他格式或添加其他一些奇怪的功能。这会迫使你再次修改那些珍贵的代码。 解决Visitor模式建议你把新的行为放在一个单独的类中，而不是把它继承在已存在的类中。关联到对象的行为，不会被对象本身调用。对象被作为visitor对象的方法参数传递。 对于不同类型的对象，行为的代码可能有点不同。因此，visitor类必须为不同类型的参数提供不同的行为方法。 12345class ExportVisitor implements Visitor is method doForCity(City c) &#123; ... &#125; method doForIndustry(Industry f) &#123; ... &#125; method doForSightSeeing(SightSeeing ss) &#123; ... &#125; // ... 但是，我们怎么为整个地图调用这些方法呢？这些方法有不同的签名，这不允许我们使用多态。为了找到合适的方法来执行给定的对象，我们需要检查它的类。这听起来就是个噩梦。 1234567foreach (Node node : graph) if (node instanceof City) exportVisitor.doForCity((City) node); if (node instanceof Industry) exportVisitor.doForIndustry((Industry) node); // ...&#125; 即使给定的编程语言支持重载（比如：Java或者C#），方法的重载也不会有帮助。因为无法事先知道给定节点的精确类，即使使用了重载也不一定能正确找到执行方法。 但是Visitor模式对整个问题有一个解决方案。它使用Double Dispatch技术来保持多态性。如果我们把确定正确visitor方法的工作委托给我们传递给visitor的对象会怎么样？这些对象自己知道自己的类，所以他们可以挑选一个合适的方法。 123456789101112131415// Client codeforeach (Node node : graph) node.accept(exportVisitor);// Cityclass City is method accept(Visitor v) is v.doForCity(this); // ...// Industryclass Industry is method accept(Visitor v) is v.doForIndustry(this); // ... 我必须承认，我们必须改变node类。但是至少这个改动很小，并且具有可扩展性。 我们接下来要为所有的个性visitor抽离出通用的接口。现在，如果你需要给程序添加一个新的行为，你要做的仅仅是增加一个visitor类。所有已存在的类仍然可以不受影响的很的工作。 真实世界的类比保险代理想象下一个刚入行的保险员，迫切需要新的客户。他随机访问附近的邻居，为他们提供服务。但是不同类型的邻居，需要不同的保险服务。 在住宅，他兜售医疗保险。 在银行，他兜售防盗保险。 在公司，他兜售自然灾害险。 结构 Visitor为所有类型的visitor声明了通用的接口。他声明了一系列把Context Components当作参数的参观方法。这些方法的名字在支持重载的语言中可以一样，但是参数类型不能一样。 Concrete Visitor实现通用接口描述的操作。每个具体的visitor都表示一个独立的行为。 Component声明了一个用来接收Visitor参数的方法。这个方法以Visitor接口作为参数。 Concrete Component实现这个验收方法。这个方法的目的是为了用来为当前组件重定向到一个正确的visitor方法。 Client表示一个集合或者其他复杂对象（比如，一个Composite树）。Client通常不知道其组件的具体类别。 伪代码在这个例子中，Visitor模式将XML导出添加到几何图形的层次结构中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// A complex hierarchy of components.interface Shape is method move(x, y) method draw() method accept(v: Visitor)// It is crucial to implement the accept() method in every// single component, not just a base class. It helps the// program to pick a proper method on the visitor class in// case if a given component's type is unknow.class Dot extends Shape is // ... method accept(v: Visitor) is v.visitDot(this)class Circle extends Dot is // ... method accept(v: Visitor) is v.visitCircle(this)class Rectangle extends Shape is // ... method accept(v: Visitor) is v.visitRectangle(this)class CompoundShape implements Shape is // ... method accept(v: Visitor) is v.visitCompoundShape(this)// Visitor interface must have visiting methods for the// every single component. Note that each time you add a new// class to the component history, you will need to add a// method to the visitor classes. In this case, you might// consider avoiding visitor altogether.interface Visitor is method visitDot(d: Dot) method visitCircle(c: Circle) method visitRectangle(r: Rectangle) method visitCompoundShape(cs: CompoundShape)// Concrete visitor adds a single operation to the entire// hierarchy of components. Which means that if you need to// add multiple operations, you will have to create// several visitor.class XMLExportVisitor is method visitDot(d: Dot) is Export dot's id and center coordinates. method visitCircle(c: Circle) is Export circle's id, center coordinates and radius. method visitRectangle(r: Rectangle) is Export rectangle's id, left-top coordinates, width and height. method visitCompoundShape(cs: CompoundShape) is Export shape's id and the list of children ids.// Application can use visitor along with any set of// components without checking their type first. Double// dispatch mechanism guarantees that a proper visiting// method will be called for any given component.class Application is field allShapes: array of Shapes method export() is exportVisitor = new XMLExportVisitor() foreach shape in allShapes shape.accept(exportVisitor) 如果你不知道为什么这里需要accapt方法，你需要了解一下二次分派。在Java 8之后，接口允许有默认实现，所以本例子可以利用重载和default实现的更加精简。 适用性 当你需要对复杂对象结构（例如树）的所有元素执行操作时，并且所有元素都是异构的。 Visitor模式允许你为一系列不同类型的对象执行一个操作。 当你需要能够在一个复杂的对象结构上运行几个不相关的行为，但是你不想用这些行为的代码来“阻塞”结构的类。 Visitor模式允许你从一堆构成对象结构的类中提取和统一相关的行为，并将其集成到一个visitor类中。这些转型与虚拟在不同的app中重用这些类，而不用关心和它不相关的行为。 当一个新行为只对现有层次结构中的某些类有意义。 Visitor模式允许你制作一个特殊的visitor类实现某些对象的行为，但不为其他对象。 如何实现 为程序中的具体组件创建Visitor接口并且声明一个“visiting”方法。 在组件的基类中添加抽象的accept方法。 具体的组件实现抽象的accept方法。他们必须把请求重定向到适合当前组件类的特定visitor方法。 组件层级结构只需要关心Visitor接口。这样visitor就不必和具体的组件耦合。 对于每个新行为，创建一个新的Concrete Visitor类并实现所有的访问方法。 客户端创建visitor对象，并把他们当作参数传给组建的accept方法。 优点 简化类在复杂的对象结构上添加新的操作。 将相关的行为移动到一个类中。 visitor可以在对对象结构的工作过程中积累状态。 缺点 如果组件的层次经常改变，不适合使用该模式。 违反组件的封装。 和其他模式的关系 Visitor模式像加强版的Command模式，它可以在任何类型的对象上执行一个操作。 Visitor可以对整个Composite树应用一个操作。 Visitor可以和Iterator模式协作来遍历复杂的数据结构，并对所有元素执行一些操作，即使它们有不同的类型。 小结Visitor模式的结构比较简单，其中比较巧妙的是“二次分派”技术，这里不做展开，大家可自行问度娘或者谷哥。给个简单的例子，自行体会下。 参考翻译整理自：https://refactoring.guru/design-patterns/visitor]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-行为模式之Template-Method]]></title>
      <url>%2F2018%2F01%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%BC%8F%E4%B9%8BTemplate-Method%2F</url>
      <content type="text"><![CDATA[意图Template Method 时行为模式的一种，让你定义一个算法的骨架，允许子类重新定义在不改变结构的情况下重新定义算法的某些步骤。 问题假设你正在写一个挖掘办公文档数据的应用程序。用户想要输入各种格式的文件（PDF，DOC，CSV），程序输出给他们有用的格式化数据。 第一个版本你仅支持DOC文件。下一个版本支持CSV格式文件。一个月后，你又增加了从PDF中分析数据的功能。 这时候，你注意到这三种转换算法有很多相似之处。他们除了处理不同的文件格式外，对数据的萃取和分析都是一致的。这点对减少重复代码和算法独立很有帮助。 客户端代码使用这些算法还有另一个问题。选择合适的行为的许多条件都需要依赖选择的算法。如果这三个转换类都遵循一个通用接口或者一个基类，这些条件就可以用多态消灭掉。 解决Template Method模式建议把一个算法分成几个步骤，把步骤封装到方法中并在一个“template”方法中挨个调用。 子类可以复写特定的步骤，但是无法修改模板方法，保持算法的结构不变。 在我们的应用中，我们为所有的转换算法创建一个通用的基类。模版方法的关键步骤看起来像这样子： 123456method templateMethod() is openDocument(); extractRawData(); parseRawData(); analyzeData(); closeDocument(); 首先，你要把模版方法声明为abstract的，让所有的步骤都需要子类实现。然后，在子类的所有方法都实现后，再把子类共有的部分放到基类中，并使这些步骤（方法）成为可选的复写方法。 在我们的例子中，打开和关闭文档的操作对三种文件方式都不同，所以这点不需要默认实现。但是其他的步骤，比如，转换和分析，可以放到基类中，使得子类间共享这些代码。 还有另外一种步骤，叫做钩子。钩子时可选的步骤，他默认是空的。因此，即使一个模板没有腹泻够爱方法，它依然可以工作。通常，钩子被用来再算法开始之前或者结束之后给子类提供机会来做一些事情。 真实世界的类比大众住房建设建筑商使用模板方法来进行大规模住房建设。有一个标准的建筑模板来描述施工步骤：打地基，筑桩，垒墙，走水电等。 但是，尽管标准化，建筑商可以稍微改变每一步，使一个房子有点不同（即添加更多的窗口，用不同的颜色涂墙…） 结构 Abstract class声明了算法的每个步骤，以及用来统筹调用每个步骤的模版方法。这些步骤可以被声明为abstract或者有默认的实现。 Concrete class实现模版方法中定义的每个抽象步骤，但是它也可以复写抽象类中的默认实现。具体的实现类不能自己复写模板方法。 适用性 当子类能够扩展基本算法而不能修改他的结构时。 模版方法模式把算法分割成几个定义在基类中的个性化的步骤，可以被子类轻松扩展，并保持算法的结构。 当你需要几个类来做相似的事情但是又有一些不同时时。当你修改其中一个类时，你必须同时修改其他的类。 模版方法模式把相似的算法步骤抽取到基类中。代码的不同部分保留在各个子类中。 如何实现 分析算法，看他们是否可以被分解成几个步骤。这些步骤中那些事所有子类公用的，哪些事子类唯一的。 创建抽象基类，并且声明模版方法。列出这些算法的结构，把他们声明为abstract。考虑哪些方法应当被声明为final来阻止子类的重写。 如果所有的步骤都是抽象的那就好了。然而，一些步骤适合有默认实现。子类必须实现哪些抽象的方法。 考虑在合适的步骤之间增加钩子，以及在模板方法的开始和结束之间添加钩子。 算法的每个变种都从抽象类继承。变种必须实现所有必要的步骤，但是可以选择性重写可选步骤。 优点 帮助消除重复代码。 缺点 你将受限于现有算法的架构。 如果通过子类复写默认的步骤实现就违背了里氏替换原则。 模板方法往往难以保持更多的步骤。 和其他模式的关系 Factory Method是专业化的Template Method。另一方面，Factory Method通常作为大型Template Method的一个步骤。 Template Method采用继承方式来扩展不同的类取修改算法。Strategy采用修改委托对象行为的方式来改变对象的行为。Template Method工作在类级别。Strategy允许你更改单个对象的行为。 小结Java核心库中有些例子： java.io.InputStream，java.io.OutputStream，java.io.Reader和java.io.Writer中所有非抽象的方法。 java.util.AbstractList，java.util.AbstractSet和java.util.AbstractMap中所有非抽象的方法。 javax.servlet.http.HttpServlet中所有的doXXX()方法都默认响应一个HTTP 405 “Method Not Allowed”错误。你可以自由复写他们。 参考翻译整理自：https://refactoring.guru/design-patterns/template-method]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-行为模式之Strategy]]></title>
      <url>%2F2018%2F01%2F22%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E6%A8%A1%E5%BC%8F%E4%B9%8BStrategy%2F</url>
      <content type="text"><![CDATA[意图Strategy是行为模式的一种，让你定义一组算法，各自封装，并且他们可替换。Strategy让这些算法独立与使用他们的客户端。 问题一天你决定写一个给驴友使用的导航应用。这个应用以漂亮的地图为中心，允许用户在任何城市快速的定位。应用最大的特点是能够自动规划路线，所以你决定特别关注这点。用户可以输入一个期望的目的地，能够快速在屏幕上画出路线。 第一个版本的应用只能规划道路上的路线，适合汽车旅客。但显然不是所有的人都喜欢在休假时开车。所以下一次更新，你添加了规划步行路线的选项。之后，你又增加了一个选项，允许用户规划基于公共交通的路线。 但这仅是一个开始。最近的版本中你计划增加一个可以规划自行车路线的特性。之后，根据沿途景点规划路线成为可选项。 这款应用的业务是成功的，但是技术部分让你头疼不已。每次增加一个新的路线算法，Map类的大小就会增长。至此，应用开始变得难以维护。 任何搜索算法的改变，比如修复一个BUG或者微调算法行为，都会影响整个类，增加了让已存在代码出错的风险。 最终，团队合作变得低效。你的队友在你成功发布一次之后都会抱怨要花费大量的时间在处理代码合并冲突上，因为它们都和一个大类相关联。 解决策略模式建议采使用一个以许多不同方式做重要事情的类，并将这些算法分别提取到单独的被称为策略的类中。 源类被称为context，它有一个字段来接受存储所有策略中的一种。上下文把工作委托给关联的策略，而不是自己去执行。 上下文没有选择合适算法的职责，客户端负责传递一个适当的策略到上下文中。 事实上，上下文不知道策略的细节。上下文只通过策略基本接口暴漏出来的方法和它通信。这是的上下文独立与策略，允许你在不修改上下文或者其他策略的情况下添加新的策略。 在我们导航应用中，每个路线算法都将被抽离到它们自己对应的只有一个buildRoute方法的类中。这个方法接受出发地和目的地，返回路线检查点的集合。 甚至每个路线类在相同的参数下会给出不同的路线。Map类不需要在关心那个策略被选中，因为它唯一的工作就是把检查点渲染到地图上。 这个Map将会提供出一个方法来切换路线策略，这样客户端就可以提供出一个按钮给用户来修改当前规划路线的方式。 真实世界的类比运输你必须到机场去。你可以坐巴士，打的或者骑单车。出行方式就是策略。你根据上下文来选择一个策略，比如预算或者时间限制。 结构 Context存储一个Concrete Strategy对象，但是只通过通用的Strategy接口和其协作。上下文应当报漏出一个setter方法让其他对象可以替换关联的策略对象。 Strategy为所有的策略声明了一个通用接口。这个接口让具体的策略在上下文中是可替换的。 Concrete Strategy实现了不同的算法，旨在以不同的方式完成相同的工作。 上下文只在它需要的时候去调用策略来执行任务。但它并不知道到底是那个策略在执行。 Client会根据不同的场景选择不同的策略。他们可以在运行时根据需要来配置上下文的策略。 伪代码在这个例子中，上下文使用策略来进行不同的算数运算。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// Common interface for all strategies.interface Strategy is method execute(a, b)// Each concrete strategy provides unique implementation.class ConcreteStrategyAdd implements Strategy is method execute(a, b) is return a + bclass ConcreteStrategySubtract implements Strategy is method execute(a, b) is return a - bclass ConcreteStrategyMultiply implements Strategy is method execute(a, b) is return a * b// Context (as a client) always works with strategies// through a common interface. It does not know or care// which strategy is currently active.class Context is private strategy: Strategy method setStrategy(Strategy strategy) is this.strategy = strategy method executeStrategy(int a, int b) is return strategy.execute(a, b)// The concrete strategy is picked on a higher level (for// example, by application config) and passed to the client// object. At any time, the strategy object can be replaced// by a different strategy.class ExampleApplication is method main() is Create context object. Read first number. Read last number. Read the desired action from user input. if (action == addition) then context.setStrategy(new ConcreteStrategyAdd()) if (action == subtraction) then context.setStrategy(new ConcreteStrategySubtract()) if (action == multiplication) then context.setStrategy(new ConcreteStrategyMultiply()) result = context.executeStrategy(First number, Second number) Print result. 适用性 当你有一个对象需要以许多不同的方式来做相同的任务时。 策略模式允许你在运行时通过提供不同的子对象（实际处理工作的对象）来修改对象的行为。 当你有许多相似的类，它们以不同的方式执行一些行为。 策略模式允许你将所有这些类的行为抽取到单独的类层次结构中，从而使原始类的行为可以自定义。 当你不想把算法实现的细节暴露给其他类时。 策略模式通过把代码，内部数据和算法的依赖关系提取到自己的类中来隔离其他对象。 一个算法通过大量条件操作被选择执行。背个条件分支代表不同的算法。 策略允许你通过抽离每个算法到自己的类中来分解条件，这些类都遵循一个相同的接口。上下文把工作委托给这些对象，而不是自己实现这些行为。 如何实现 确定客户希望通过“flex ponit”访问的算法。 为这个算法所有的实现声明通用的接口。 挨个把这些算法抽离到它们自己的类中。它们都应当遵循通用的Strategy接口。 给Context类增加一个字段来关联当前使用的策略，并提供一个setter方法用来改变策略。上下文应当只通过Strategy接口和策略协作。 当客户端需要上下文来以某种方式工作的时候，必须提供一个合适策略对象。 优点 允许在运行时热替换算法。 对其他类隔离代码和算法数据。 用委托替代继承。 符合开闭原则。 缺点 通过创建多个额外类增加代码复杂度。 客户端必须关心策略间的差异以便选择正确的策略。 和其他模式的关系 State，Strategy，Bridge（和某种程度上的Adapter）都有相似的解决结构。它们都是共享“handle/body”句柄。它们的意图不一样，所以他们用来解决不同的问题。 Command和Strategy很相似，因为他们都是把一些行为参数化到上下文。Command可以用爱把任何操作转换到一个对象中。可选的参数变成了那个对象的字段。这个转换允许延迟或者远程执行，存储命令历史等。 另一方面，Strategy模式通常用来描述处理相同事情的不同方式。它可以帮助我们让这些算法在一个单独的上下文类中是可替换的。 Decorator可以让你改变一个对象的皮肤（外部表象）。Strategy让你改变胆子（内部实现）。 Template Method使用继承来改变算法（子类扩展父类的某些方法）。Strategy通过把工作委托给可替换的策略对象来改变对象的行为。模版方法模式工作在类这一层面。策略模式允许你改变个性化对象的行为。 State可以看作是Strategy模式的一种扩展。这两种模式都采用组合的方式来改变主对象的行为，主对象委托工作给这些帮助对象。Strategy模式让这些对象完全独立。State模式允许状态对象改变上下文对象的当前状态，他们之间是相互依存的。 小结策略模式是行为模式的一种，他把一系列行为分解到不同的对象中，使得他们在源上下文对象中可以互换。 源对象被叫做上下文，他会持有一个策略对象的引用，并把任务委托给策略执行。为了改变上下文处理工作的方式，其他对象可以修改当前上下文中的策略对象。 参考翻译整理自：https://refactoring.guru/design-patterns/strategy]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-行为模式之State]]></title>
      <url>%2F2018%2F01%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E6%A8%A1%E5%BC%8F%E4%B9%8BState%2F</url>
      <content type="text"><![CDATA[意图State是行为模式的一种，它允许你在对象内部状态发生变化时改变其行为。这个对象会改变它的类。 问题状态模式和有限状态机很相似。 它主要的思想是程序是几个状态之一，这些状态相互关联。状态的数量和它们之间的转换是有限的并且是预先定义的。根据当前的状态，程序对相同的事件会有不同的响应。 类似的方法可以应用到对象上。比如，Document（提案）对象可以是以下三种状态之一：Draft（草案），Moderations（待审）和Publish（发布）。对每种状态而言，publish方法会有不同的处理方式： 第一种状态，它将改变提案的状态到待审。 第二种状态，它将使提案变成发布状态，当然只有在当前用户是管理员时。 第三种状态，它什么也不做。 状态机通常基于许多条件操作来实现，比如，if或者wsitch来检查当前状态并作出适当的行为。即使你第一次听说状态机，你很可能已经至少实现多一次。下面这段代码看起来是不是很眼熟？ 1234567891011121314151617class Documentstring state;// ...method publish() &#123; switch (state) &#123; "draft": state = "moderation"; break; "moderation": if (currentUser.role == 'admin') state = "published" break; "published": // Do nothing. &#125;&#125;// ... 当你你要添加更多状态或者状态依赖行为到Document中时，使用条件构建起来的状态机最大的限制就展露出来。大多方法需要有很多条件参数来决定这个状态下的正确行为。 这些代码很难维护，因为任何转换逻辑的改变都需要在每个方法中对每个条件做双重检查。 项目越老这个问题往往越大，因为在设计阶段事先预测所有可能的状态和转换是相当困难的。因此，一个由少量条件构成的精简状态机随着时间的推移会变的一团糟。 解决状态模式建议为上下文对象的所有可能状态创建新类，并将与状态有关的行为提取到这些类中。 上下文将会包含一个代表当前状态的状态对象。上下文将把执行交给状态对象，而不是自己去处理。 为了改变上下文对象，一个状态对象可以将另一个状态对象传到上下文中。但是为了让状态可以呼唤，所有的状态类必须遵循相同的接口，并且上下文必须通过状态对象的接口和它通信。 上面描述的结构看起来有些像Strategy模式，但是它们有一个关键点不同。在状态模式中，上下文和特定的状态都可以发起状态间的转换。 真实世界类比智能手机智能手机当前处于不同的状态会有不同的行为： 当手机处于解锁状态，按下按钮会执行一些列功能。 当手机被锁定，所有的按钮都会展示解锁画面。 当手机电量低，所有按钮都会展示充电画面。 结构 Context（上下文）持有Concrete State（具体状态）对象的引用，并把状态相关的行为委托给它。上下文通过状态通用的接口和状态对象协作。上下文必须报漏出一个方法来接收一个新状态对象。 State（状态）为具体状态声明通用的接口。它声明的方法应当对所有的状态都是有意义的。但是每个状态应该提供不同的实现。 Concrete State实现特定状态的行为。增加状态基类避免在多个状态中出现重复代码。 一个状态可以持有上下文的引用。这不仅让它可以访问上下文数据，也提供了一种法器状态转变的方式。 上下文和具体的状态都可以决定何时发起状态转换及决定转换到什么状态。为了处理转换，一个新的状态对象应当被传给上下文。 伪代码在这个例子中，状态模式依赖当前不同的播放器的状态来控制播放器不同的行为。Player主类持有一个状态对象的引用，它被用来处理播放器的大多数工作。用户的一些操作会使播放器转换到另一个状态。 状态模式让播放器改变其行为而对其他对象无感知。转换可以被播放器本身或者特定的状态对象执行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121// Common interface for all states.abstract class State is protected field player: Player // Context passes itself through the state constructor. // This may help a state to fetch some useful context // data if needed. constructor State(player) is this.player = player abstract method clickLock() abstract method clickPlay() abstract method clickNext() abstract method clickPrevious()// Concrete states provide the special implementation for// all interface methods.class LockedState is // When you unlock a locked player, it may assume one of // the two states. method clickLock() is if (player.playing) player.changeState(new PlayingState(player)) else player.changeState(new ReadyState(player)) method clickPlay() is Do nothing. method clickNext() is Do nothing. method clickPrevious() is Do nothing.// They can also trigger state transitions in the context.class ReadyState is method clickLock() is player.changeState(new LockedState(player)) method clickPlay() is player.startPlayback() player.changeState(new PlayingState(player)) method clickNext() is player.nextSong() method clickPrevious() is player.previousSong()class PlayingState is method clickLock() is player.changeState(new LockedState(player)) method clickPlay() is player.stopPlayback() player.changeState(new ReadyState(player)) method clickNext() is if (event.doubleclick) player.nextSong() else player.fastForward(5) method clickPrevious() is if (event.doubleclick) player.previous() else player.rewind(5)// Player acts as a context.class Player is field state: State field UI, volume, playlist, currentSong constructor Player() is this.state = new ReadyState(this) // Context delegates handling user's input to a // state object. Naturally, the outcome will depend // on what state is currently active, since all // states can handle the input differently. UI = new UserInterface() UI.lockButton.onClick(this.clickLock) UI.playButton.onClick(this.clickPlay) UI.nextButton.onClick(this.clickNext) UI.prevButton.onClick(this.clickPrevious) // Other objects must be able to switch Player's // active state. method changeState(state: State) is this.state = state // UI methods delegate execution to the active state. method clickLock() is state.clickLock() method clickPlay() is state.clickPlay() method clickNext() is state.clickNext() method clickPrevious() is state.clickPrevious() // State may call some service methods on the context. method startPlayback() is // ... method stopPlayback() is // ... method nextSong() is // ... method previousSong() is // ... method fastForward(time) is // ... method rewind(time) is // ... 适用性 当你有一个对象在不同状态下会有不同行为时。状态的数量有很多。状态关联的代码经常改变。 状态模式建议隔离那些和状态相关的代码到不同的类中。源类被叫做“上下文”，它要持有这些状态对象中的其中一个。它应当把工作委托给这个状态对象。这种结构允许通过提供给上下文不同状态对象的方式改变上下文的行为。 当一个类被大量的通过当前类字段值来改变方法行为的条件污染。 状态模式把条件分支转换成合适状态类中的方法。然后需要依赖多态吧执行委托到关联的状态对象。 在基于条件的状态机中有大量重复代码分布在相似状态和转换中时。 状态模式允许你组合状态类的层次，通过把通用的代码移动到层级的基类中来减少重复。 如何实现 声明那个类来扮演Context角色。这可能是一个存在的类，已经有了状态依赖的相关代码；或者是一个新类，如果状态相关的代码分布在各个类中。 创建State接口。大多情况下，他将镜像声明在Context中的方法。 为每个真正的状态，创建一个State接口的实现。遍历Context的方法，把所有和状态有关的代码放到对应的状态类中。 添加一个State类型的引用字段到Context类中，并且需要提供一个可复写这个字段值的public方法。 再一次遍历Context中的方法，用状态对象的相应方法替换剩余的状态条件部分。 为了转换Context的状态，必须创建一个状态实例传给上下文。这步可有Context自己，或者通过State，或者Client来完成。注意，创建者将需要依赖具体的State类进行实例化。 优点 消除状态机条件。 把与特定状态相关的代码组织到不同的类中。 简化代码上下文。 缺点 如果一个状态机只有少数几个状态或很少发生变化，那么这可能是过度设计。 和其他模式的关系 State，Strategy，Bridge（某种意义上的Adapter）有相似的解决结构。他们都共享“handle/body”元素。他们的意图有所不同 - 也就是说，他们解决不同的问题。 State可以看作是Strategy模式的扩展。这两种模式都使用组合把工作委托给辅助对象来改变主对象的行为。但是，State模式允许状态对象用另一个状态改变当前上下文的状态，使得它们相互依赖。 小结State是一种行为设计模式，允许对象在其内部状态改变时改变行为。该模式将与状态相关的行为提取为单独的状态类，并强制原始对象将工作委派给状态类的实例，而不是自行处理。 参考翻译整理自：https://refactoring.guru/design-patterns/state]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-行为模式之Observer]]></title>
      <url>%2F2018%2F01%2F15%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%BC%8F%E4%B9%8BObserver%2F</url>
      <content type="text"><![CDATA[意图Observer是行为模式的一种，允许你定义对象间一对多的关系，以便一个对象状态改变后，它的依赖者可以被通知并可以自动更新。 问题假设你有两个对象，Customer和Store。商店采购了一批新产品，一些客户对这些产品很感兴趣。 客户可能每天都来商店看下是否有感兴趣的产品售卖，但大多情况下的是无意义的，因为产品还在路上。 另一方面，商店可以给所有的客户发送上新的邮件。但是对那些不关心这类产品的用户来说是不必要的。 因此，我们遇到了一个冲突：是客户浪费时间来顶起检查还是商店浪费时间来通知到错误的客户。 解决我们把有一些有趣状态的对象叫做Publisher。把另外那些想要追踪状态改变的对象叫做Subscriber。 Observer模式提供一个发布者，他有要追踪状态订阅者的列表。这个列表可以通过几个订阅方法来供订阅者修改。因此，在任何时候，每个订阅者都能够把自己从列表中添加或者移除。发布者每次有新的事件发布，它会遍历它的订阅者列表并调用订阅者的通知方法。 发布者可以和任何订阅者协作，因为他们都遵循通用的接口。这个接口生命力一个带有一些参数的通知方法，这些参数提供给订阅者事件的细节。 如果应用有几个发布者类型，通用的发布者接口也需要提取出来。它由几个订阅方法组成。这个接口允许订阅者观察发布者的状态却不必和某个具体的实现类耦合。 类比杂志订阅一旦你订阅了杂志或者报纸，你不在需要去商店检查是否有新的杂志或者报纸发布。相反，发布者将会在期刊发布后直接发送到你的邮箱。 发布者维护了订阅者的信息，并且知道他们感兴趣的杂志。如果订阅者不想发布者再发送新的杂志给他们，他们可以随时取消对杂志的订阅。 结构 Publisher（发布者）发布其他对象感兴趣的事件。这些事件发生在发布者改变了他的状态或者它执行力一些行为时。发布者包含订阅的基本设施，允许新订阅者的加入和老订阅者的退出。 当一个新事件发生，发布者遍历订阅者列表并调用他们的通知方法，这些方法声明在Subscriber（订阅者）接口中。 Subscriber（订阅者）声明通知接口。大多情况下，它只有update方法。这个方法可能有几个参数让订阅者可以获取到事件详情。 具体的订阅者实现通知接口并且响应发布者发布的事件。 订阅者只需要一个简单的方法来争取的处理更新。基于这个原因，发布者通常把一些上下文数据当作这个方法的参数传递给订阅者。甚至可能是发布者自身的引用。 客户端分别创建发布者和订阅者对象，并且把订阅者注册到发布者。 有时候，订阅者可以直接访问发布者是很便利的。这个链接通常通过订阅者的构造方法建立。它允许订阅者在收到通知后直接从发布者抓取更新的状态。 伪代码在这个例子中，Observer允许文本编辑器对象通知其他对象状态的变化。订阅者列表是动态编译的。对象可以在运行期间开始或者停止对更新的监听。 在这个实现中，编辑器自己维护订阅者列表而不是把它委托给特别的helper对象。这允许其他对象复用订阅基础结构。因此，Observer模式允许动态配置对象内发生的各种事件的处理者。 添加新的订阅者不需要改变已经存在的发布者类，只要他们之间通过通用接口协作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586// Base publisher class. It should include the subscription// management code and notification methods.class EventManager is private field listeners: hash map of event types and listeners method subscribe(eventType, listener) is listeners.add(eventType, listener) method unsubscribe(eventType, listener) is listeners.remove(eventType, listener) method notify(eventType, data) is foreach listener in listeners.of(eventType) listener.update(data)// Concrete publisher, which contains real business logic// interesting for some subscribers. We could derive this// class from a base publisher, but that is not always// possible in real life, since the concrete publisher might// already have a different parent class. In this case, you// can patch the subscription logic in with composition,// just like we did it here.class Editor is private field events: EventManager private field file: File constructor Editor() is events = new EventManager() // Business logic methods can notify subscribers about // the changes. method openFile(path) is this.file = new File(path) events.notify("open", file.name) method saveFile() is file.write() events.notify("save", file.name) // ...// Common subscribers interface. By the way, modern// programming languages allow to simplify this code and use// functions as subscribers.interface EventListener is method update(filename)// List of concrete listeners. They react to publisher// updates by doing some useful work.class LoggingListener is private field log: File private field message constructor LoggingListener(log_filename, message) is this.log = new File(log_filename) this.message = message method update(filename) is log.write(replace('%s',filename,message))class EmailAlertsListener is private field email: string constructor EmailAlertsListener(email, message) is this.email = email this.message = message method update(filename) is system.email(email, replace('%s',filename,message))// Application can configure publishers and subscribers even// in run time.class Application is method config() is editor = new TextEditor() logger = new LoggingListener( "/path/to/log.txt", "Someone has opened file: %s"); editor.events.subscribe("open", logger) emailAlers = new EmailAlertsListener( "admin@example.com", "Someone has changed the file: %s") editor.events.subscribe("save", emailAlers) 适用性 当一个对象的状态发生变化其他对象也需要改变，但是这些对象事先不知道或者需要动态改变时。比如，你在开发一个专注于按钮的GUI框架。你想你的客户端能够在用户按下按钮时回调一些定制的代码。 Observer模式允许任何实现了订阅者接口的对象到发布者订阅事件通知。 一些对象需要观察其他对象，但只在限定的时间内或者特别的情况下。 Observer模式让发布者维护一个动态的订阅列表。所有的订阅者可以在运行时随时加入或者离开这个列表。 如何实现 区分核心（独立的）功能和可选（依赖的）功能。前者扮演发布者，后者扮演订阅者。 创建Subscriber接口。大多情况下，一个update方法足够。 创建Publisher接口并且定义开始和结束订阅操作。切记，发布者和订阅者通过通用接口协作。 你必须决定真实的订阅列表和订阅方法的实现放在哪里。通常，这些代码对所有类型的发布者而言都差不多。所以最恰当的地方是放在Publisher接口派生出的抽象基类中。但是如果你在已存在的类结构层次中集成Observer，那么创建一个小的helper类来维护制定发布者的订阅关系会比较方便。 创建具体的发布者类。在每次有重要事件发生时，他们都应当通知列表中所有的订阅者。 在具体的订阅者类中实现update方法。大多订阅者需要事件的上下文数据。可以通过update方法的参数传递给接受者。但是还有另外的方式。在收到通知后，接受者可以直接从发布者对象中抓取任何数据。在这种情况下，发布者必须把它自己当作参数传递给接受者。最不灵活的方法是通过订阅者构造方法持久的建立和发布者的关系。 客户端代码必须创建所有必须的订阅者并把它们注册到正确的发布者上。 优点 发布者不会和具体的订阅者类耦合。 你可以动态的订阅或者取消订阅。 -遵循开闭原则。 缺点 通知到订阅者的顺序是随机的。 和其他模式的关系 CoR、Command、Mediator和Observer处理各种方式的发送者和接受者： CoR让请求沿着一个动态的潜在接受者链条传递直到某个接口者处理它。 Command建立了发送者和接受者的单项链接。 Mediator让发送者和接受者相互间简介关联。 Observer在同一时间把请求发送给所有关心的接收者，但是允许他们动态的订阅和取消订阅之后的请求。 Mediator和Observer模式的区别常常很模糊。在大多数情况下，模式间是竞争的，但有时他们可以合作。 Mediator调模式的主要目标是消除一组系统组件之间的相互依赖关系。所有组件都变成独立的对象。另一方面，Observer的主要目的是建立对象间动态的单向链接，其中一些随想作为其他对象的下属。 有一个非常受欢迎的Mediator实现依赖于Observer模式。中间人对象扮演发布者，所有的同事组件扮演订阅者。他们动态的订阅和取消订阅中间人的事件。这种实现方式看起来和两种模式都很像。 但是Mediator模式可以有不同的实现方式，比如所有的组件都永久连接到形同的中间人对象。这种实现看起来不像Observer，但仍是Mediator模式的一个例子。 现在想象另一个程序，其中所有的组件都是发布者，并允许彼此动态链接。这里没有一个中央中间人对象，而是一个分布式的观察员系统。 参考翻译整理自：https://refactoring.guru/design-patterns/observer]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-行为模式之Mediator]]></title>
      <url>%2F2018%2F01%2F13%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%BC%8F%E4%B9%8BMediator%2F</url>
      <content type="text"><![CDATA[意图Meditor是行为模式的一种，允许你定一个对象来封装一些对象的关联关系，以使这些对象相互独立。 问题你有一个对话框用来编辑用户的配置。它是由TextEdit、Checkboxes、Button等组成的表单。 表单中元素会相互影响。比如，“我有一条狗”的复选框应当展示隐藏的文本框用来输入狗的名字。另外一个例子是提交按钮在保存数据钱必须娇艳所有字段的数据。 把这些逻辑直接放在表单元素代码中，使得这些类难以被app其他表单复用。比如，你不能使用另一个表单中的复选框，因为它和狗名字的文本框紧密耦合。 解决Mediator模式阻止单个组件间的直接交。取而代之，他们发行请求到中间人对象，这个对象知道如何引导请求。组件摆脱了相互间的依赖，只和中间人对象有关联。 在我们的例子中，对话框类可以当这个中间人。可能，甚至不需要在类中添加任何新的依赖关系，因为对话框已经知道它的子表单元素。 表单元素代码会发生重大的变化。比如，提交按钮之前必须在按钮点击后校验变淡元素，但是现在它只需要发出被点击的通知即可。收到提交通知后，对话框自己完成所有的校验。通过这种方式，按钮将只需要依赖对话框类。 你甚至可以更进一步使得依赖更加宽松，为所有对话框抽离出一个通用接口。这个接口需要声明一个方法去通知对应表单元素相关的事件。这样，我们的提交按钮就可以和任意一个遵循这个接口的的对话框通信。 通过这种方式，Mediator模式包装各个组件的关联关系到一个单独的中间人对象中。类的依赖越少，修改、扩展或重用它就越容易。 现实世界类比空中管制塔台控制机场很形象的展示了Mediator模式。飞行员在降落或者起飞时和塔台通信，而不是和其他飞行员直接通信。塔台控制哪架飞机可以起飞或者降落。 注意，塔台并不控制整个航程，只对终端区域进行管制。 结构 Components（组件）是包含业务逻辑程序的各种对象。每个组件都持有一个中间人的引用。组件不关心中间人的实际类型，因为他们通过Mediator接口协作。这允许在其他程序中复用组件，只要改变他们的关联中间人即可。 组件也不关心其他组件。当它们的状态改变时，它们只需要通知中间人。中间人知道哪些组件需要响应这个事件。 Mediator声明了和Component通信的接口，它通常含有一个方法。组件组件使用这个方法通知中间人他们发生了一个重要的事件。组件把他们自己当作事件的一部分传给通知方法。 中间人接口是已存在组件可被其他程序崇重用的关键。你需要做的是提供一个新的中间人来控制组件如何在新的上下文中同其他组件协作。 Concrete Mediator（具体的中间人）封装了各个组件间的关系。中间人通常持有它它管理的所有组件的引用。 具体的中间人常常和他们的组件紧密耦合。当中间人收到一个通知，他可以轻松的识别出发送者。它也知道哪个组件应当被触发。但是对组件而言，它就是一个黑盒。发送者不知道谁来处理它的事件，接受者也不知道谁发出的这个事件。 伪代码在这个例子中，Mediator模式帮助消除UI类间的相互依赖：按钮、复选框和文本标签。当用户与元素进行交互时，他们不直接进行通信，而是把这个事件通知给中间人。 认证对话框扮演了这个中间人。它知道具体的要素应该如何协作并促进其合作。在接收到一个通知事件后，他把事件传递给适当的组件来执行。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// The mediator interface.interface Mediator is method notify(sender: Component, event: string)// The concrete mediator class. All chaotic communications// between concrete components were extracted to the// mediator class.class AuthenticationDialog implements Mediator is private field title: string private field loginOrRegister: Checkbox private field loginUsername, loginPassword: Textbox private field registrationUsername, registrationPassword private field registrationEmail: Textbox private field ok, cancel: Button constructor AuthenticationDialog() is Create all component objects. Link meditor with components via constructor params. // When something happens with a component, it notifies // the mediator. Upon receiving a notification, the // mediator may do something on its own or pass the // request to another component. method notify(sender, event) is if (sender == loginOrRegister and event == "check") if (loginOrRegister.checked) title = "Log in" Show login components Hide registration components. else title = "Register" Show registration components. Hide login components if (sender == ok and event == "click") if (loginOrRegister.checked) Try to find user using login credentials. if (!found) Show errors over login fields. else Create account using registration fields. Log user in. // ...// Components communicate with a mediator using the mediator// interface. Thanks to that, you can use the same// components in other contexts by linking them with a// different mediator object.class Component is field dialog: Mediator constructor Component(dialog) is this.dialog = dialog method click() is dialog.notify(this, "click") method keypress() is dialog.notify(this, "keypress")// Concrete components do not talk to each other. They have// only one communication channel, which is sending// notifications to the mediator.class Button extends Component is // ...class Textbox extends Component is // ...class Checkbox extends Component is method check() is dialog.notify(this, "check") // ... 适用性 当组件间依赖混乱，某个组件简单的改变导致其关联的组件都需要改变。 中间人把类之间的关系抽离到一个单独的类中，使得一个组件的改变对其他代码是隔离的。 当你无法在不同的程序中复用一个组件，因为它太依赖其他组件。 使用了中间人后，组件个体不在关心其他组件。他们通过中间人间接通信。在不同的app中复用一个组件只需要创建一个新的中间人类。 当你必须创建组件的多个子类但只是为了在不同的上下文中使用相同的组件时。 中间人封装了组件之间的关系。因此，完全可以创建一个新的中间人子类为同一群组件定义一个新的关系。 如何实现 确定一组紧密联系的类，他们如果相互更加独立，我们能从中获得收益。 创建Mediator接口并且声明其和各个组件间的通讯协议。大多情况下，定义一个从组件接收通知的方法就足够了。 在具体的Mediator中实现这个方法。Mediator类最好持有它管理的所有组件的引用。 你甚至可以把创建组件的代码挪到Mediator中。这将使中间人变成一个工厂。 组件也应当持有中间人的引用。这个链接通常在组件的构造方法中建立，中间人对象是组件构造方法的一部分。 改变组件的代码以便当一些事情发生时它能够调用中间人的通知方法。剥离真正的业务代码到Mediator类中，并在其接收到组件的通知后执行它。 优点 减少一个程序中组件的耦合。 允许复用单个组件。 集中各个组件之间的通信。 缺点 Mediator可能会发展成God Object。 和其他模式的关系 CoR、Command、Mediator和Observer处理各种方式的发送者和接受者： CoR让请求沿着一个动态的潜在接受者链条传递直到某个接口者处理它。 Command建立了发送者和接受者的单项链接。 Mediator让发送者和接受者相互间简介关联。 Observer在同一时间把请求发送给所有关心的接收者，但是允许他们动态的订阅和取消订阅之后的请求。 Mediator和Facade在抽象已存在类的功能这点上很像。Mediator 抽象/集中同事间的任意通信。它通常“添加值”并且是同事对象所知道/参考的。相比之下，Facade为子系统定义了一个更简单的接口，它不会增加新的功能，而且子系统类也不知道它的存在。 Mediator和Observer模式的区别常常很模糊。在大多数情况下，模式间是竞争的，但有时他们可以合作。 Mediator调模式的主要目标是消除一组系统组件之间的相互依赖关系。所有组件都变成独立的对象。另一方面，Observer的主要目的是建立对象间动态的单向链接，其中一些随想作为其他对象的下属。 有一个非常受欢迎的Mediator实现依赖于Observer模式。中间人对象扮演发布者，所有的同事组件扮演订阅者。他们动态的订阅和取消订阅中间人的事件。这种实现方式看起来和两种模式都很像。 但是Mediator模式可以有不同的实现方式，比如所有的组件都永久连接到形同的中间人对象。这种实现看起来不像Observer，但仍是Mediator模式的一个例子。 现在想象另一个程序，其中所有的组件都是发布者，并允许彼此动态链接。这里没有一个中央中间人对象，而是一个分布式的观察员系统。 小结Java代码中Mediator模式最流行的用法是促进应用程序的GUI组件之间的通信。Mediator的同义词是MVC模式的控制器部分。 在Java核心库中有以下使用该模式的例子： java.util.Timer (所有的scheduleXXX()方法) java.util.concurrent.Executor#execute() java.util.concurrent.ExecutorService (invokeXXX()和submit()方法) java.util.concurrent.ScheduledExecutorService (所有的 scheduleXXX()方法) java.lang.reflect.Method#invoke() 参考翻译整理自：https://refactoring.guru/design-patterns/mediator]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-行为模式之Iterator]]></title>
      <url>%2F2018%2F01%2F08%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%BC%8F%E4%B9%8BIterator%2F</url>
      <content type="text"><![CDATA[意图Iterator是行为模式的一种，允许在不暴露底层结构的情况下顺序访问聚合对象中的元素。 问题集合是编程中最常用的数据结构。它把一组对象放到一个单独的容器中。 大多集合看起来都像元素的列表。然而，一些集合以树、图或者其他复杂数据结构组织数据。并且每个集合都必须提供一个方法让用户可以按照顺序处理集合中的元素。 但是，要怎么顺序遍历一个复杂结构呢？必须有几个方法来做到这一点。比如，今天想要深度优先来遍历树。但是，明天又想宽度优先来遍历。下周，又可能需要随机访问集合元素。添加越来越多的遍历算法使其丧失了它主要的职责，即高效存储数据。另一方面，一些特定的算法只只在指定的应用场景中适用。 解决Iterator模式建议抽出集合遍历方法到一个叫做“Iterator”的独立对象中。 迭代器封装遍历细节，像当前位置及还有多少元素需要遍历。允许几个迭代器去独立遍历相同的集合。集合本身甚至不知道有人在访问它的元素。 甚至，如果你需要一个特别的方式来遍历一个集合，你只需要创建一个新的迭代器类而不需要改动集合代码。 真实世界的类比旅游向导你计划去罗马一周来参观它所有的景点。但是到那后，你花了很长的时间来找斗兽场。 另一方面，你还有些备用预算可以请当地的导游。这个导游可以带你去看每个景点并且能给你讲许多有趣的故事。 如果预算不够，你可以在手机上使用虚拟导游。它虽然没有真正的导游那么有趣，但是便宜。你可以只去你感兴趣的地方。 真正的导游和虚拟导游都是罗马提供的遍历景点的迭代器。 结构 Iterator定义了遍历集合的接口。通常有获取下/上一个元素方法和用来跟踪是否迭代完毕的方法。 具体的Iterator实现遍历集合的特定算法。迭代器对象应当自己追踪遍历进度。它允许几个迭代器独立遍历相同的集合。 Collection接口声明了可以被迭代的集合。正如我们之前提到的，不是每一个集合都被表示成一个列表。集合可能把元素存储在一个数据库中，需要通过远程API获取他们；或者存储在一个Composite树中。因此，集合本身可能会创建迭代器，因为有一定数量的迭代器能够处理给定的集合类型。 具体的Collection在每次客户端请求时都会返回一个新的特定的迭代器实例。注意，这个方法的参数都要返回抽象迭代器类型。这将使得客户端和具体的迭代器独立。 客户端通过集合和迭代器的通用接口工作。这种方式让客户端与具体的类解耦。它允许添加新的迭代器并且不要修改现有代码。 通常，客户端自己不创建迭代器，而是从集合对象获取。但是客户端总是可以直接创建迭代器如果它需要特定的迭代器。 伪代码在这个例子中，迭代器模式被用来遍历封装了访问Facebook社交关系的集合。这个集合提供了几种可以以不同方式遍历配置文件的迭代器。 friend迭代器遍历给定配置集合中所有的朋友。colleague迭代器遍历同样遍历给定配置文件集合中的朋友但跳过了那些不是同事的朋友。所有的迭代器遵循相同的接口，这些接口允许客户端在不深入社交网络细节的情况下获取配置（比如，认证，发送REST请求等）。 因为客户端代码通过通用接口同集合、迭代器协作，所以，需要支持新的社交网络时仅需要添加新的集合类，而不用改变现有代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293// The collection interface must declare a factory method for producing// iterators. You can declare several methods if there are different kinds// of iteration available in your program.interface SocialNetwork is method createFriendsIterator(profileId): ProfileIterator method createCoworkersIterator(profileId): ProfileIterator// Each concrete collection will be coupled to a set of concrete iterator// classes it returns. But the client will not be, since the signature of these// methods returns iterator interfaces.class Facebook implements SocialNetwork is // ... The bulk of the collection's code should go here ... // Iterator creation code. method createFriendsIterator(profileId) is return new FacebookIterator(this, profileId, "friends") method createCoworkersIterator(profileId) is return new FacebookIterator(this, profileId, "coworkers")// The common interface for all iterators.interface ProfileIterator is method getNext(): Profile method hasMore(): bool// The concrete iterator class.class FacebookIterator implements ProfileIterator is // The iterator needs a reference to the collection that it traverses. private field facebook: Facebook private field profileId, type: string // An iterator object traverses collection independently from other // iterators. Therefore it has to store the iteration state. private field currentPosition private field cache: array of Profile constructor FacebookIterator(facebook, profileId, type) is this.facebook = network this.profileId = profileId this.type = type private method lazyInit() is if (cache == null) cache = facebook.sendSophisticatedSocialGraphRequest(profileId, type) // Each concrete iterator class has its own implementation of the common // iterator interface. method getNext() is if (hasMore()) currentPosition++ return cache[currentPosition] method hasMore() is lazyInit() return cache.length &lt; currentPosition// Here is another useful trick: you can pass an iterator to a client class,// instead of giving it access to a whole collection. This way, you do not// expose the collection to the client.//// But there is another benefit: you can change the way the client works with// the collection at run time by passing it a different iterator. This is// possible because the client code is not coupled to concrete iterator classes.class SocialSpammer is method send(iterator: ProfileIterator, message: string) is while (iterator.hasNext()) profile = iterator.getNext() System.sendEmail(profile.getEmail(), message)// The application class configures collections and iterators and then passes// them to the client code.class Application is field network: SocialNetwork field spammer: SocialSpammer method config() is if working with Facebook this.network = new Facebook() if working with LinkedIn this.network = new LinkedIn() this.spammer = new SocialSpammer() method sendSpamToFriends(profile) is iterator = network.createFriendsIterator(profile.getId()) spammer.send(iterator, "Very important message") method sendSpamToCoworkers(profile) is iterator = network.createCoworkersIterator(profile.getId()) spammer.send(iterator, "Very important message") 适用性 当你有一个复杂的数据结构，并且你想对客户端隐藏它的复杂性（为了安全或者方便）。 迭代器封装与复杂数据结构的交互并保护它免受粗心和恶意行为。迭代器模式允许客户端和集合元素协作而不必暴露集合对象。 当你需要几种不同的遍历数据结构的方式，但是你不能把它加到集合中或者这个代码和业务逻辑关联。 遍历数据结构的算法可能很大。把它放在集合或者主业务逻辑代码中，导致原有代码责任不明确且难以维护。把这些代码放在迭代器中让应用代码简洁和清晰。 当你想要一个单独接口来遍历不同的数据结构。 迭代器为所有实现者提供了通用的接口，允许在客户端代码中更换不同的迭代器。 如何实现 定义Iterator接口。它至少包含用来获取容器中下一个元素的方法。方便起见，它还可以包含获取上一个元素，追踪当前位置，检查是否到达迭代器尾部等方法。 创建Collection接口，它要提供获取一个新迭代器的方法。注意，它应当返回抽象迭代器类型。 为一个可迭代的集合实现一个具体的迭代器类。一个迭代器只能关联一个集合实例。通常通过迭代器的构造方法产生关联。 在相应的集合类中实现Collection接口。他们应当创建并返回一个适当的迭代器实例。集合通过迭代器的构造方法和迭代器建立关联。 在使用了这个模式后，在集合和客户端代码中应该不会再有遍历的代码。客户端每次需要迭代集合元素时都要通过集合获取新的迭代器。 优点 简化集合代码。 提供不同的方式遍历相同的数据结构。 允许并行遍历相同的集合。 缺点 对于使用简单集合的程序来说，有些导致矫枉过正。 和其他模式的关系 Iterator可以用来遍历Composite树。 Factory Method可以和Iterator一起使用，让集合的子类返回合适的迭代器。 Memento可以和Iterator一起使用来捕捉迭代器的当前状态，后面如果需要可以进行回滚。 Visitor可以和Iterator一起使用来遍历一个复杂的数据结构，并在这些元素上执行一些操作，即使他们类型不同。 小结Iterator可以在不暴露复杂数据结构的前提下让客户端顺序访问其元素。 Iterator模式在Java代码中很常见。很多框架和库都提供一种标准的方式来遍历他们的集合。 Java核心库中的java.util.Iterator和java.util.Enumeration是很好的例子。 参考翻译整理自：https://refactoring.guru/design-patterns/iterator]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-行为模式之Memento]]></title>
      <url>%2F2018%2F01%2F01%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%BC%8F%E4%B9%8BMemento%2F</url>
      <content type="text"><![CDATA[意图Memento是行为模式的一种，他允许你在不暴露对象内部结构的情况下捕获其内部状态，以便稍后对象可以返回到这个状态。 问题假设你在写一个文本编辑器。核心逻辑放在Editor主类中。另外一些特性，像文本格式化，内联图像等，放在不同的命令类中。 你决定让用户的操作变得可逆。换句话讲，要增加“撤销”功能。为了实现它，你需要在执行任何操作前保存Editor的状态。之后，如果用户决定还原他的一些操作，程序要从历史中拿出快照并恢复Editor到过去状态。为了拷贝一个对象的状态，你必须遍历它的字段并拷贝字段的值。但是，一个对象必须要有宽松的访问它内容的方式，可以让其他对象窥视其内部并拷贝他的内容。 虽然这种方式可以简单完成这个任务并且允许每个类都能够生产编辑器的备份，但是这种方式与我们的想法相去甚远。如果你决定重构或者修改Editor类的字段，你就必须同时修改那些和Editor耦合的类。 更近一步。我们考虑下真实的Editor备份。即使最原始的编辑器也必须有一些字段来存储数据，比如真实的文本，游标坐标，当前滚动的位置等。为了创建一个备份，你必须记录所有的值并把它们放到一些容器中。 这个容器中最终放置了一些类的对象。这些类可能有许多编辑器状态的镜像字段并且没有什么方法。为了允许其他对象能够读写数据到备份对象，你肯能需要把字段声明为public。但是，这将导致与无限制的Editor类相同的问题。Editor的变化将会影响其他的类。 看起来这个问题无解了。你要么暴露一个类的内部，使得所有关联的类变得脆弱，要么限制对状态的访问，使得撤销操作难以实现。难道没有其他方法了吗？ 解决上面问题的本质是破坏了封装。当一些对象试图做比他们想象的更多的事情时，往往会发生这种情况。这些对象不是请求其他对象为他们做一些事情，而是入侵了其他对象的私有空间来搜集执行动作需要的数据。 Memento模式把创建状态快照的工作委托给状态拥有者本身，也即是Originator对象。因此，也就不需要其他对象从外部拷贝Editor的状态，Editor本身就可以创建快照，因为它自己可以访问自己的所有状态。 模式提供了一种特殊对象来存储对象状态的快照，叫做Memento。memento的内容除了创建者自己外其他的对象都无法访问。其他对象可以通过限制性接口和menento交流，该接口只允许获取快照的元数据，比如创建时间，标签等。 这些数据保护允许把memento存储在叫做Caretakers的对象中。因为他们只能通过限制性接口访问menento，caretakers无法修改存储在里面的状态。 在编辑器例子中，我们创建一个单独的History类来扮演caretakers。它把memento组织成一个栈，每个操作被执行前它会被压入新的memento。当用户触发撤销操作，History弹出栈顶memento并把它传给Editor，请求回滚。因为Editor可以完全访问memento，它将用memento的状态值覆盖当前变量值。 结构嵌套类实现经典的实现方式依赖编程对嵌套类的支持，许多流行的编程语言（C++，C#和Java）都支持该方式。 Originator包含复杂的状态并且你不想把它们暴露出去。它能够自己创建快照，也能够在需要的时候从快照恢复。 Memento是一个值对象，用来扮演Originator状态的快照。最佳实践是将Memento做成不可变的，并且Memento只通过其构造方法接收一次数据。 Caretaker不仅知道何时及为什么要捕捉Originator的状态，也知道什么时候应该恢复状态。 caretaker能够把originator的状态存储成一个栈。当originator要回到历史时，caretaker拿到栈顶数据并把它传给originator的恢复方法。 这种实现的下，Memento是Originator的嵌套类，Memento可以访问Originator的变量和方法，即使他们被声明为private。另一方面，Caretaker被限制性访问Memento的字段和方法，这对存储memento很好但是对修改他们的状态不是很好。 中间接口实现不支持嵌套类语言（PHP）的替代方式。 在没有嵌套类的情况下，通过让caretaker使用有限接口和memento协作来限制其对memento的访问。 另一方面，originator可以直接和memento类协作并访问他的public方法，而caretaker不行。 更严格的封装实现当你不想给远程的其他类通过Memento来访问Originator状态时，这种方式很有用。 这种实现允许有多个类型的originator和memento。每个originator和其对应的memento协作。originator和memento不把他们的状态暴露给任何人。 Caretaker不能间接修改memento存储的状态。甚至，它独立与originator。和originator的关联及恢复方法都移动到memento中。 每个memento都关联指定的originator。originator把它自己和状态值一起传入到memento的构造方法中。由于具体的memento和originator之间的密切关系，memento可以恢复其originator的状态。 伪代码在这个例子中，采用Memento和Command模式来存储复杂的文本编辑器对象并在需要时恢复它。 command对象扮演caretaker，在它执行前请求editor创建一个memento。当用户需要回滚操作时，之前command关联的memento就可以反转编辑器的状态。 memento不需要有任何public的字段，set或者get方法。因此没有对象可以修改它的内容。memento和创建它的editor关联在一起，能够随意恢复它的状态。这就允许应用支持多个独立的编辑器窗口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// Originator class should have a special method, which captures originator's// state inside a new memento object.class Editor is private field text, cursorX, cursorY, selectionWidth method setText(text) is this.text = text method setCursor(x, y) is this.cursorX = cursorX this.cursorY = cursorY method setSelectionWidth(width) is this.selectionWidth = width method createSnapshot(): EditorState is // Memento is immutable object; that is why originator passes its state // to memento's constructor parameters. return new Snapshot(this, text, cursorX, cursorY, selectionWidth)// Memento stores past state of the editor.class Snapshot is private field editor: Editor private field text, cursorX, cursorY, selectionWidth constructor Snapshot(editor, text, cursorX, cursorY, selectionWidth) is this.editor = editor this.text = text this.cursorX = cursorX this.cursorY = cursorY this.selectionWidth = selectionWidth // At some point, old editor state can be restored using a memento object. method restore() is editor.setText(text) editor.setCursor(cursorX, cursorY) editor.setSelectionWidth(selectionWidth)// Command object can act as a caretaker. In such case, command gets a memento// just before it changes the originator's state. When undo is requested, it// restores originator's state with a memento.class Command is private field backup: Snapshot method makeBackup() is backup = editor.saveState() method undo() is if (backup != null) backup.restore() // ... 适用性 当你需要制作一些对象的快照以便稍后恢复其状态时。 Memento模式允许生成对象状态的完整副本，并将其与对象分开存储。虽然这种模式的“撤销”应用已经相当普遍，但在处理交易时也是不可或缺的（如果你需要在出错时会滚一个操作）。 当直接访问对象的字段/setter/getter违反了其封装时。 Memento让对象自己有能力创建自己状态的快照。其他对象不能读取这个快照，使得这个对象的状态变得安全可靠。 如何实现 确定那个类扮演Originator角色。知道程序使用这种类型的一个还是多个中心对象是很重要的（？）。 创建memento类。挨个声明Originator类需要镜像的字段。 让Memento对象不可变。他们应该通过构造方法一次性初始化字段的值。Memento类不应该有setter方法。 如果你的编程语言支持嵌套类，把Memento当作Originator的内部类。 如果不支持，抽象出一个memento类的一个接口，并让其他要和Memento关联的对象使用这个接口。你应该在接口中添加一些操作元数据的方法，但不要暴露originator的状态。 为Originator类添加创建memento的方法。Originator应该通过传递向memento构造方法传递它属性值的方式来创建一个新的memento实例。 这个方法的返回类型应当是之前抽象出来的接口类型（如果你提取了的话）。但是在这个方法内部，你要和具体的memento类型协作。 为Originator类增加恢复状态的方法。这个方法把memento对象当作参数之一。按照与上一步相同的逻辑分配参数类型。 对caretaker而言，不管是操作历史，命令对象，或者其他不同的实体，它都应当知道何时向originator请求一个新的memento，如何存储它以及恢复它。 caretaker和originator的关联关系可以移动到memento中。在这种情况下，每个memento都有与之对应的originator。它将有责任恢复originator的状态。但这仅当memento是originator的内部类或者originator提供了相应的复写其状态的setter方法时。 优点 没有破坏originator的封装。 通过允许caretaker来维护originator历史状态的方式，简化了originator的代码。 缺点 如果客户端频繁创建memento会浪费许多RAM。 caretaker需要追踪originator的生命周期以便清理过时的memento。 大多数动态编程语言，像PHP，Python或者JavaScript，不能保证memento中的状态是不变的。 和其他模式的关系 Command和Memento可以一起使用。他们可以充当魔法token，在稍后时间被传递和调用。在Command中，token代表一个请求；在Memento中，token代表一个对象在特定时间的内部状态。多态对Command很重要，但对Memento不重要，因为它的接口很狭隘所以只能被当作值传递。 Memento可以和Iterator一起只用来捕捉当前迭代的状态，在有必要的时候进行回滚。 如果一个对象想在历史中保存状态相对简单（没有外部资源的链接，或者这些链接很容易重新建立），Prototype可以作为Memento更简单的替代方案。 参考翻译整理自：https://refactoring.guru/design-patterns/memento]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式-行为模式之Command]]></title>
      <url>%2F2017%2F12%2F20%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%BC%8F%E4%B9%8Bcommand%2F</url>
      <content type="text"><![CDATA[意图Command（命令）是一种行为模式，让你可以把请求转换到单独的对象，可以用来把不同的请求参数化，排队或者记录请求，并且支持撤销操作。 问题假设你在做一个新的文本编辑器。你创建了一个Button类，可以被用做工具栏的按钮，也可以用作对话框的通用按钮。 这些按钮看起来很像，但是它们做不同的事情。此时我们要把针对不同按钮点击的处理代码放在哪里呢？简单的解决方法是为每个按钮创建一个Button的子类，然后把处理点击事件的代码放到子类中。 但是这么做的缺点很明显。首先，你创建了许多子类。其次，GUI代码依赖了易变的业务逻辑代码。还有更加讨厌的部分。一些操作，比如拷贝文本，可以在几个不同地方调用。比如，工具栏的按钮，上下文菜单的按钮或者使用Ctrl+C。当应用只有按钮时，拷贝逻辑的代码只会出现在CopyButton子类中。但是，现在你需要拷贝相同的代码到其他两个地方。 解决Command模式建议封装请求到它们各自的命令（command）对象中。如果这个操作有参数，把它们变成command类的字段。 大多数command作为客户端之间的链接，它们触发请求和接收对象，接收对象通过执行一些操作来处理它们。 现在command只有一个无参方法，让各个command遵循通用接口很容易。通常，一个command接口只有一个类似execute()的方法。一旦通用接口创建，你可以用command替换掉客户端代码之前耦合的特定操作。 在编辑器例子中使用了Command模式之后，你讲不再需要Button子类。基础类将需要增加一个字段来保存command对象的引用。一个按钮对象将把用户发起的点击请求委托给关联的command对象，而不是自己去完成处理。command要么他自己执行一些操作要么把它委托给一个业务逻辑对象。 你可以对上下文按钮和热键代码做类似处理。这些类将把工作委托给在它们之间共享的单个command对象。 因此，command类将使得GUI和业务逻辑类的衔接变得很方便。这只是Command众多优点中的一部分。 真实世界的类比在餐厅下单你到一个餐厅中并找了个靠窗的位置坐下。服务员拿走了你写在纸上的订单，把它贴在厨房的墙上，它之前还有其他订单。 正如你猜的那样，这个纸条就是一个command。它排在队列中知道一个厨师准备去做。这个订单包含了做这道菜的所有信息。他允许厨师立马开始做菜而不是跑来跑去来搞清楚订单的细节。 结构 Invoker保存Command对象的引用，并且当一个操作需要被执行的时候使用它。Invoker通过通用接口和command协作，这个接口通常只有一个execute()方法。Invoker不负责创建command对象。他们通常通过构造函数从客户端获取预创建的command。 为具体的Command声明接口。接口最少需要一个方法来执行实际操作。 具体的Command实现实际操作。一些command是自足的，不可变的。它们通过构造方法一次性接收所有必要的数据。其他的需要一个Receiver，作为外部的上下文对象。 Receiver包含特定命令所必需的业务逻辑或数据。命令可以查询这些对象的其他信息或整个操作委托给他们。在某些情况下，为了简单起见，可以将接收者的代码合并到命令类中。 Client创建并配置具体的Command对象。然后把他们传给适当的Invoker。 伪代码在这个例子中，Command模式用来记录操作历史，还可以还原它。不想之前的例子，这个应用每次用户操作都创建一个新的command。之后在帮助列表中会展示这些个性的命令。 在执行操作前，command会创建编辑器当前状态的备份。执行后，command把自己放到历史栈中。 客户端的代码，比如UI元素，command历史和其他类将不会和具体的command类耦合，因为他们通过command接口来协作。这就允许在不改变已存在代码的情况下新增command。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122// Abstract command defines the common interface for all concrete commands.abstract class Command is protected field app: Application protected field editor: Editor protected field backup: text constructor Command(app: Application, editor: Editor) is this.app = app this.editor = editor // Make a backup of the editor's state. method saveBackup() is backup = editor.text // Restore the editor's state. method undo() is editor.text = backup // The execution method is declared abstract in order to force all concrete // commands to provide their own implementations. The method must return // true or false depending on whether or not the command changes the // editor's state. abstract method execute()// Concrete commands.class CopyCommand extends EditorCommand is // The copy command is not saved to the history since it does not change // editor's state. method execute() is app.clipboard = editor.getSelection() return falseclass CutCommand extends EditorCommand is // The cut command does change the editor's state, therefore it must be // saved to the history. And it will be as long as the method returns true. method execute() is saveBackup() app.clipboard = editor.getSelection() editor.deleteSelection() return trueclass PasteCommand implements Command is method execute() is saveBackup() editor.replaceSelection(app.clipboard) return true// The undo operation is also a command.class UndoCommand implements Command is method execute() is app.undo() return false// The global command history is just a stack.class CommandHistory is private field history: array of Command // Last in... method push(c: Command) is Push command to the end of history array. // ...first out method pop():Command is Get the most recent command from history.// The editor class has an actual text editing operations. It plays the role of// a receiver: all commands end up delegating execution to the editor's methods.class Editor is field text: string method getSelection() is Return selected text. method deleteSelection() is Delete selected text. method replaceSelection(text) is Insert clipboard contents at current position.// The application class sets up object relations. It acts as a sender: when// something needs to be done, it creates a command object and executes it.class Application is field clipboard: string field editors: array of Editors field activeEditor: Editor field history: CommandHistory // The code which assigns commands to UI objects may look like this. method createUI() is // ... copy = function() &#123; executeCommand(new CopyCommand(this, activeEditor)) &#125; copyButton.setCommand(copy) shortcuts.onKeyPress("Ctrl+C", copy) cut = function() &#123; executeCommand(new CutCommand(this, activeEditor)) &#125; cutButton.setCommand(cut) shortcuts.onKeyPress("Ctrl+X", cut) paste = function() &#123; executeCommand(new PasteCommand(this, activeEditor)) &#125; pasteButton.setCommand(paste) shortcuts.onKeyPress("Ctrl+V", paste) undo = function() &#123; executeCommand(new UndoCommand(this, activeEditor)) &#125; undoButton.setCommand(undo) shortcuts.onKeyPress("Ctrl+Z", undo) // Execute a command and check whether it has to be added to the history. method executeCommand(command) is if (command.execute) history.push(command) // Take the last command from the history and run its undo method. Note that // we do not know the class of that command. But we don't have to, since the // command knows how to undo its own action. method undo() is command = history.pop() if (command != null) command.undo() 适用性 当你想要把行为参数化成对象。举个例子，你在开发一个用户接口组件，比如一个菜单，你想你的用户可以配置菜单元素被点击之后的行为。 Command模式将操作转换为可以从各种UI元素链接的对象。每个元素把工作委托给command对象而不是自己去做。command可以自己执行操作或者调用时昂的业务逻辑对象。 当你需要排队，规划，或者执行远程操作。 和其他任何对象以牙膏，command是可以序列化的，意味着它可以转换成一个字符串。这个字符串可以背保存到一个文件或者数据库并且稍后可以再把它转换成一个commadn对象。甚至，你可以通过网络发送一个序列化的command，然后在远程服务上恢复并执行它。 当你需要撤销操作。 想要支持撤销操作的第一件事就是保存历史。尽管有很多实现方式，Command模式或许是最流行的。 command历史栈由已执行的command对象组成。每个command在执行操作前线创建当前应用状态的快照。在操作完成后，command把自己压入历史栈中。注意，它始终保持应用程序状态的备份。当需要撤销时，程序从历史栈中拿到栈顶command并且恢复它存储的快照。 这个方法有两个缺点。首先，保存应用的状态不容易，因为一些是私有的。这个问题可以使用Memento模式缓解。 其次，状态的保存需要消耗大量RAM。因此，有时候你可以修改实现，不是恢复过去的状态，而是执行命令的逆操作。这个选择是昂贵的。反转操作通常很难以实现甚至不能实现。 如何实现 声明只有一个execute方法的Command接口。 在遵循通用Command接口情况下抽离操作到具体的Command实现中。把操作的参数转换成具体command类的字段。他们应当通过command的构造方法来初始化。 确保command中有字段来持有需要和它协作Receiver对象的引用。这个字段也应该通过构造方法来初始化。 识别Invoker类并为其提供用于存储command对象的字段。Invoker应当只通过Command的接口和command对象交互。他们通常不是自己创建command对象，而是从客户端获取。 应用的主要代码，看作Client，应该创建并配置具体的command并且传递给适当的Invoker对象。有时，多个Invoker可以使用相同的command对象。 优点 解耦操作调用和处理类。 允许撤销操作。 允许延迟操作。 允许简单命令组装成更大的命令。 符合开闭原则。 缺点 创建了多个额外类导致代码复杂度上升。 和其他模式的关系 Chain Of Responsibility，Command，Mediator和Observer处理连接请求的发送者和接收者的各种方式： 责任链沿着潜在接收者的动态链顺序传递一个请求，直到其中一个处理这个请求。 命令模式建立从发送者到接收者的单向连接。 调解模式持有发送者和接收者间接引用。 观察者会在同一时间把一个请求发送给所有关心的接受者，但是允许它们动态的确定是否继续订阅和取消订阅后面的请求。 责任链中的处理者可以表示为命令（Command）。在这种情况下，许多不同的操作可以在由请求表示的相同上下文中执行。 但还有另外一种方式，请求本身就是一个Command对象，沿着对象链传递。这种情况下，相同的操作可以在由链条对象表示的不同上下文中执行。 Command和Memento可以一起使用。他们可以充当魔法token，被延迟传递和调用。在Command中，token代表一个请求；在Memento中，它代表了某个特定时间的物体的内部状态。多态性对Command而言是重要的，但对于Memento来说却是非常重要的，因为它的接口太狭隘所以Memento只能作为一个值来传递。 Command和Strategy很像，因为他们都用于参数化一些行为的上下文。Command被用来转化任意操作到一个对象。操作的参数变成对象的字段。转换允许延迟或远程执行命令，存储命令历史等。 另一方面，Strategy模式通常来描述做相同事情的不同方式。它可以帮助在单个上下文类中交换这些算法。 在我们需要保存Command拷贝到历史中时Prototype可以提供帮助。 Visitor模式就像增强版的Command模式，可以对任何类型的对象执行操作。 小结Command是行为模式的一种，可以将请求或者简单的操作转换到对象中。这种转换允许延迟或者远程执行命令，存储命令历史等。 在Java中这种模式很常见。大多数情况下，它被用作参数化UI元素的动作回调。也被用来任务排队，追踪操作历史等。 Java核心库中的一些例子： java.lang.Runnable接口的所有实现 javax.swing.Action接口的所有实现 参考翻译整理自：https://refactoring.guru/design-patterns/command]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-行为模式之Chain-Of-Responsibility]]></title>
      <url>%2F2017%2F12%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%BC%8F%E4%B9%8Bchain-of-responsibility%2F</url>
      <content type="text"><![CDATA[意图责任链（Chain Of Responsibility）是一种行为模式，通过给多个对象一个机会去处理请求的的方式来避免请求发送者和接受者的耦合。责任链接收对象并且沿着链条传递它，直到一个对象来处理它。 问题假设你在做一个订单系统。你第一个任务就是限制用户对系统的访问，只有已经授权的用户可以创建订单。另外，一些用户拥有管理员权限，可以访问全部的订单。 你意识到这些检查必须顺序处理。程序能够在任何时候对用户进行尝试认证，只要用户的证书被请求传递。但是，如果未能对用户进行身份验证，则无法检查用户的权限。几个月后，你已经实现了这些顺序检查。 你的同时建议，将原始数据直接交给代码处理不安全。所以你添加了一个额外校验步骤来验证请求数据。 之后，其他人建议协同无法应对暴力的密码破解。为了解决这个问题，你添加了另一个检查来过滤重复使用相同用户名但是失败的请求。 你甚至添加了缓存来提升订单在高负载下的性能。 不幸的是，随着新特性的增加，代码变得越来越臃肿。甚至，你为了保护其他页面，把这些检查代码的一部分做了拷贝，导致出现重复代码片段。 这个系统变得难以维护。但是，一天你收到了重构系统的任务… 解决和其他行为模式很像，责任链依赖于将行为转化为独立的对象。在我们的例子中，每个检查都将被移动到不同的类中，这些类只有一个方法来执行这些检查。这个方法通过参数来接收请求数据。 现在，到了有趣的部分。模式建议连接这些对象到一个链条中。 每个处理者都有一个字段来存储这个链条中下一个处理者的引用。不管什么时候，一个处理者接收到一个请求，它可以把请求传递给链条中在其之后的处理者。这个请求沿着链条旅行知道所有的处理者都有机会来处理它。 最后，一个处理者不需要在继续传递这个请求。有两种流行的方式来处理这个想法。 在我们访问过滤的例子中，处理者排队并挨个处理他们的检查。流的终点只可能是某个检查失败或者到达链条尾部。 但还有一个略微不同的方式，处理者只会传递那些它们自己无法处理的请求。否则，它们执行自己的业务并且终止链条的执行。这个选项在处理GUI组件事件时很常见。 比如，当用户点击一个按钮，这个事件便沿着由按钮开始的组件链传播，传到他们的父组件，像form和panel，直到应用的窗口停止。这个事件被链条中第一个可以处理它的组件处理。这个例子值得一提，因为它告诉我们一个链条可以从一个树结构中抽离出来。 所有的处理者类都需要遵循一样的接口。这将让你可以在运行时使用各个处理者组合一个链条，而代码不会和处理者的具体实现类耦合。每个具体的处理者应该只关心自己的execute方法。 现实世界的类比技术支持你为你的PC买了一个新的显卡。Windows可以自动检测并启用他。但你钟爱的Linux却无法使用新硬件。抱着微小的希望，你打电话给技术支持。 首先，你听到了自动应答的机器人声音。它提出了九种解决各种问题的流行解决方案，但没有一个与你的问题有关。过了一会，机器把你转给在线客服。 客服也没有给出有用的解决方法，于是你请求联系一个正确的工程师。 客服把你转给了工程师。最后，这个工程师告诉你到哪下载显卡驱动及如何在Linux中怎么安装。于是，你愉快的结束了这通电话。 结构 Handler为所有具体的处理者声明一个通用接口。通常，它只有一个处理请求的方法，但有时候也会有设置链条下一个处理者的方法。 Base Handler是可选的类，它可以包含负责构建维护对象责任链的模版代码。 这个类可以包含一个字段来存储链条中下一个处理者。使用这个字段，客户端可以将多个处理者链接到一个链中。这个字段可以通过构造方法或者一个set方法来控制。这个类也可能有一个基本处理方法的实现，这个方法检查下一个处理者是否存在然后把执行传递给它。 Concrete Handlers包含处理请求的实际代码。接收到请求后，处理者必须决定是否处理该请求，另外还要决定是否在链条中继续传递它。 处理者通常是独立的和不可变的，通过构造函数参数一次性接收所有必要的数据。 Client可以只组装一次链条或者依赖于程序逻辑动态组装。注意，一个请求可以被发送到链中的任何处理者，它并不总必须是第一个。 伪代码在这个例子中，责任链负责显示活动UI元素关联的一个上下文帮助。 这些GUI元素是树状结构。Dialog类渲染树根的主窗口。中间层由Panel组成。叶子结点有：Component、Button、TextEdit等。 一个Component能够显示上下文提示，只要它有帮助文本。一些复杂的组件有他们自己的方式来显示上下文帮助。 当用户将鼠标光标指向组件并按下F1时，应用抓取这个组件并发送帮助请求。这个请求向上传递给所有父容器知道这个组件可以显示帮助。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// Handler interface.interface ComponentWithContextualHelp is method showHelp() is// Base class for simple components.abstract class Component implements ContextualHelp is field tooltipText: string // Container, which contains component, severs as a following object // in chain. protected field container: Container // Component shows tooltip if there is a help text assigned to it. Otherwise // it forwards the call to the container if it exists. method showHelp() is if (tooltipText != null) Show tooltip. else container.showHelp()// Containers can contain both simple components and other container as// children. The chain relations are established here. The class inherits// showHelp behavior from its parent.abstract class Container extends Component is protected field children: array of Component method add(child) is children.add(child) child.container = this// Primitive components may be fine with default help implementation...class Button extends Component is // ...// But complex components may override the default implementation. If a help can// not be provided in a new way, the component can always call the base// implementation (see Component class).class Panel extends Container is field modalHelpText: string method showHelp() is if (modalHelpText != null) Show modal window with a help text. else parent::showHelp()// ...same as above...class Dialog extends Container is field wikiPage: string method showHelp() is if (wikiPage != null) Open a wiki help page. else parent::showHelp()// Client code.class Application is // Each application configures the chain differently. method createUI() is dialog = new Dialog("Budget Reports") dialog.wikiPage = "http://..." panel = new Panel(0, 0, 400, 800) panel.modalHelpText = "This panel does..." ok = new Button(250, 760, 50, 20, "OK") ok.tooltipText = "This is a OK button that..." cancel = new Button(320, 760, 50, 20, "Cancel") // ... panel.add(ok) panel.add(cancel) dialog.add(panel) // Imagine what happens here. method onF1KeyPress() is component = this.getComponentAtMouseCoords() component.showHelp() 适用性 当一个程序有几个处理不同请求的处理者，但事先并不知道过来的是什么类型的请求。 你要把几个处理者放到一个链条中。请求沿着链条传递直到有个处理者能够处理它。 当要以特定顺序执行处理程序。 责任链允许按照给定的顺序依次执行处理者。 当有很多对象来处理请求，并且它们的顺序动态改变。 责任链允许对一个存在的链条中的处理者进行新增、移除或者排序操作。 如何实现 声明Handler接口，包含一个处理请求的方法。决定如何传递请求的信息到方法中。最灵活的方法是将请求数据转换为对象并传递给处理方法。 为了减少重复的样板代码，从Handler接口派生出一个抽象BaseHandler类是很值得的。 添加一个字段来保存下一个处理者的引用。这个字段可以从构造参数中获得初始化数据。你也可以定义一个set方法来修改这个字段。但仅当你想要在运行时想要修改链条才需要这么做。 实现处理方法，以便将请求转发给链中的下一个对象（如果有的话）。具体的处理者能够通过调用父类方法来转发请求。因此，它们不需要访问引用字段，你就可以把它声明为private了。 创建ConcreteHandler子类并且实现它们的处理方法。每个处理者在收到请求时应做出两个决定： 是否要处理这个请求。 是否要继续传递这个请求。 Client可以自己组装链条也可以从其他对象接收已经构造好的链条。在后一种情况下，可以采用工厂对象通过应用配置护着环境变量来构建链条。 Client可能触发链条中任意一个处理者，不仅仅只是第一个。这个调用将会沿着链条传递直到链条结尾或者一些处理者拒绝进一步传递它。 由于链条的动态特性，Client应该准备好处理以下情况： 有时一个链可能包含一个单一的链接。 一些请求可能无法到达链条的尾部。 一些请求到达链条尾部还未被处理。 优点 减少请求发送者和接受者的耦合。 遵循单一职责原则。 遵循开闭原则。 缺点 一些请求肯能到链条尾部仍未被处理。 和其他模式的关系 Chain Of Responsibility，Command，Mediator和Observer处理连接请求的发送者和接收者的各种方式： 责任链沿着潜在接收者的动态链顺序传递一个请求，直到其中一个处理这个请求。 命令模式建立从发送者到接收者的单向连接。 调解模式持有发送者和接收者间接引用。 观察者会在同一时间把一个请求发送给所有关心的接受者，但是允许它们动态的确定是否继续订阅和取消订阅后面的请求。 责任链通常和组合（Composite）结合使用。在这种情况下，一个组件的父类可以看作是他的后继者。 责任链中的处理者可以表示为命令（Command）。在这种情况下，许多不同的操作可以在由请求表示的相同上下文中执行。 但还有另外一种方式，请求本身就是一个Command对象，沿着对象链传递。这种情况下，相同的操作可以在由链条对象表示的不同上下文中执行。 责任链和装饰者（Decorator）的类结构很相似。它们都依赖于递归组合来在一系列对象中传递执行。但是它们也有几个关键区别。 责任链的处理者能够随意执行动作，之间相互独立。它们也能够随意终止请求的进一步传递。另一方面，各个装饰者扩展一个特定行为并应该保持其接口一致。另外，装饰者不允许随意中断链条的执行。 小结责任链允许请求烟盒潜在的处理链传递直到某个处理者处理这个请求。这种模式允许多个对象处理这个请求而不发送者类不需要和具体接受者类耦合。这个链可以在运行时动态组合遵循标准处理者接口的任何处理者。 在Java中比较流行的使用样例：在GUI类中向父组件传递事件；过滤访问请求。 在Java的核心类库中有些例子： javax.servlet.Filter#doFilter() java.util.logging.Logger#log() 当我们发现组织结构类似以下描述时，可能就采用了责任链模式：一个对象的行为方法间接调用其他对象中的相同方法，而所有对象都遵循共同的接口。 参考翻译整理自：https://refactoring.guru/design-patterns/chain-of-responsibility]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-创建模式之Singleton]]></title>
      <url>%2F2017%2F11%2F23%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E6%A8%A1%E5%BC%8F%E4%B9%8BSingleton%2F</url>
      <content type="text"><![CDATA[意图Singleton是创建模式的一种，让你可以确保一个类只有一个实例，并为此实例提供一个全局访问点。 问题Singleton同时解决了两个问题（违反了单一职责原则）： 确保一个类只有一个实例。最常见原因是控制一些共享资源，比如，数据库。 假设你已经创建了一个新对象，不久，又尝试创建一个新的。在这种秦光下，你想要老的那个对象而不是新创建一个实例。 它不能通过正常的构造方法完成，因为在设计上每个构造方法总是返回一个新对象。 为实例提供一个全局的访问点。听起来像一个全局变量，不是吗？但是你无法做一个只读的全局变量。任何可以访问这个变量的人都可以替换他的值。 还有另外一个问题：你不希望解决以前的问题的代码分散在你的程序中。它们最好放在一个类中，特别当你的代码已经依赖那个类时。 注意，Sigleton同时解决了上面两个问题。但是现在模式很流行，即使他只解决了其中一个问题人们也会把它称为Sigleton。 解决单例所有实现的都有以下两个步骤： 创建私有的构造方法。 创建静态的创建方法扮演构造方法的角色。这个方法使用私有的构造方法创建一个对象并把它保存在静态变量或者字段中。对这个方法的所有调用都将返回缓存的对象。 Singleton保持把单实例的生产代码放在一个地方–Singlton类的创建方法中。任何可以访问Singleton类的客户端也都可以访问他的创建方法。因此，他提供给我们Singleton实例的一个全局访问点。 真实世界的类比政府政府是Singleton模式的一个很好的例子。一个国家只能有一个官方政府。不管组件政府的个人身份如何，“X的政府”这个称号是全球的一个访问点，他可以识别这个组织的负责人。 结构 Singleton声明静态的方法getInstance()，这个方法返回相同的Singleton类实例。 Singleton的构造方法对客户端代码应当不可见。getInstance()应该是唯一的可以创建并获得Singleton对象的途径。 伪代码在这个例子中，数据库连接类扮演Singleton角色。这个类没有公开的构造方法，所以只有调用getInstance方法可以获取这个对象。这个方法混存第一次创建的对象，在随后所有的调用中都返回它。 单例模式保证他的类只有一个实例被创建。并且，他提供了实例全局访问点：这个静态方法getInstance。 123456789101112131415161718192021222324252627282930class Database is private field instance: Database static method getInstance() is if (this.instance == null) then acquireThreadLock() and then // Ensure that instance has not yet been initialized by other // thread while this one has been waiting for the lock release. if (this.instance == null) then this.instance = new Database() return this.instance private constructor Database() is // Some initialization code, such as the actual connection to a // database server. // ... public method query(sql) is // All database queries of an app will go through this methods. // Therefore, you can place a throttling or caching logic here. // ...class Application is method main() is Database foo = Database.getInstance() foo.query("SELECT ...") // ... Database bar = Database.getInstance() bar.query("SELECT ...") // The variable `bar` will contain the same object as the variable `foo`. 适用性 当程序需要提供给所有客户端一个类的一个可以实例。比如，一个单独的数据库对象，在程序的不同模块贡献。 除了特别的的创建方法，Singleton对客户端隐藏了所有创建类的新对象的方法。这个方法创建一个新对象或者返回之前已经创建过的已经存在的对象。 当你需要严格控制全局变量。 不想全局变量，Singleton保证只有一个类实例。除了Singleton本身，没有任何类可以替换缓存的实例。 Sigleton让你可以轻松改变这个限制。比如，允许任何数量的实例，你只需要在一个地方修改代码–getInstance()方法体内。 如何实现 在类中添加一个静态字段用来持有单实例。 声明静态的公开创建方法，它将用来检索单实例。 在创建方法中实现“懒初始化”。它应该在第一次调用时创建一个新实例，并把它放到静态变量中。在随后的调用中这个方法都返回这个实例。 把类的构造方法声明为私有。 把客户端代码中所有直接对构造方法的调用替换为对创建方法的调用。 优点 保证类只有一个实例。 提供实例的全局访问点。 允许懒实例。 缺点 违背单一职责原则。 面具坏设计（Masks bad design？）。 在多线程的环境下需要特别处理。 在单元测试中要无尽mock。 和其他模式的关系 Facade可以改造成Singleton，因为大多情况下，一个门面对象就足够了。 在一些情况下Flyweight和Sigleton很像，Flyweight把什么事情都减少到一个享元对象。但是记住，它们之间有两个基本的不同： 1.Singleton对象时易变的。Flyweight对象时不变的。 单例类只有一个类实例，而享元类有多个不同状态的实例。 Abstract Factory，Builder和Prototype都可以实现为Singleton。 小结Singleton在优缺点方面几乎和全局变量一样。尽管它们很好用，但却破坏了你代码的模块化。 在其他的上下文中，你可以使用一个依赖于Singleton的类。你将不得不携带Singleton类。大多数时候，在创建单元测试时会出现这个限制。 尽管许多开发着认为Singleton是反模式，但是在Java的核心类中也有许多例子： java.lang.Runtime#getRuntime() java.awt.Desktop#getDesktop() java.lang.System#getSecurityManager() Singleton可以通过一个返回相同缓存对象的静态创建方法来识别。 参考翻译整理自：https://refactoring.guru/design-patterns/singleton]]></content>
    </entry>

    
  
  
</search>

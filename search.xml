<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[译-设计模式-结构模式之Flyweight]]></title>
      <url>%2F2017%2F10%2F31%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E6%A8%A1%E5%BC%8F%E4%B9%8BFlyweight%2F</url>
      <content type="text"><![CDATA[目的Flyweight是结构模式的一种，通过在多个对象见共享对象状态的通用部分而不是让各个对象独自持有的方式来让你在可用的RAM中装入更多的对象。 问题在长时间工作后想要找些乐趣，你决定写一个简单的视频游戏。玩家能够在地图上移动并且可以相互射击。你决定实现一个真实的粒子系统并让它称为这个游戏的特性。子弹，导弹和爆炸产生的碎片应该到处飞舞并且能够给玩家分配经验。 过了一会，你最后一次提交代码并且把游戏发给了你的朋友，希望他能够立马玩起来。尽管游戏在你电脑上完美运行，但是你的朋友却不能玩起来。这个游戏总是在他的电脑上运行一会儿就崩溃。 在你看了日之后，发现是因为RAM不足导致了游戏崩溃。这个看起来和你的粒子系统有关。 每一个例子由一个包含和丰富数据的对象表示。在某一刻，当团战达到高潮，可用的RAM无法装入新创建的粒子，此时程序就崩溃了。 解决仔细检查Particle类，你会发现color和sprite数据是对象中最耗内存的字段。更糟糕的是，这些字段存储的是所有粒子都相同的数据。比如，所有的子弹都是相同的颜色和质地。 粒子的其他数据，像坐标，移动向量和速度是所有粒子唯一的。另外，这些字段的数据是实时变化的。对color和sprite这类保留常量而言，它们看起来就像粒子的可变上下文。 这些context-specific对象的变量数据通常被叫做“外在状态”，因为他们早对象外部变化。对象余下的状态，就是这些不可变的数据，被叫做“内在状态”。 Flyweight模式建议你不要再对象内部存储外部状态，而是通过调用方法时当作参数传递进来。通过这种方式你就可以把不可变状态留在对象内，这样你就可以在不同的上下文环境中重用它。更重要的，你将会需要很少这种对象，因为仅仅出现在固有状态不同时，而这种状态并不多。 就我们的游戏而言，只需要三个粒子对象就能满足（子弹，导弹和碎片）。现在你应该猜到了，这种分离对象的方式就叫做“flyweight”（享元，这个术语来自拳击，表示选手小于111磅）。 外部状态存储但是我们在那里做外部状态的移动？用一些类来持有他，对吗？大多情况下，把这些数据移动到容器中是很便利的，该容器用于在应用模式之前聚合对象。 在我们的例子中，它是主要游戏对象。你可以创建额外的数组字段来存储坐标，向量和速度。另外，你也需要其他的数组来存储表示一个粒子的指定享元对象的引用。 等一下！难道我们不需要在一开始就需要有相同数量的上下问对象？从技术上讲，需要。但事实是，这些对象要比之前小太多了。最耗内存的字段现在仅存活在几个享元对象中。上千个上下文对象可以连接并且重用单个享元对象，而不是复制状态到内部各自存储。 不可变性因为相同的享元对象可以被用在不同的上下文中，你必须确保它们的状态不能被改变。享元应该智能通过构造参数来接收内部状态。它们不应该暴露set方法或者称为公开字段。 享元工厂你可以创建一个工厂方法来管理已经存在享元对象的池子。这个方法接收客户端期望的内部状态，并能够在已经存在的享元对象中匹配这个状态，如果找到就返回它。如果没有找到，它将创建一个新享元并且把它加入池子。 有几个地方可以放置该方法。通常的做法是放在享元容器中。另外，一个新工厂类应该被创建。你甚至可以把工厂方法做成静态的，并将其放在主要的Flyweight类中。 结构【structure.png】 不要忘记，Flyweight模式是一种优化，只有在使用大量相似对象的程序中才有意义。模式把对象的状态分成两个部分：享元和上下文。 Flyweight保存能够在多个对象之间共享的原始对象状态的一部分。相同的享元对象可以被用在许多不同的上下文中。被保存在享元中的状态叫做“内部状态”。原始对象状态的另一部分通过参数传递给flyweight的称为“外在状态”。 Context包含外部状态，就是对所有原对象都唯一的那些。当一个上下文和一个享元对象结合起来，它就表示来一个原对象的所有状态。 大多情况下，原对象的行为保留在Flyweight类中。在这种情况下，不管是谁调用一个享元方法，必须把外部状态通过方法参数传递进来。另一方面，这个行为也可以放在Context类中，把连接的享元仅当作数据对象。 Client计算或者存储享元的外部状态。从一个客户端角度看，一个享元就是一个模版，可以在运行时通过调用带有上下文数据参数的方法进行配置。 Flyweight Factory管理已经存在享元的池子。客户端不直接创建享元。它们调用享元工厂的方法并且告诉这个创建方法它们期望得到享元的内部状态。工厂先去享元池中查找，如果这种享元已经存在就直返回，否则，就创建一个新的。 伪代码在这个例子中，享元模式帮助在画布上渲染一百万棵树。模式从一个主Tree类中抽离出重复的内部状态并把它放到一个享元类TreeType中。 现在不是将相同数据存储在多个对象中，而是把它们保留在几个享元对象中并且被响应的Tree对象连接（译者注：引用）。客户端代码通过享元工厂和不同的书协作，这个工厂封装了在新树对象中重用现有树类型的逻辑。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// The Flyweight class contains only a portion of state that describes a tree.// These field store values that hardly unique for each particular tree. You// won't find here tree coordinates, however textures and colors shared between// multiple are here. And since this data is usually BIG, you'd waste a lot of// memory by keeping it in each tree object. That's why we extract texture,// colors and other data to a separate flyweight class that can be referenced// from all those similar trees.class TreeType is field name field color field texture constructor Tree(name, color, texture) &#123; ... &#125; method draw(canvas, x, y) is Create a bitmap from type, color and texture. Draw bitmap on canvas at X and Y.// Flyweight factory decides whether to re-use existing flyweight or create a// new object.class TreeFactory is static field treeTypes: collection of tree types static method getTreeType(name, color, texture) is type = treeTypes.find(name, color, texture) if (type == null) type = new TreeType(name, color, texture) treeTypes.add(type) return type// Context object contains extrinsic part of tree state. Application can create// billions of these since they are pretty thin: just two integer coordinates// and one reference.class Tree is field x,y field type: TreeType constructor Tree(x, y, type) &#123; ... &#125; method draw(canvas) is type.draw(canvas, this.x, this.y)// Tree and Forest classes are Flyweight's clients. You might merge them// together if you don't plan to develop a Tree class any further.class Forest is field trees: collection of Trees method plantTree(x, y, name, color, texture) is type = TreeFactory.getTreeType(name, color, texture) tree = new Tree(x, y, type); trees.add(tree) method draw(canvas) is foreach tree in trees tree.draw(canvas) 适用性 当你在给定的RAM中难以装下必须要支持数量级的对象时。 应用Flyweight模式的好处在很大程度上取决于使用方式和位置。它常用在： 一个需要大量对象的应用； 这些对象占用系统全部RAM； 对象包含重复对象，并且它们可以被抽离并且共享。 如何实现 将一个类的字段划分享元，从以下两方面入手： 内部状态：字段包含不变的数据，许多对象的该字段值重复； 外部状态：字段包含上下文数据，所有对象的这个字段值都不一样。 把那些代表内部状态的字段保留在这个类中，并确保它们的不便性。它们应仅仅能通构造方法接收数据。 将外在状态的字段转化为引用它们的方法的参数。 创建一个享元工厂类。它应该在创建新享元之间检查该享元是否已经存在。客户端必须从享元工厂中请求享元。客户端需要在获取享元时需要像工厂方法描述它们期望的享元。 客户端必须存储或计算外部状态（上下文）的值以便能够调用flyweight对象的方法。 优点 节省RAM，因此允许一个程序支持更多对象。 缺点 在查找或者计算上下文时浪费CPU。 创建类更多的额外类增加代码复杂度。 和其他模式的关系 Flyweight常常和Composite结合使用来实现叶子结点共享和节约RAM。 Flyweight展示如何让创造更多小对象，而Facade告诉我们如何让用一个单独对象来代表一个完整子系统。 当每件事情都减少成一个享元对象时，Flyweight就和Singleton很像了。但是请记住，它们两者之间有两个根本区别： 单例对象是可变的。享元对象是不可变的。 Singleton的实力职能有一个，而Flyweight类可以有多个不同内部状态的实例。 Java中模式的应用用例：Flyweight目的单一：最小化内存占用。如果您的程序不会遇到RAM不足，那么你可以暂时忽略此模式。 Java核心库中Flyweight的例子： java.lang.Integer#valueOf(int) (also Boolean, Byte, Character, Short, Long and BigDecimal) 鉴定：Flyweight可以通过创建方法来识别，该方法返回缓存的对象，而不是创建新的对象。 参考翻译整理自：https://refactoring.guru/design-patterns/flyweight]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-结构模式之Proxy]]></title>
      <url>%2F2017%2F10%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E6%A8%A1%E5%BC%8F%E4%B9%8BProxy%2F</url>
      <content type="text"><![CDATA[意图Proxy是结构模式的一种，它能够让你为另外一个对象提供一个替身或者占位符来控制对它的访问。 问题为什么要控制对对象的访问？比如：你有一个需要消耗大量系统资源的对象。你时不时会用到它，但不是一直使用。 因此，这个对象不用再程序启动时创建，而是当真正需要它的时候再创建。每个用到这个对象的客户端可能都有一些延迟实例化代码。显而易见，它导致了大量重复代码。 理想状态下，我们可以直接在对象类中加入代码，但不总是这样。比如，这是第三方库中的类。 解决Proxy模式建议创建一个和原服务对象遵循相同接口的替代类。当接收到客户端的请求时，代理对象创建一个服务对象的实例并把真正工作委托给他。 但是有什么好处呢？你可以在调用真正服务对象方法之前（或之后）在代理类中加入一些代码。因为代理和服务对象遵循相同的接口，它可以传递服务对象可以接受的任何代码。 现实世界类比支票支票是一种文件，可以命令银行从个人账户支付特定金额给持有支票的人。支票和现金都有一个通用的接口：可以用作付款。因此，支票是一大堆现金的代理。 站在消费者角度看，支票很棒，因为没有必要携带大量的现金。对于店主来说，他们也很好，因为可以在最近的银行兑换现金。 结构 Service interface为Service和Proxy生命了通用接口。 Service是一个提供有用业务逻辑的类。 Proxy有一个持有Service对象的字段。Proxy的方法做一些中间工作，并且大部分时间将请求传递给服务对象的相同方法。 大多情况下，Proxy管理它们的Service对象的声明周期。 Client应该同Service和Proxy通用接口协作。这样就可以把Proxy对象传递给任何期望一个Service对象的代码。 伪代码在这个例子中，Proxy模式帮助实现懒实例化并且为一个低效的第三方Youtube集成库做缓存。 原视频下载类在之前已经下载过的情况下也会再去下载这个视频。代理类仅会使用原下载器下载一次相同的视频，然后把它缓存下来，随后相同的请求会直接返回缓存。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// The interface of a remote service.interface ThirdPartyYoutubeLib is method listVideos() method getVideoInfo(id) method downloadVideo(id)// Concrete implementation of a service connector. Methods of this class can// request various info from youtube. Request speed depends on a user's internet// connection as wells as Youtube's. Application will slow down if a lot of// requests will be fired at the same time, even if they are requesting the// same info.class ThirdPartyYoutubeClass is method listVideos() is Send API request to Youtube. method getVideoInfo(id) is Get a meta information about some video. method downloadVideo(id) is Download video file from Youtube.// On the other hand, to save some bandwidth, we can cache request results and// keep them for some time. But it might be impossible to put such code directly// to the service class: it could be provided by third party library or/and// defined as final. That is why we put the caching code to a new proxy class// which implements the same interface as a service class. It is going to// delegate to the service object only when the real requests have to be sent.class CachedYoutubeClass implements ThirdPartyYoutubeLib is private field service: ThirdPartyYoutubeClass private field listCache, videoCache field needReset constructor CachedYoutubeClass(service: ThirdPartyYoutubeLib) is this.service = service method listVideos() is if (listCache == null || needReset) listCache = service.listVideos() return listCache method getVideoInfo(id) is if (videoCache == null || needReset) videoCache = service.getVideoInfo(id) return videoCache method downloadVideo(id) is if (!downloadExists(id) || needReset) service.downloadVideo(id)// The GUI class, which used to work with a service object stays unchanged. But// only as long as it works with the service object through an interface. We can// safely pass here a proxy object instead of a real service object since both// of them implement the same interface.class YoutubeManager is protected field service: ThirdPartyYoutubeLib constructor YoutubeManager(service: ThirdPartyYoutubeLib) is this.service = service method renderVideoPage() is info = service.getVideoInfo() Render the video page. method renderListPanel() is list = service.listVideos() Render the list of video thumbnails. method reactOnUserInput() is renderVideoPage() renderListPanel()// Application can configure proxies on the fly.class Application is method init() is youtubeService = new ThirdPartyYoutubeClass() youtubeProxy = new CachedYoutubeClass(youtubeService) manager = new YoutubeManager(youtubeProxy) manager.reactOnUserInput() 适用性 懒初始化（虚拟代理）。当你有一个需要从文件系统，网络或者数据库加载数据的重量级对象时。 不是在应用启动时加载数据，而是将对象的初始化延迟到需要它的时间。 访问控制（保护代理）。当一个程序有不同类型的用户并且你想阻止未授权用户对保护对象的访问。比如，当对象是操作系统的关键部分，并且程序（包括恶意的）是他们的客户端。 代理会在每次请求时检查客户端的证书，只会让拥有正确访问权限请求通过。 本地执行一个远程服务（远程代理）。当一个真实服务对象在远程服务器上时。 在这种情况下，代理会把客户端的请求通过网络传递到远程服务，处理所有网络传输细节（译者注：Dubbo等RPC框架）。 缓存对象（智能引用）。当你需要混存客户端的请求并且管理它们的生命周期时（当结果比较重时）时。 Proxy能够统计引用服务对象或者缓存结果的数量。当所有的引用被释放，代理就可以销毁它追踪的对象（比如，终止数据库链接）。 Proxy还可以追踪客户端是否改变了服务对象。它可以重用未改变的对象并且保存系统资源。 请求日志（日志代理）。当你需要保留一个服务对象的请求历史。 Proxy可以在传递给服务对象之前记录下每次请求。 如何实现 从一个服务类抽象出代理和服务对象的通用接口。你可能需要创建一个服务类的子类作为被代理类，因为服务类可能是闭合的。 创建一个代理类。你应该用一个字段来持有服务对象的强引用。大多情况下，代理类自己创建它自己需要的服务对象。少数情况下，客户端通过构造代理类的构造方法把服务传递给代理。 根据目的来实现代理方法。大多情况下，在做一些事情后，代理类应该把工作委托给服务对象。 想想可以引入工厂对象来决定客户端需要什么样的对象，代理或真正的服务。另一方面，这个逻辑也可以在一个代理类中的一个创建方法中。 考虑添加懒初始化服务对象。这对比较重的对象很有用处。 优点 客户端无感知情况下控制对对象的访问。 可以在服务对象没有准备好时开始工作。 管理服务对象的生命周期，即使客户端并不关心。 缺点 延迟响应。 和其他模式的关系 Adapter提供不同的接口达到目的，而Proxy提供相同的接口。Decorator提供增强的接口。 Facade和Proxy很像，它们给复杂的实体提供缓冲并且初始化它。不像Facade，Proxy模式和服务对象遵循一样的接口，他们是通用的。 Decorator和Proxy结构相似，但目的不同。两者均采用组合的方式来把工作委托给其他对象。然而，Proxy自己管理服务对象的生命周期，而Decorator由客户端管理。 在Java中的使用用例：虽然代理模式在大多数Java程序中不是常客，但在某些特殊情况下，它是非常方便的。当你想在一些现有的类的对象中添加一些额外的行为而不改变客户端代码时，它是不可取代的。 在标准Java库中有一些例子： java.lang.reflect.Proxy java.rmi.* javax.ejb.EJB (注释) javax.inject.Inject (注释) javax.persistence.PersistenceContext 鉴定：代理将真正的工作全部委托给其他对象。每个代理方法应该最终引用一个服务对象，除非代理是服务的一个子类。 参考翻译整理自：https://refactoring.guru/design-patterns/proxy]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-结构模式之Facade]]></title>
      <url>%2F2017%2F10%2F21%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E6%A8%A1%E5%BC%8F%E4%B9%8BFacade%2F</url>
      <content type="text"><![CDATA[目的Facade是结构模式的一种，它让你可以为一个复杂的系统，类库或者框架提供一个简单的接口。 问题想象一下，代码必须和一大堆复杂的框架或者类库协作。你必须手动实力话这些对象，跟踪依赖，正确的顺序关系等等。 最后，你的业务逻辑类会和第三方类库的实现紧密耦合。这些代码难以理解和维护。 解决门面是一个类，它为一个包含很多类的复杂子系统提供一个简单的接口。相对直接调用子系统而言，门面提供有限的功能。它仅提供客户端关心的那些特性。 当你在使用一个拥有很多模块的的复杂类库，但是你只用到其中一部分功能时，使用门面模式就显得很便利。 比如，一个上传短视频到Youtube伤的app使用了一个专业的视频转换类库。但是它真正需要的只是一个拥有encode(filename,format)方法的类。创建这种类之后，你变有了第一个门面。 现实世界的类比电话下单当你用电话向一个商店下单时，话务员就是所有服务和部门的门面。他或者她提供了下单，支付，配送的简单接口。 结构 Facade（门面）为访问子系统的特定功能提供方便。它知道怎样引导客户的请求和怎样为所有moving parts做准备。 Additional facades用来隔离功能和阻止源门面变成另外一个复杂结构。Additional facades也可以被客户端或者其他门面使用。 Complex subsystem（复杂的子系统）包含很多类。为了让他们做一些有意义的事情，你必须知道它的实现细节，初始化顺序等很多事情。 注意：子系统并不关心门面的存在，它直接和其他模块协作。 Client使用门面代替直接调用子系统对象。 伪代码在这个例子中，门面简化了和一个复杂视频转换框架的协作。 门面是一个单独的类，它提供一个公开的方法来处理框架复杂的配置并返回一个正确的格式。 通过这种方式，门面模式保证客户端代码简单、干净、可靠。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// Some classes of a complex 3rd-party video conversion framework. We don't// control that code, therefore can't simplify it.class VideoFile// ...class OggCompressionCodec// ...class MPEG4CompressionCodec// ...class CodecFactory// ...class BitrateReader// ...class AudioMixer// ...// To defeat the complexity, we create a Facade class, which hides all of the// framework's complexity behind a simple interface. It is a trade-off between// functionality and simplicity.class VideoConvertor is method convertVideo(filename, format):File is file = new VideoFile(filename) sourceCodec = new CodecFactory.extract(file) if (format == "mp4") distinationCodec = new MPEG4CompressionCodec() else distinationCodec = new OggCompressionCodec() buffer = BitrateReader.read(filename, sourceCodec); result = BitrateReader.convert(buffer, distinationCodec); result = (new AudioMixer()).fix(result); return new File(result)// Application classes don't depend on a billion classes provided by the complex// framework. Also, if you happen to decide to switch framework, you will only// need to rewrite the facade class.class Application is method main() is convertor = new VideoConvertor(); mp4video = convertor.convertVideo("youtubevideo.ogg", "mp4"); mp4video.save(); 适用性 当你需要一个简单但是功能有限的复杂子系统接口时 通常，子系统随着时间的推移变得越来越复杂。即使使用了设计模式也难避免创建更多的类。子系统可能变的更加灵活并且在不同的环境中复用性更高，但是它的样板代码数量也会随之增长。门面模式尝试通过提供访问子系统的一部分来适应更多客户端的需要。 当你想把一个子系统构建成层 创建门面来定义每个层子系统的连接点。如果多子系统之间相互依赖，你可以通过要求子系统只能通过门面交互来限制耦合。 如何实现 检查是否可以使用简化的接口和一个复杂的子系统交互。 如果接口使客户端没有子系统的依赖，你就在正确的轨道上。 创建一个门面类并在接口中描述它。它必须能够引导客户端调用适当的子系统对象。门面应该关心子系统正确的初始化。通常，这些代码在门面的构造方法中，懒实例化往往比较有用。 如果客户端仅和门面协作，你将得到巨大的收益。在这种情况下，客户端不需要关心子系统代码的变化。比如，当一个库的代码更新世，你只需要修改门面。 如果这个门面变的太大，请考虑抽离出一个新的门面。 优点 分离客户端和子系统组件。 客户端代码和子系统最小耦合。 缺点 门面可能造成god object，它和所有应用类耦合。 和其他模式的关系 Facade重新定义了一个接口，而Adapter重用了一个老接口。记住，Adapter使两个已存在接口协作，反对完全重新定义一个接口。 Abstract Factory可以用来替代Facade来隐藏平台特定的类。 Flyweight展示如何制造更多小对象，而Facade展示如何使用一个对象代表整个子系统。 Meditor在抽象已存在类的功能上和Facade很像。Mediator抽象/集中两个随意交互的协作对象。它常规的做法是“add values”，并且协作对象间相互知道被引用。相比之下，Facade为子系统定义了一个简单的接口，它并不添加新功能，并且子系统类不知道它的存在。 Facade可以被改造成Singleton，因为大多情况下单例门面对象就够了。 Facade在缓冲一个复杂实体和初始化这点上和Proxy很像。不像Facade，Proxy模式和他服务的对象拥有相同的接口，使得它们是通用的。 Java中模式的使用用例：在用Java写的app中，门面模式很常见。它特别用来处理和复杂类库和API协作的情景。 鉴定：Facade可以在具有简单接口的类中被识别，但是它将大部分工作委托给其他类。通常，门面管理它们使用对象的生命周期。 参考翻译整理自：https://refactoring.guru/design-patterns/facade]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式-结构模式之Composite]]></title>
      <url>%2F2017%2F10%2F20%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E6%A8%A1%E5%BC%8F%E4%B9%8BComposite%2F</url>
      <content type="text"><![CDATA[目的Composite是结构设计模式的一种，允许你像树一样组合对象，并且允许客户端像单个对象一样和这些结构协作。 问题Composite模式只有在你的业务模型可以被表示为一个树结构时才有意义。 比如，你有两个对象：Product和Box。这个Box可以包含几个Product和一些更小的Box。这些更小的Box也可以包含一些Product或者更小的Box等等。 现在，想象你的Product和Box是订单的一部分。计算订单的总价会非常困难。你拿到了一个大的Box，打开后看到它里面还有：ProductA，ProductB或者其他的Box，让我们再看看它里面有什么…不久，你将会停在一堆胶带和纸盒上，但仍在尝试计算总价。 那么，有更好的方法吗？ 解决Composite模式建议通过让Product和Box都遵循一个拥有getPrice()方法的通用接口来解决这个问题。 对Product来讲，它仅需要返货这个产品的价格。但是Box需要有更多的有趣行为。一个Box需要遍历它的内容并且寻味每一个商品（item）的价格。所以，如果一个商品是产品，它会立即返回价格。如果是一个更小的Box，它也需要遍历它自己商品的价格直到返回一个总价。一旦小计计算出来，Box甚至可以对总价做一些额外操作，像包装价之类。 现在，通过这个途径我们不必太过关心树的具体对象。不管是单个Product还是复杂的Box，你通过一个通用接口来操作它。并且，这个结构可以自己传递请求。 现实世界的类比军事结构大多数国家的军队看起来就像组合树。最底层，是一些士兵。它们组合成班。班组合成排。排组合成师。最后，几个师组成军队。 命令下达给层级的最高层，然后层层向下传递直到每个士兵都知道他们要做什么。 结构 Component为这个树结构的所有简单的和复杂的元素声明一个通用的接口。 Leaf是一个树的一个基本元素，它没有子节点。 因此它们没有任何委托对象，叶子节点通畅要做大多真正的工作。 Container（也叫做Composite）是一个有子节点的元素：叶子（Leaves）或其他容器（Container 或 Composite组合）。容器不需要知道子节点的类型，因为它们都实现了Component接口。 收到请求后，容器把它们委托给子节点，然后在返回给客户端之前运行并合计结果。 Client通过Component接口来使用树上的所有元素。 因此，客户端不需要关心它到底是在用简单的叶子还时复杂的容器。 伪代码在这个例子中，Composite模式帮助我们实现堆叠几何形状。 CompoundGraphic是一个容器，由任意数量的子形状，包括其他组合形状。组合形状和简单形状拥有相同的方法。但是，组合形状自己并不做实际的工作，它把请求传递给子形状，递归遍历自己的叶子节点和组合形状下的子节点。最后容器合并结果返回给客户端。 客户端通过接口和所有形状协作，这些形状都遵循这个接口。这样，客户端代码可以与非常复杂的结构一起工作，而不需要耦合具体的树形元素类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// Common interface for all components.interface Graphic is method move(x, y) method draw()// Simple component.class Dot implements Graphic is field x, y constructor Circle(x, y) &#123; ... &#125; method move(x, y) is this.x += x, this.y += y method draw() is Draw a dot at X and Y.// Components could extend other components.class Circle extends Dot is field radius constructor Circle(x, y, radius) &#123; ... &#125; method move(x, y) is this.x = x, this.y = y method draw() is Draw a circle at X and Y and radius R.// The composite component includes methods to add/remove child components. It// tries to delegates to its children all operations defined in the// component interface.class CompoundGraphic implements Graphic is field children: array of Graphic method add(child: Graphic) is Add child to children array. method remove(child: Graphic) is Remove child to children array. method move(x, y) is For each child: child.move(x, y) method draw() is Go over all children and calculate bounding rectangle. Draw a dotted box using calculated values. Draw each child.// Application can operate with specific components or whole groups.class ImageEditor is method load() is all = new CompoundGraphic() all.add(new Dot(1, 2)) all.add(new Circle(5, 3, 10)) // ... method groupSelected(components: array of Graphic) is group = new CompoundGraphic() group.add(components) all.remove(components) all.add(group) // All components will be drawn. all.draw() 适用性 当你需要实现一个像树一样有着简单元素和容器的结构 Composite模式提供两种基本元素：简单叶子和可以存储其他叶子或者其他容器等的复杂容器。模式强制容器和它的子元素遵循通用的接口，这样就允许递归整个树结构操作。 当客户端应该统一处理简单和复杂的元素时。 感谢通用叶子和容器均遵循了通用接口，客户端代码不需要关心协作对象的类型。 如何实现 确保你的业务逻辑可能够被当作树结构。尝试把它们分离成简单元素和容器。切记，容器能够包含基本元素和其他容器。 定义Components（组件）的通用接口。它应该包含对简单和复杂组件来讲都合理的操作。 创建代表基本组件的Leaf（叶子）类。顺便说下，一个程序中可以有多个叶子类。 创建拥有可以存储子组件（数组）的Container类。这个字段可以存储叶子和容器，所以它要被声明为Component类型。 在实现Component接口的方法时，记住，Container应该把它的多数工作委托给子组件。 最后，为Container实现add/remove子元素的方法。 记住，这些操作应该被放在Component接口中。它喂饭了接口分离原则，因为这些方法在Leaf类中是空的。但是另一方面，树中所有的组件变得与客户端的立场相当。 优点 简化必须与复杂树结构交互的客户端代码。 添加新组件类型变的简单。 缺点 创建了一个太过通用的类设计。 和其他模式的关系 Builder可以用来一步一步的构建一个复杂的Composite。 Chain of Resopnsibility通常和Composite结合使用。在这种情况下，组件的父级可以作为其后继。 Iterator可以用来遍历Composite树。 Visitor用来操作Composite树的实体。 Flyweight场合Composite结合使用来实现叶子结点共享和保存RAM。 Composite和Decorator结构图很相似，因为它们都依赖递归组合来组织开放数量的对象。 Decorator可以看作只有一个组件的弱化Composite。然而，Decorator给对象赋予了额外责任，而Composite仅是对所有拥有相同行为的子元素做了“合并”。 但是它们也可以合作：Composite能够用Decorator改变树组件的行为。 使用Composite和Decorator模式使得设计笨重，可以使用Prototype来简化。它允许克隆复杂结构，而不是重新构造它们。 Java中模式的使用用例：Composite模式在Java代码中很常见。它常用来表示用户接口组件的层级或者和图像一起使用的代码。 这有一些在标准Java苦衷使用组合的例子： java.awt.Container#add(Component) (几乎遍及Swing组件) javax.faces.component.UIComponent#getChildren() (几乎遍及JSF UI 组件) 鉴别：组合模式很容易识别，它们的行为方法都有一个在树结构中具有相同抽象/接口类型的实例。 参考翻译整理自：https://refactoring.guru/design-patterns/composite]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-结构模式之Bridge]]></title>
      <url>%2F2017%2F10%2F17%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E6%A8%A1%E5%BC%8F%E4%B9%8BBridge%2F</url>
      <content type="text"><![CDATA[目的Bridge是结构模式的一种，它可以帮你分离一个巨大的类或者将一组关系相近的类分离成为两个独立的层次结构，抽象和实现，可以各自独立开发。 问题抽象？实现？听起来害怕？我们首先来看个简单的例子。 你有一个几何Shap类，他有一对子类：Square和Triangle。你希望扩展这个层次结构来融入颜色以便创建红色和蓝色的形状。但是因为你已经有子类，你需要创建4个类来组合，比如BlueSquare和RedTriangle。 添加更多的形状类型和颜色将会导致层级结构变的更大。比如，添加一个Circles，你必须创建两个子类，每个对应一种颜色。之后，再添加新的颜色就需要为每个形状添加一个子类。再往后发展，将会变的更糟。 解决我们每次在扩展类层次到几个独立纬度时都会碰到这个问题。 Bridge模式尝试通过用委托替换继承来解决这个问题。你必须将其中一个维度抽离到不同的层次结构中。原类将通过持有新层次结构中的一个对象的引用的方式来替换在一个类中保留它所有的状态和行为的方式。 通过这种方式我们抽离出Color和它的两个子类，Red和Blue。Shape类将持有一个颜色类的引用域。当我们需要时通过这个引用把工作委托给color对象。这个引用在Shapps和Color之间像桥一样提供服务。从现在开始，添加color将不再需要改变shape类，反之亦然。 抽象（Abstraction）和实现（Implementation）在GoF的书中把“抽象和实现”一词作为Bridge模式定义的一部分。在我看来，那样太过学术并且使得这个模式变的更加难以理解。通过上面那个简单的例子，让我们看下GoF的真正意思。 抽象（Abstraction），也叫做接口（Interface），是一些实体的控制层。它们自己并不做任何真正事情，而是把大多工作委托给实现（Implementation）层，有时叫做平台（Platform）。不要把接口和抽象类和你的编程语言混淆，他们不是一回事。 比如，当我们谈到真正的应用是，抽象可以表示用户图形界面（GUI），实现可以表示响应用户交互的GUI层调用系统底层操作的API。 有两个方向来将应用扩展： 有一些不同的GUI（用户GUI和管理GUI） 支持一些不同的API（可以工作在Windows，Linux和MacOS下） 这个程序的代码看起来像“巨大的意大利面条碗”，有着成吨的连接不同GUI和API行为的操作条件。 可以通过对所有接口-平台的变体进行子类化来改进代码。但实际上，这个将导致我们已经在形状例子中看到的同样的问题。类层次将爆发时增长，每个新GUI或者API类型将需要增加一些组合类。 Bridge模式建议把这些类分成两个层次： 抽象层（Abstraction）：应用的GUI层。 实现层（Implementation）：操作系统API。 抽象对象持有一个具体实现对象的引用。只要遵循通用的接口，使同一个GUI能够在Windows和Linux下工作，不同的实现将是可互换的。 更重要的是，你可以在不触碰操作系统代码的情况下开始在GUI类中工作，反之亦然。比如，添加一个对新操作系统的支持，将仅需要在实现层中创建一个子类。 结构 抽象（Abstraction）主要包含一个像用户接口一样的控制逻辑。抽象代码依赖具体实现对象来完成任务。 实现（Implementation）为所有具体的实现声明了通用的接口。抽象层可以和任何一个符合这个接口的具体实现工作。 抽象和实现接口在一些程序中是相等的。但是大多情况下，实现包含基本的原语操作，抽象层用它们来处理一些复杂的行为。 具体实现包含具体平台的代码。 精制抽象（Refined Abstractions）可以用来创建一些控制逻辑的变种。这些类和它们的父类一样，应该用实现接口（Implementation inteface）来和不同的实现协作。 客户端（Client）只和抽象类有一个地方不同。在构建抽象对象时，客户端会传递一个具体实现对象。然而，如果需要，具体实现可以动态替换。 伪代码在这个例子中，Bridge将设备（Devices）和遥控器（Remotes）的代码分成几部分： 设备（看作实现） 遥控器（看作抽象） 遥控器的基类有一个域来持有一个要控制设备的对象引用。遥控器通过设备提供的通用接口工作。它允许一个遥控器可以和几个不同的设备协作（译者注：控制几个不同类型的设备）。 你可以独立的改变控制类。例如，你可以创建一个仅有两个按钮的遥控器或者带有触摸屏的复杂遥控器。 因此，Bridge模式允许你将一个实体分成几个不同的实体，它们可以独立发展。客户端代码总是保持简单。它只需要选择一个抽象并且配置给它一个具体实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// All remote classes contain reference to the device they controls. Remote's// methods delegate most of the work to the device methods.class Remote is protected field device: Device constructor BasicRemote(device: Device) is this.device = device method togglePower() is if device.isEnabled() then device.disable() else device.enable() method volumeDown() is device.setVolume(device.getVolume() - 10) method volumeUp() is device.setVolume(device.getVolume() + 10) method channelDown() is device.setChannel(device.getChannel() - 1) method channelUp() is device.setChannel(device.getChannel() + 1)// You can extend remote hierarchy independently from device classes.class AdvancedRemote extends BasicRemote is method mute() is device.setVolume(0)// All devices have the common interface. This makes them compatible with// all remotes.interface Device is method isEnabled() method enable() method disable() method getVolume() method setVolume(percent) method getChannel() method setChannel(channel)// But each concrete device may have its own implementation.class Tv implements Device is // ...class Radio implements Device is // ...// Somewhere in client code.tv = new Tv();remote = new Remote(tv)remote.pover()radio = new Radio();remote = new AdvancedRemote(radio) 适用性 当你有一个包含一些功能变种的大类（比如，工作在几个不同的数据库服务上） 这个类会变的很难维护，因为任何一个人触碰她的人都需要花费大量的时间去完全理解它。更改功能的某个变种会导致编辑整个类，这可能会引起讨厌的被忽视的错误。 Bridge模式将单体类分成几个层次，一个包含另外一个的引用。这些层次中的类可以独立的编辑。它简化了支持，并最大限度地减少了修改现有代码的风险。 当你需要在正交（独立）的维度扩展一个类 取代单层次的增长，Bridge模式建议为每个维度创建一个分离的类层次，并且通过引用域来关联这些层次。 当你需要在运行时改变实现 尽管它是可选的，Bridge模式允许改变抽象中的实现对象。这就像为一个字段分配一个新值一样简单。 顺便说下，这也是为什么许多人对Bridge模式和Strategy模式分不清楚。记住，模式不仅仅是类结构，而是意图（译者注：或者目的）。Bridge模式的目的就是结构化代码。 如何实现 确定你的类是正交维度。这些独立的概念可以是：abstraction/platform, or domain/infrastructure, or front-end/back-end, or interface/implementation. 考虑客户端想要干什么，然后把他们描述在基本抽象类中。 确定所有平台的能力和抽象需要什么。然后把它们描述在实现接口中。 在你的领域中为所有平台创建具体实现类，确定它们都遵循了实现接口。 在抽象类中增加一个实现类型的域。然后实现所有抽象方法，同时将大部分工作委托给该域中引用的实现对象。 客户端代码应将实现对象传递给抽象的构造函数。它可以根据需要使用抽象对象。 优点 允许建立平台独立代码。 符合开闭原则。 对客户端隐藏实现细节。 缺点 创建多个附加类导致总体代码复杂性增加。 和其他模式的关系 Bridge是前置设计，让抽象和实现相互独立。Adapter是通过改装使得没有关系的类协作。Adapter通常是在设计完成后使用；Bridge通常是设计时采用。 State, Strategy, Bridge (和某种程度上的Adapter) 具有相似的解决结构。它们都是采用分享“句柄/身体”的方式。它们的意图不同，因此它们解决不同的问题。 Abstract Factory可与Bridge模式一起使用。当Bridge“接口”的一部分只能与特定的“实现”工作时，这很有用。在这种情况下，工厂可以封装这些关系，对客户端隐藏复杂性。 Builder可以构造为Bridge模式：Director将作为接口，Builders将扮演实现角色。 Java中模式的使用用例：Bridge模式对这些情况特别适用：跨平台应用，支持多类型的数据库服务，和一些特定类型的API提供者（例如，云平台，社交网络等）合作。 坚定：可以通过区分控制实体和它所依赖的几个不同的平台来识别Bridge模式。 参考翻译整理自：https://refactoring.guru/design-patterns/bridge]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-结构模式之Decorator]]></title>
      <url>%2F2017%2F09%2F20%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E6%A8%A1%E5%BC%8F%E4%B9%8BDecorator%2F</url>
      <content type="text"><![CDATA[目的Decorator（装饰器）是一个结构设计模式，可以让你在封装包涵对象原有行为的基础上增加新的行为。 问题你需要动态的添加或者移除一个对象的责任，但是你要做到和应用中其他代码的兼容。 当你需要扩展一个类的行为时继承时第一个想到的处理方式。然而，继承是静态的。你不能够增加一个新的类到程序中当它已经编译或者执行完成。 解决办法装饰器模式依赖一个叫做装饰者（或者包装者）的特别类。他们和被封装的类拥有一样的接口，所以客户端代码不会注意到你用封装者替换了源对象。 所有的封装者这都持有一个源对象实例的强引用。大多数包装器使用传入其构造函数的对象初始化该字段。 所以，该如何动态改变他的行为呢？正如我提到的，封装者何和目标对象拥有一样的接口。当你调用装饰者的方法时，他执行被封装对象中同样方法并且在返回的结果中添加一些东西。它也可以在原始方法之前调用，但这取决于业务逻辑。 这里是有趣的一部分：你可以使用装饰者封装一个对象，然后再使用另外一个装饰器封装这个包装结果，等等。最终的行为结果是所有装饰器和源对象组合得到的。 现实世界的类比穿衣服就是使用装饰者的例子。当你冷的时候，你用毛衣包裹自己。如果你还是冷，你可以在外边套一个夹克。如果下雨了，你还可以再传一件雨衣。 所有的服装“扩展”自你基本的行为，但不是你的一部分。因此，在你不需要他们的时候，可以轻松的移除它们。 结构 Component为被封装者声明了一个通用的接口。 Concrete Component是一个包涵基本行为并可以被装饰器修改的类。 Base Decorator包涵一个被封装对象的强引用域。这个域应该被声明为Component类型，以便支持Concrete Components 和 Decorators.Base Decorator将所有操作委托给被封装对象。 Concrete Decorators包涵可以被动态添加的额外行为。装饰器可以在调用被封装对象方法前后执行自己的行为。 伪代码在这个例子中，装饰器通过加密保护金融数据，对已经存在的代码来讲是透明的。应用对金融数据做了加密和压缩装饰，当我们从硬盘读取数据时返回的是普通的数据，但是当我们写会到磁盘时数据被加密和压缩。 装饰者和金融类都有一个相同的接口，使得它们对客户端来讲是通用的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596// Common interface for all components.interface DataSource is method writeData(data) method readData():data// One of the concrete components can act as a base layer.class FileDataSource implements DataSource is constructor FileDataSource(filename) &#123; ... &#125; method writeData(data) is Write data to file. method readData():data is Read data from file.// All other concrete components may act as wrappers.class DataSourceDecorator implements DataSource is protected field wrappee: DataSource constructor DataEncyptionDecorator(source: DataSource) is wrappee = source method writeData(data) is wrappee.writeData(data) method readData():data is return wrappee.readData()// Concrete Decorators extend the functionality of a component they wrap.class EncyptionDecorator extends DataSourceDecorator is method writeData(data) is Encrypt passed data. Pass the compressed data to wrappee's writeData() method. method readData():data is Get the data from wrappee's readData() method. Decrypt and return that data.// You can wrap objects in several layers of decorators.class CompressionDecorator extends DataSourceDecorator is method writeData(data) is Compress passed data Pass the compressed data to wrappee's writeData() method. method readData():data is Get the data from wrappee's readData() method. Uncompress and return that data.// Option 1. A simple example of decorator assembly.class Application is method dumbUsageExample() is source = new FileDataSource('somefile.dat') source.writeData(salaryRecords) // a file with plain data source = new CompressionDecorator(source) source.writeData(salaryRecords) // compressed file source = new EncyptionDecorator(source) source.writeData(salaryRecords) // compressed and encrypted file// Option 2. Client code, which uses an external data source. SalaryManager// neither knows not cares about data storage specifics. It receives already// configured data source.class SalaryManager is field source: DataSource constructor SalaryManager(source: DataSource) &#123; ... &#125; method load() is return source.readData() method save() is source.writeData(salaryRecords) // ...Other useful methods...// Application can assemble objects with a different set of functionality using// the same decorators at run time, depending on the configuration// or environment.class ApplicationConfigurator is method configurationExample() is source = new FileDataSource("salary.dat"); if (enabledEncryption) source = new EncyptionDecorator(source) if (enabledCompression) source = new CompressionDecorator(source) logger = new SalaryLogger(source) salary = logger.load(); // ...Rest of an application code. 适用性 当你需要动态赋予某个对象行为并且不需要破坏这个对象的代码。 装饰器模式允许给某个对象动态的赋予新的行为，而且对客户端代码是隐式的。对象可以同时封装多个wrapper（译者注：就像同时穿了背心、衬衣和西装），结果是所有封装的堆叠结果。 当不可能活着不合适通过继承来扩展对象的行为。 许多编程语言都有final关键字来阻止未来对一个类的扩展。当处理这些代码，进行扩展的唯一选项就是适用装饰器模式。 如何实现 确保您的任务可以表示为一个主要组件和几个可选扩展。 创建Component（组件）接口，它需要描述该组件所有可被扩展的方法。 创建Concrete Component（具体组件）类并且实现业务逻辑。 创建Base Decorator（基础装饰）类。创建一个域来保存被封装对象的强引用。该域应该是Component类型，这样强引用就可以持有组件类和装饰器的强引用（译者注：即变量声明为接口类型，这样可以持有所有Component的所有子类）。 确保所有子类实现了Component接口。 确保Base Decorator类的所有方法都将方法执行委托给了被包装对象。它将允许Concrete Decorators（具体装饰器）仅扩展一部分组件行为，并且不需要修改其他行为。 创建Concrete Decorators类，该类从Base Decorator扩展。 一个Concrete Decorator可以在调用被封装对象相同方法前后执行它自己的的行为（你可以仅仅只调用弗雷德方法，因为它将最终调用封装方法）。 Client代码必须负责配置包装层。Client应该通过Component的接口和其他类一起工作，使装饰器可以互换。 不必完全拘泥于以上步骤，一些情况下译者认为完全可以省略掉Base Decorator。 优缺点 优点 比继承灵活 允许在运行时添加和删除行为 通过使用多层封住，组合几个额外的行为。 可以组合多个单行为实现使其实现更加复杂的行为。 缺点 配置一个多封装对象是困难的。 导致很多小类。 和其他模式的关系 Adapter提供不同的接口来达到目的。Proxy提供相同的接口。Decorator提供增强的接口。 Adapter意味着改变一个存在对象的接口。Decorator在不改变原有接口的情况下增强另外一个对象。Decorator对应用来讲比Adapter更加透明。因此，Decorator支持递归组合，这对于纯Adapter是不可能的。 Chain of Responsibility（责任链）和Decorator具有非常普通的类机构。它们都依赖于一系列对象的递归组合来执行。但是它们也有几个关键的不同点。 Chain of Responsibility的处理者可以执行随意的行为操作，处理者之间相互独立。它们可以随意的终端下一步的调用。另一方面，各种Decorator扩展一个特别的行为并且假设保持接口一致。并且，Decorator不允许随意中断执行链。 Composite和Decorator拥有类似的结构图，因为它们都依赖递归组合来组织一个对象开闭的数量。 装饰器可以看作只有一个组件的退化组合。然而，Decorator向对象增加了额外的责任，而Composite只是对其子类执行相同的行为的“summs up”。 但是它们也可以协作：Composite可以使用Decorator来改变树组件的行为。 大量使用Composite和Decorator模式的设计通常可以从Prototype中受益。它允许克隆复杂的结构，而不是从头重新构建它们。 装饰器可以让您更改对象的皮肤。策略让你改变勇气。 Decorator和Proxy有相似的结构，但是目的不同。两种模式都建立在将工作委托给其他对象的组合原则上。然而，Proxy自己管理他持有服务对象的生命周期，而Decorator结构由客户端控制。 Java中模式的使用用例：Decorator在Java中是十分标准的，尤其是和流相关的代码。 这有几个Java核心库中使用Decorator的例子： java.io.InputStream，OutputStream，Reader和Writer的所有子类都有接受它们自己类型的构造方法。 java.util.Collections，方法checkedXXX()，synchronizedXXX()和unmodifiableXXX()。 javax.servlet.http.HttpServletRequestWrapper和HttpServletResponseWrapper。 鉴定：可以通过创建方法或构造函数来识别Decorator，它接受与当前类相同的类或接口的对象。 参考翻译整理自：https://refactoring.guru/design-patterns/decorator]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-设计模式-结构模式之Adapter]]></title>
      <url>%2F2017%2F09%2F15%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E6%A8%A1%E5%BC%8F%E4%B9%8BAdapter%2F</url>
      <content type="text"><![CDATA[目的适配器是一种结构设计模式，使得不兼容接口间的可正常进行协作。 问题想象你有一个使用XML作为数据处理格式的APP，但你用到了一个仅支持JSON数据格式的类库。 举个例子，你有一个做股票数据的APP。他从多个数据源获取XML来展示成图标。在一个新版本中，你决定使用一些三方的分析包。但是有一个问题：分析包仅支持JSON数据。 在这种情况下，可以重写你自己的代码以便支持JSON或者改变依赖的库使其支持XML。第一种选择要破坏已有的代码，第二种选择看上去是不可能的，因为我们常常无法修改三方库。 解决方法你可以创建一个适配器。它可以将调用方发送的数据按照格式转换成三方库可以解析的类型。适配器封装了对一个对象复杂的转换过程。 适配器可以不仅可以格式化数据，也可以适配接口。比如，适配器接收到一个对方法A的调用，他可以转交给被包装的方法B、C、D。 有时甚至可以创建一个双向适配，这样就可以双向转换。 综上讨论，股票超市APP需要一个特别的XML_To_JSON_Adapter类。在调用分析类库之前，将xml转换为json。采用这种方式你将不需要改变任何已有的APP代码，也不需要改变分析库的代码。 真实世界的类比不同国家的插头和插板当你第一次从美国到偶主，你会发现没办法给你的笔记本充电。两个国家插座和插头的标准根本不一样。这就是为什么美国的插头没办法适配德国的插座。 这个问题可以通过使用具有美式插座和欧式插头的电源插头适配器来解决。 结构对象适配实现采用组合原则：适配器实现其中一对象的接口，并且封装另一个对象。他可以在所有新生代语言中实现。 类适配实现采用集成。适配器同是继承两个接口。该方式只有像C++这种支持多继承的语言可以实现。 Existing interface （存在的接口或者类）已经被你的其余代码支持 Service （服务）是一些不能在应用类直接工作的有用类（通常是三方库或者遗留代码） Adapter 实现了 Existing interface 并且持有 Service 类引用。 adapter会接收到client通过 Existing interface 定义的方法调用。他在调用 Service 前可能会修正调用参数的类型或者格式化数据。 Client 使用 Adapter 调用 Existing interface 中定义的接口。 这里允许添加新的 Adapter 来编程而不需要改动已经存在的代码（Service 改变的的情况可能也会出现，比如，当你更新依赖的三方库）。 这个adapter类不需要封装任何对象。他同时实现了两个接口。因此，对所有的对象都是兼容的。 伪代码让我们看看Adapter如何从一个接口到另一个接口进行基本数据转换。这个例子给予圆孔和方形钉的冲突。圆孔可以和圆钉很好的工作；可以通过两者的半径来决定是否合适。但是方形钉不能测量半径。 这就是我们为什么需要创建一个Adapter类来封装方形钉对象并且伪装他有一个等于方形直径一半的半径。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// Classes with compatible interfaces: RoundHole and RoundPeg.class RoundHole is constructor RoundHole(radius) &#123; ... &#125; method getRadius method fits(peg: RoundPeg) is return this.getRadius() &gt;= peg.radius()class RoundPeg is constructor RoundPeg(radius) &#123; ... &#125; method getRadius() is Return the peg radius.// Obsolete incompatible class: SquarePeg.class SquarePeg is constructor SquarePeg(width) &#123; ... &#125; method getWidth() is Return the square peg width.// Adapter allows fitting square pegs into round holes.class SquarePegAdapter extends RoundPeg is private field peg: SquarePeg constructor SquarePegAdapter(peg: SquarePeg) is this.peg = peg method getRadius() is return Math.sqrt(Math.pow((peg.getWidth()/2), 2) * 2);// Somewhere in client code.hole = new RoundHole(5)rpeg = new RoundPeg(5)hole.fits(rpeg) // truesmall_sqpeg = new SquarePeg(2)large_sqpeg = new SquarePeg(5)hole.fits(small_sqpeg) // won't compile (incompatible types)small_sqpeg_adapter = new SquarePegAdapter(small_sqpeg)large_sqpeg_adapter = new SquarePegAdapter(large_sqpeg)hole.fits(small_sqpeg_adapter) // truehole.fits(large_sqpeg_adapter) // false 适用性当你想服用已经存在的类，但是接口和应用其他代码不兼容 采用适配器模式创建一个中间层来将调用转换成应用中已存在对象可以处理的数据。 你需要复用几个已经存在的类，但是她们缺少一些常用的功能。并且你无法在父类中添加这些功能，因为他是闭源或者被其他代码使用的。 你可以把这些缺少的功能放到新建的adapter中。他将连接你应用的代码和你感兴趣的类。这种解决方式看起来很像Visitor模式。 如何实现 确保你有两种元素： 有用的service对象 应用代码必须使用service对象。应用不能够直接调用service，因为接口或者数据格式不兼容。 声明后面需要adpater跟随的client接口。应用将使用这个接口和adapter交互。 创建一个adpater，实现client接口（空实现）。 adapter增加一个service变量。通常情况下，这个变量在构造方法中设置。简单的场景下，适配器可直接转发调用（直接调用service中对应的方法）。 实现client定义的接口。adapter方法直接调用service中适当的方法并传递格式化后的数据。 adapter类编写完成后，在应用中通过client接口来使用它。 优缺点 优点：隐藏了客户端代码不需要知道的接口实现细节和数据转换 缺点：引入新的类，使得整体复杂度增加 和其他模式的联系 Bridge（桥接）是先期设计把抽象和实现独立。Adapter是进行改装，使没有关系的类在一起工作。Adapter是在设计后期使一些功能工作；Bridge在前期做这些事情。 Adapter为了实现目标，提供不同的接口。Proxy（代理）提供相同的接口。Decorator（装饰）提供增强的接口。 Adapter意味着改变现有代码的接口。Decorator另一个对象的接口但是没有改变接口。因而Decorator比Adapter更透明。结果就是，Decorator支持递归组合，纯粹的适配器做不到这点。 Facade（门面）定义了一个新接口，而Adapter复用已有接口。记住，Adapter使两个存在的接口协作而不是完全定义一个新接口。 Sate（状态），Strategy（策略），Bridge（某种程度上的Adapter）有类似的解决结构。他们都是共享”handle/body”元素。他们的意图不同，所以，他们解决不同的问题。 Java中模式的使用用例：Adapter模式在Java代码中很常见。它经常用于基于一些遗留代码的系统中。在这种情况下，Adapter使得老代码变得符合现在的需要。 在Java核心库中有一些标准的Adapter： java.util.Arrays#asList() java.util.Collections#list() java.util.Collections#enumeration() java.io.InputStreamReader(InputStream) (returns a Reader object) java.io.OutputStreamWriter(OutputStream) (returns a Writer object) javax.xml.bind.annotation.adapters.XmlAdapter#marshal() and #unmarshal() 参考翻译整理自：https://refactoring.guru/design-patterns/adapter]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[译-Spring-理解AOP代理]]></title>
      <url>%2F2017%2F06%2F29%2F%E8%AF%91-spring-%E7%90%86%E8%A7%A3AOP%E4%BB%A3%E7%90%86%2F</url>
      <content type="text"><![CDATA[引入之前写过一篇关于Spring代理流程的博客，当时没有深入思考，最近碰到一个有趣的事情，类内部调用带有spring注解，但注解不生效的问题，举例说明： 123456789101112public class SimplePojo implements Pojo &#123; public void foo() &#123; // this next method invocation is a direct call on the 'this' reference this.bar(); &#125; @Transaction public void bar() &#123; // some logic... &#125;&#125; 外部一个类直接调用SimplePojo.bar()事务是有效的，但如果调用SimplePojo.foo()，那么bar()方法上的事务不会生效。查了一下spring文档，其中特别对AOP代理做了讲解，现翻译记录。 对照译文原文链接:https://docs.spring.io/spring/docs/current/spring-framework-reference/html/aop.html#aop-understanding-aop-proxies Spring AOP is proxy-based. It is vitally important that you grasp the semantics of what that last statement actually means before you write your own aspects or use any of the Spring AOP-based aspects supplied with the Spring Framework. Srping AOP基于proxy-based。在我们基于Spring框架自定义切面或者使用Spring基于AOP-based提供的切面之前，理解proxy-based的含义很重要。 Consider first the scenario where you have a plain-vanilla, un-proxied, nothing-special-about-it, straight object reference, as illustrated by the following code snippet. 看下面一个最简单的调用片段。 1234567891011public class SimplePojo implements Pojo &#123; public void foo() &#123; // this next method invocation is a direct call on the 'this' reference this.bar(); &#125; public void bar() &#123; // some logic... &#125;&#125; If you invoke a method on an object reference, the method is invoked directly on that object reference, as can be seen below. 如果你使用对象的引用调用其一个方法，这个方法是被直接调用的，看下图。 12345678910public class Main &#123; public static void main(String[] args) &#123; Pojo pojo = new SimplePojo(); // this is a direct method call on the 'pojo' reference pojo.foo(); &#125;&#125; Things change slightly when the reference that client code has is a proxy. Consider the following diagram and code snippet. 当客户端代码的引用是代理时，会略有改变。请看下图和代码片段。 1234567891011121314public class Main &#123; public static void main(String[] args) &#123; ProxyFactory factory = new ProxyFactory(new SimplePojo()); factory.addInterface(Pojo.class); factory.addAdvice(new RetryAdvice()); Pojo pojo = (Pojo) factory.getProxy(); // this is a method call on the proxy! pojo.foo(); &#125;&#125; The key thing to understand here is that the client code inside the main(..) of the Main class has a reference to the proxy. This means that method calls on that object reference will be calls on the proxy, and as such the proxy will be able to delegate to all of the interceptors (advice) that are relevant to that particular method call. However, once the call has finally reached the target object, the SimplePojo reference in this case, any method calls that it may make on itself, such as this.bar() or this.foo(), are going to be invoked against the this reference, and not the proxy. This has important implications. It means that self-invocation is not going to result in the advice associated with a method invocation getting a chance to execute. 着重看下Main类中main方法中对代理的引用。这意味着对该对象引用的方法调用实际调用的是代理，因此代理能够将调用委托给与该方法调用相关的所有拦截器（advice）。然而，一旦调用最终到达目标对象，例子中的SimplePojo引用，那么其任何自我方法的调用，例如this.bar()或者this.foo(),都将是直接调用，而不是调用的代理。这点特别重要。这意味着自我调用不会被其相关联advice不会被执行。 Okay, so what is to be done about this? The best approach (the term best is used loosely here) is to refactor your code such that the self-invocation does not happen. For sure, this does entail some work on your part, but it is the best, least-invasive approach. The next approach is absolutely horrendous, and I am almost reticent to point it out precisely because it is so horrendous. You can (choke!) totally tie the logic within your class to Spring AOP by doing this: 那么我们要做些什么呢？最好的方式是重构你自己的代码使得不会发生自我调用。当然，这需要一些工作量，但这是最好并且低侵入的方式。另外一种方式绝对是可怕的。你可以将你的逻辑与Spring AOP完全耦合，比如： 1234567891011public class SimplePojo implements Pojo &#123; public void foo() &#123; // this works, but... gah! ((Pojo) AopContext.currentProxy()).bar(); &#125; public void bar() &#123; // some logic... &#125;&#125; This totally couples your code to Spring AOP, and it makes the class itself aware of the fact that it is being used in an AOP context, which flies in the face of AOP. It also requires some additional configuration when the proxy is being created: 这完全将你的代码与Spring AOP结合在一起，它使得这个类本身就意识到它被用在一个面向AOP的AOP上下文中。它也使用时也需要加入一些配置： 123456789101112131415public class Main &#123; public static void main(String[] args) &#123; ProxyFactory factory = new ProxyFactory(new SimplePojo()); factory.adddInterface(Pojo.class); factory.addAdvice(new RetryAdvice()); factory.setExposeProxy(true); Pojo pojo = (Pojo) factory.getProxy(); // this is a method call on the proxy! pojo.foo(); &#125;&#125; Finally, it must be noted that AspectJ does not have this self-invocation issue because it is not a proxy-based AOP framework. 最后，必须注意的是，AspectJ没有这种自我调用问题，因为它不是基于proxy-based的AOP框架。 总结回顾了下上一篇关于AOP源码阅读的博客，其实代码中已经给出答案。只是当时并没想这么多。代理类实际上是对目标类做了聚合封装。这也就解释了为什么自我调用时advisor不会被执行。 123456789101112131415161718192021222324//AbstractAutoProxyCreatorprotected Object createProxy( Class&lt;?&gt; beanClass, String beanName, Object[] specificInterceptors, TargetSource targetSource) &#123; ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.copyFrom(this); ... Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); for (Advisor advisor : advisors) &#123; proxyFactory.addAdvisor(advisor); &#125; proxyFactory.setTargetSource(targetSource); customizeProxyFactory(proxyFactory); proxyFactory.setFrozen(this.freezeProxy); if (advisorsPreFiltered()) &#123; proxyFactory.setPreFiltered(true); &#125; return proxyFactory.getProxy(getProxyClassLoader());&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[了解ClassLoader]]></title>
      <url>%2F2017%2F06%2F28%2F%E4%BA%86%E8%A7%A3ClassLoader%2F</url>
      <content type="text"><![CDATA[初识ClassLoader 在开发中有时会碰到ClassNotFoundException。这个异常和ClassLoader有着密切的关系。 我们常使用instanceof关键字判断某个对象是否属于指定Class创建的对象实例。如果对象和Class不属同一个加载器加载，那么instanceof返回的结果一定是false。 GC Root有一种叫做System Class，官方解释“Class loaded by bootstrap/system class loader. For example, everything from the rt.jar like java.util. .”，大意是：被bootstrap/system加载器加载的类，比如，像java.util.这些来自rt.jar的类。 GC时对Class的卸载，需要满足的条件如下： 类需要满足以下3个条件才能算是“无用的类” 该类所有的实例已经被回收 加载该类的ClassLoder已经被回收 该类对应的java.lang.Class对象没有任何对方被引用 ClassLoader简介 我们的Java应用程序都是由一系列编译为class文件组成，JVM在运行的时候会根据需要（比如：我们需要创建一个新对象，但是该对象的Class定义并未在Perm区找到）将应用需要的class文件找到并加载到内存的指定区域供应用使用，完成class文件加载的任务就是由ClassLoader完成。 ClassLoader类的基本职责就是根据一个指定的类的名称，找到（class可能来源自本地或者网络）或者生成其对应的字节代码，然后从这些字节代码中定义出一个java.lang.Class类的一个实例。除此之外，ClassLoader还负责加载 Java 应用所需的资源，如图像文件和配置文件等。 在JVM中每个ClassLoader有各自的命名空间，不同的ClassLoader加载的相同class文件创建的Class实例被认为是不相等的，由不相等的Class创建的对象实例无法相互强制转型，如开头所提，当我们使用instanceof关键字判断时需要注意。 双亲委派模型双亲委派模型很好理解，直接上代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243/*** 使用指定的二进制名称来加载类。默认的查找类的顺序如下： * 调用findLoadedClass(String) 检查这个类是否被加载过；* 调用父加载器的loadClass(String)，如果父加载器为null，使用虚拟机内置的加载器代替； * 如果父类未找到，调用findClass(String)方法查找类。*/protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; 从源码中我们看到有三种类加载器： 引导类加载器（bootstrap class loader）：它用来加载 Java 的核心库，是用原生代码（C++）来实现的，并不继承自java.lang.ClassLoader。负责将${JAVA_HOME}/lib目录下和-Xbootclasspath参数所指定的路径中的，并且是Java虚拟机识别的（仅按照文件名识别，如rt.jar，不符合的类库即使放在lib下也不会被加载）类库加载到JVM内存中，引导类加载器无法被Java程序直接引用； 扩展类加载器（extensions class loader）：它用来加载 Java 的扩展库（${JAVA_HOME}/ext），或者被java.ext.dirs系统变量所指定的路径中的所有类库； 系统类加载器（system class loader）：它根据 Java 应用的类路径（CLASSPATH）来加载Java类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。 1234567891011121314151617public class ClassLoaderTree &#123; /** * 输出： * sun.misc.Launcher$AppClassLoader@18b4aac2 * sun.misc.Launcher$ExtClassLoader@5305068a * null * @param args */ public static void main(String[] args) &#123; ClassLoader loader = ClassLoaderTree.class.getClassLoader(); while (loader!=null)&#123; System.out.println(loader.toString()); loader = loader.getParent(); &#125; System.out.println(loader); &#125;&#125; 每个Java类都维护着一个指向定义它的类加载器的引用，通过getClassLoader()方法就可以获取到此引用。通过调用getParent()方法可以得到加载器的父类，上述代码输出中，AppClassLoader对应系统类加载器（system class loader）；ExtClassLoader对应扩展类加载器（extensions class loader）；需要注意的是这里并没有输出引导类加载器，这是因为有些JDK的实现对于父类加载器是引导类加载器。这些加载器的父子关系通过组合实现。 为什么要双亲委派 避免重复加载。当父亲已经加载了该类，子类就没有必要再加载一次； 安全。如果不使用这种委托模式，那我们就可以使用自定义的String或者其他JDK中的类，存在非常大的安全隐患，而双亲委派使得自定义的ClassLoader永远也无法加载一个自己写的String。 创建自定义ClassLoader自定义的类加载器只需要重写findClass(String name)方法即可。java.lang.ClassLoader封装了委派的逻辑，为了保证类加载器正常的委派逻辑，尽量不要重写findClass()方法。 123456789101112131415161718192021222324252627282930313233343536373839404142public class FileSystemClassLoader extends ClassLoader &#123; private String rootDir; public FileSystemClassLoader(String rootDir)&#123; this.rootDir = rootDir; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = getClassData(name); if (classData == null)&#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] getClassData(String className) &#123; String path = classNameToPath(className); try &#123; InputStream ins = new FileInputStream(path); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 1024; byte[] buffer = new byte[bufferSize]; int bytesNumRead = 0; while ((bytesNumRead = ins.read(buffer)) != -1)&#123; baos.write(buffer, 0, bytesNumRead); &#125; return baos.toByteArray(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; private String classNameToPath(String className) &#123; return rootDir + File.separatorChar + className.replace('.', File.separatorChar) + ".class"; &#125;&#125; 实验更多实验代码放在github上：https://github.com/Childe-Chen/goodGoodStudy/tree/master/src/main/java/com/cxd/classLoader 1234567891011121314151617181920212223242526public class TestClassIdentity &#123; public static void main(String[] args) &#123; FileSystemClassLoader fileSystemClassLoader = new FileSystemClassLoader("/Users/childe/Documents/workspace/goodGoodStudy/target/classes"); try &#123; Class&lt;?&gt; c = fileSystemClassLoader.findClass("com.cxd.classLoader.Sample"); //forName会执行类中的static块(初始化) Class&lt;?&gt; c1 = Class.forName("com.cxd.classLoader.Sample"); System.out.println(c1.isAssignableFrom(c)); //运行时抛出了 java.lang.ClassCastException异常。虽然两个对象 o1 o2的类的名字相同，但是这两个类是由不同的类加载器实例来加载的，因此不被 Java 虚拟机认为是相同的。 //不同的类加载器为相同名称的类创建了额外的名称空间。相同名称的类可以并存在 Java 虚拟机中，只需要用不同的类加载器来加载它们即可。 // 不同类加载器加载的类之间是不兼容的，这就相当于在 Java 虚拟机内部创建了一个个相互隔离的 Java 类空间。这种技术在许多框架中都被用到 Object o = c.newInstance(); Method method = c.getMethod("setSample", java.lang.Object.class); Object o1 = c1.newInstance(); method.invoke(o,o1); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 1234567891011public class Sample &#123; private Sample instance; static &#123; System.out.println("static"); &#125; public void setSample(Object instance) &#123; this.instance = (Sample) instance; &#125;&#125; 打破双亲委派模型没有完美的模型，双亲委派在面对SPI时，不得不做出了特例或者说改进。我们知道Java提供了很多服务提供者接口（Service Provider Interface，SPI），允许第三方为这些接口提供实现。常见的有JDBC、JCE、JNDI、JAXP 和 JBI 等。SPI的接口由Java核心库定义，而其实现往往是作为Java应用所依赖的 jar包被包含到CLASSPATH里。而SPI接口中的代码经常需要加载具体的实现类。那么问题来了，SPI的接口是Java核心库的一部分，由引导类加载器加载；SPI的实现类是由系统类加载器加载，引导类加载器无法找到SPI的实现类，因为依照双亲委派模型，BootstrapClassloader无法委派AppClassLoader来加载类。 为了解决这个问题，Java引入了线程上下文类加载器，在Thread中聚合了contextClassLoader，通过Thread.currentThread().getContextClassLoader()获得。原始线程的上下文ClassLoader通常设定为用于加载应用程序的类加载器。也就是说父加载器可以通过县城上下文类加载器可以获得第三方对SPI的实现类。 以Java链接Mysql为例，看下Java如何来加载SPI实现。12345// 注册驱动，forName方法会初始化Driver，初始化块中向DriverManager注册驱动Class.forName("com.mysql.jdbc.Driver").getInstance(); String url = "jdbc:mysql://host:port/db"; // 通过java库获取数据库连接Connection conn = java.sql.DriverManager.getConnection(url, "name", "password"); com.mysql.jdbc.Driver是java.sql.Driver的一种实现。 1234567891011121314package com.mysql.jdbc;public class Driver extends NonRegisteringDriver implements java.sql.Driver &#123;// // Register ourselves with the DriverManager // 向DriverManager注册驱动 static &#123; try &#123; java.sql.DriverManager.registerDriver(new Driver()); &#125; catch (SQLException E) &#123; throw new RuntimeException("Can't register driver!"); &#125; &#125; ...&#125; 接下来我们调用getConnection就进入了本小结的关键点。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// Worker method called by the public getConnection() methods. private static Connection getConnection( String url, java.util.Properties info, Class&lt;?&gt; caller) throws SQLException &#123; /* * 再次强调下：原始线程的上下文ClassLoader通常设定为用于加载应用程序的类加载器 * When callerCl is null, we should check the application's * (which is invoking this class indirectly) * classloader, so that the JDBC driver class outside rt.jar * can be loaded from here. */ //caller由Reflection.getCallerClass()得到，而调用方是java.sql.DriverManager，所以getClassLoader()是引导类加载器，也就是null //所以此处使用线程上下文加载器来加载实现类 ClassLoader callerCL = caller != null ? caller.getClassLoader() : null; synchronized(DriverManager.class) &#123; // synchronize loading of the correct classloader. if (callerCL == null) &#123; callerCL = Thread.currentThread().getContextClassLoader(); &#125; &#125; if(url == null) &#123; throw new SQLException("The url cannot be null", "08001"); &#125; println("DriverManager.getConnection(\"" + url + "\")"); // Walk through the loaded registeredDrivers attempting to make a connection. // Remember the first exception that gets raised so we can reraise it. SQLException reason = null; for(DriverInfo aDriver : registeredDrivers) &#123; // If the caller does not have permission to load the driver then // skip it. // isDriverAllowed中使用给定的加载器加载指定的驱动 if(isDriverAllowed(aDriver.driver, callerCL)) &#123; try &#123; println(" trying " + aDriver.driver.getClass().getName()); Connection con = aDriver.driver.connect(url, info); if (con != null) &#123; // Success! println("getConnection returning " + aDriver.driver.getClass().getName()); return (con); &#125; &#125; catch (SQLException ex) &#123; if (reason == null) &#123; reason = ex; &#125; &#125; &#125; else &#123; println(" skipping: " + aDriver.getClass().getName()); &#125; &#125; // if we got here nobody could connect. if (reason != null) &#123; println("getConnection failed: " + reason); throw reason; &#125; println("getConnection: no suitable driver found for "+ url); throw new SQLException("No suitable driver found for "+ url, "08001");&#125; 总结&amp;扩展 双亲委派作为基本模型，隔离了不同的调用者，保证了程序的安全。 线程上线文加载器与其说破坏了双亲委派倒不如说是扩展了双亲委派的能力，使其有更好的通用性。 Tomcat、Jetty等Web容器都是基于双亲委派模型来做资源的隔离。 Spring在设计中也考虑到了类加载的问题，详细可见：org.springframework.web.context.ContextLoader.initWebApplicationContext(…)。 参考http://www.infocool.net/kb/Tomcat/201609/193323.htmlhttps://www.ibm.com/developerworks/cn/java/j-lo-classloader/http://github.thinkingbar.com/classloader/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[转-Servlet3-异步请求]]></title>
      <url>%2F2017%2F06%2F13%2F%E8%BD%AC-Servlet3-%E5%BC%82%E6%AD%A5%E8%AF%B7%E6%B1%82%2F</url>
      <content type="text"><![CDATA[第22章 异步请求Servlet3.0规范新增了对异步请求的支持，Spring MVC也在此基础上对异步请求提供了方便。异步请求是在处理比较耗时的业务时先将request返回，然后另起线程处理耗时的业务，处理完后再返回给用户。 异步请求可以给我们带来很多方便，最直接的用法就是处理耗时的业务，比如，需要查询数据库、需要调用别的服务器来处理等情况下可以先将请求返回给客户端，然后启用新线程处理耗时业务，等处理完成后再将结果返回给用户。稍微扩展一下还可以实现订阅者模式的消息订阅功能，比如，当有异常情况发生时可以主动将相关信息发给运维人员，还有现在很多邮箱系统中收到新邮件的自动提示功能也是这种技术。甚至更进一步的使用方式是在浏览器上做即时通信的程序！HTTP协议是单向的，只能客户端自己拉不能服务器主动推，Servlet对异步请求的支持并没有修改HTTP协议，而是对Http的巧妙利用。异步请求的核心原理主要分为两大类，一类是轮询，另一类是长连接。轮询就是定时自动发起请求检查有没有需要返回的数据，这种方式对资源的浪费是比较大的；长连接的原理是在客户端发起请求，服务端处理并返回后并不结束连接，这样就可以在后面再次运回给客户端数据。Servlet对异步请求的支持其实采用的是长连接的方式，也就是说，异步请求中在原始的请求返回的时候并没有关闭连接，关闭的只是处理请求的那个线程（一般是回收的线程池里了），只有在异步请求全部处理完之后才会关闭连接。 22.1 Servlet3．O对异步请求的支持在Servlet3.0规范巾使用异步处理请求非常简单，只需要在请求处理过程中调用request的startAsync方法即可，其返回值是AsyncContext类型。 AsyncContext在异步请求中充当着非常重要的角色，可以称为异步请求上下文也可以称为异步请求容器，无论叫什么其实就是个名字，它的作用是保存与异步请求相关的所有信息，类似于Servlet中的ServletContext。异步请求主要是使用AsyncContext进行操作，它是在请求处理的过程中调用Request的startAsync方法返回的，需要注意的是多次调用startAsync方法返回的是同一个AsyncContext。AsyncContext接口定义如下：123456789101112131415161718192021222324252627282930313233343536373839404142public interface AsyncContext &#123; static final String ASYNC_REQUEST_URI = "javax.servlet.async.request_uri"; static final String ASYNC_CONTEXT_PATH = "javax.servlet.async.context_path"; static final String ASYNC_PATH_INFO = "javax.servlet.async.path_info"; static final String ASYNC_SERVLET_PATH = "javax.servlet.async.servlet_path"; static final String ASYNC_QUERY_STRING = "javax.servlet.async.query_string"; public ServletRequest getRequest(); public ServletResponse getResponse(); public boolean hasOriginalRequestAndResponse(); public void dispatch(); public void dispatch(String path); public void complete(); public void start(Runnable run); public void addListener(AsyncListener listener); public void addListener(AsyncListener listener, ServletRequest servletRequest, ServletResponse servletResponse); public &lt;T extends AsyncListener&gt; T createListener(Class&lt;T&gt; clazz) throws ServletException; public void setTimeout(long timeout); public long getTimeout();&#125; 其中，getResponse方法用得非常多，它可以获取到response，然后就可以对response进行各种操作了；dispatch方法用于将请求发送到一个新地址，有三个重载实现方法，其中没有参数dispatch方法的会发送到request原来的地址（如果有forward则使用forward后的最后一个地址）．一个path参数的dispatch方法直接将path作为地址，两个参数的dispatch方法可以发送给别的应用指定的地址；complete方法用于通知容器请求已经处理完了；start方法用于启动实际处理线程．不过也可以自己创建线程在其中使用AsyncContext保存的信息(如response)进行处理；addListener用于添加监听器；setTimeout方法用于修改超时时间，因为异步请求一般耗时比较长，而正常的请求设置的有效时长一般比较短，所以在异步请求中很多时候都需要修改超时的时间。 22.1.1 Servlet 3.0处理异步请求实例使用Servlet 3.0处理异步请求需要三步：①配置Servlet时将async-supported设置为true；②在Servlet处理方法中调用Request的startAsync方法启动异步处理；③使用第2步中返同的AsyncContext处理异步请求。 要想使用Servlet 3.0异步请求的功能需要在配置Servlet时将async-supported设置为true，比如，配置一个叫WorkServlet的可以处理异步请求的Servlet。123456789&lt;servlet&gt; &lt;servlet-name&gt;WorkServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.excelib.servlet.WorkServlet&lt;/servlet-class&gt; &lt;async-supported&gt;true&lt;/async-supported&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;WorkServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/work&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 然后新建一个叫WorkServlet的Servlet，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.excelib.servlet;import javax.servlet.*;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;import java.text.SimpleDateFormat;import java.util.*;public class WorkServlet extends HttpServlet &#123; private static final long serialVersionUID = 1L; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; this.doPost(req, resp); &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse res) throws ServletException, IOException &#123; // 设置contentType、关闭缓存 res.setContentType("text/plain;charset=UTF-8"); res.setHeader("Cache-Control", "private"); res.setHeader("Pragma", "no-cache"); // 原始请求可以做一些简单业务的处理 final PrintWriter writer = res.getWriter(); writer.println("老板检查当前需要做的工作"); writer.flush(); // jobs表示需要做的工作，使用循环模拟初始化 List&lt;String&gt; jobs = new ArrayList&lt;&gt;(); for(int i=0;i&lt;10;i++)&#123; jobs.add("job"+i); &#125; // 使用request的startAsync方法开启异步处理 final AsyncContext ac = req.startAsync(); // 具体处理请求，内部处理启用了新线程，不会阻塞当前线程 doWork(ac, jobs); writer.println("老板布置完工作就走了"); writer.flush(); &#125; private void doWork(AsyncContext ac, List&lt;String&gt; jobs)&#123; // 设置超时时间1小时 ac.setTimeout(1*60*60*1000L); // 使用新线程具体处理请求 ac.start(new Runnable() &#123; @Override public void run() &#123; try &#123; // 从AsyncContext获取到Response进而获取到Writer PrintWriter w = ac.getResponse().getWriter(); for(String job:jobs)&#123; w.println("\""+job+"\"请求处理中。。。"); Thread.sleep(1 * 1000L); w.flush(); &#125; // 发出请求处理完成通知 ac.complete(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125;&#125; 这里的异步处理过程是在doWork方法中，它使用req．startAsync()返回的AsyncContext来处理的请求，处理完成后调用complete方法发出完成通知告诉容器请求已经处理完。doPost中除了startAsync和doWork外都是正常的操作，而且都有注释，就不解析了。当调用诸求时，返回页面结果如图22-1所示。 一个通过异步请求完成工作的示例程序就写完了。 22.1.2异步请求监听器AsyncListener上面的程序已经可以完成工作了，不过还不够完善。老板这个职业是需要思考宏观问题的，它需要宏观的数据，所以在干完活后最好给领导汇报一下什么时候干完的、干的怎么样、有没有出什么问题等综合性的数据，不过这些事情按照分工并不应该由实际干活的人来做，如果非让它们做就可能会影响效率，而且它们汇报的数据也有可能不真实，所以老板应该找专人来做这件事，这就有了二线人员。在Servlet异步请求中干这个活的二线人员就是AsyncListener监听器，AsyncListener定义如下：1234567891011public interface AsyncListener extends EventListener &#123; public void onComplete(AsyncEvent event) throws IOException; public void onTimeout(AsyncEvent event) throws IOException; public void onError(AsyncEvent event) throws IOException; public void onStartAsync(AsyncEvent event) throws IOException; &#125; onComplete方法在请求处理完成后调用，onTimeout方法在超时后调用，onError方法在出错时调用，onStartAsync方法在Request调用startAsync方法启动异步处理时调用。 这里需要注意的是只有在调用request.startAsync前将监听器添加到AsyncContext，监听器的onStartAsync方法才会起作用，而调用startAsync前AsyncContext还不存在，所以第一次调用startAsync是不会被监听器中的onStartAsync方法捕获的，只有在超时后又重新开始的情况下onStartAsync方法才会起作用。这一般也没有什么太大的问题，就像上面的例子中开始的时候是老板安排的任务，他自己当然知道，所以不汇报也没关系，不过如果到了时间节点任务没完成又重新开始了那还是要汇报的。 我们给前面的WorkServlet添加两个AsyncListener监听器BossListener和LeaderListener．一个用来给老板汇报，另一个用来给项目负责人汇报，它们都是定义在WorkServlet中的私有类，而且代码也都一样，其中BossListener的代码如下：1234567891011121314151617181920private class BossListener implements AsyncListener &#123; final SimpleDateFormat formatter = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); @Override public void onComplete(AsyncEvent event) throws IOException &#123; System.out.println("在" + formatter.format(new Date()) + "工作处理完成"); &#125; @Override public void onError(AsyncEvent event) throws IOException &#123; System.out.println("在" + formatter.format(new Date()) + "工作处理出错，详情如下：\t" +event.getThrowable().getMessage()); &#125; @Override public void onStartAsync(AsyncEvent event) throws IOException &#123; System.out.println("在" + formatter.format(new Date()) + "工作处理开始"); &#125; @Override public void onTimeout(AsyncEvent event) throws IOException &#123; System.out.println("在" + formatter.format(new Date()) + "工作处理超时"); &#125;&#125; 然后将监听器注册到WorkServlet中，注册方法是在获取到AsyncContext后将监听器添加进去，相关代码如下：123456789// 使用request的startAsync方法开启异步处理final AsyncContext ac = req.startAsync();// 添加两个监听器ac.addListener(new BossListener());ac.addListener(new LeaderListener(), req, res);// 具体处理请求，内部处理启用了新线程，不会阻塞当前线程doWork(ac, jobs);writer.println("老板布置完工作就走了");writer.flush(); 这样就将两个监听器注册完了。这里之所以添加了两个监听器，是要告诉大家一个AsyncContext可以添加多个监听器，而且有两个重载的添加方法。在监听器中可以使用AsyncEvent事件获取Request、Response以及在有异常的时候获取Throwable，代码如下：123event.getSuppliedRequest();event.getSuppliedReponse();event.getThrowable(); ##22.2 Spring MVC中的异步请求 Spring MVC为了方便使用异步请求专门提供了AsyncWebRequest类型的request，并且提供了处理异步请求的管理器WebAsyncManager和工具WebAsyncUtils。 Spring MVC将异步请求细分为了Callable、WebAsyncTask、DeferredResult和ListenableFuture四种类型。前两种是一类，它们的核心是Callable，这一类很容易理解，因为大家对Callable应该都比较熟悉；DeferredResult类可能不是很容易理解，因为它是Spring MVC自己定义的类型，我们平时可能没使用过，而且相关资料也不多，所以刚接触的时候会觉得不知道从哪里人手，不过弄明白后其实是非常简单的；ListenableFuture足Spring MVC4.0新增的，它在Java的Future基础上增加了设置回调方法的功能，主要用于需要在处理器中调用别的资源（如别的url）的情况，Spring MVC专门提供了AsyncRestTemplate方法调用别的资源，并返回ListenableFuture类型。 本章先分析Spring MVC中异步请求使用到的组件，然后分析Spring MVC是怎么使用这些组件处理异步请求的，最后再分别对每一类返回值进行介绍。 22.2.1 Spring MVC中异步请求相关组件这里主要分析AsyncWebRequest、WebAsyncManager和WebAsyncUtils组件。WebAsyncManager里面还包含了一些别的组件，在分析的过程中也一起分析。AsyncWebRequest首先来看AsyncWebRequest，它是专门用来处理异步请求的request，定义如下：1234567891011121314151617public interface AsyncWebRequest extends NativeWebRequest &#123; void setTimeout(Long timeout); void addTimeoutHandler(Runnable runnable); void addCompletionHandler(Runnable runnable); void startAsync(); boolean isAsyncStarted(); void dispatch(); boolean isAsyncComplete();&#125; 其中，addTimeoutHandler方法和addCompletionHandler方法分别用于添加请求超时和请求处理完成的处理器，其作用相当于AsyncListener监听器中的onTimeout和onComplete方法；isAsyncStarted方法用于判断是否启动了异步处理；isAsyncComplete方法用于判断异步处理是否已经处理完了。别的方法都与AsyncContext中的同名方法作用一样，就不一一解释了。它的实现类有两个，一个是NoSupportAsyncWebRequest，另一个是StandardServletAsyncWebRequest，前者不支持异步请求，所以在Spring MVC中实际用作异步请求的request是StandardServletAsync WebRequest. StandardServletAsyncWebRequest除了实现了AsyncWebRequest接口，还实现了AsyncListener接口，另外还继承了ServletWebRequest，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class StandardServletAsyncWebRequest extends ServletWebRequest implements AsyncWebRequest, AsyncListener &#123; private Long timeout; private AsyncContext asyncContext; private AtomicBoolean asyncCompleted = new AtomicBoolean(false); private final List&lt;Runnable&gt; timeoutHandlers = new ArrayList&lt;Runnable&gt;(); private final List&lt;Runnable&gt; completionHandlers = new ArrayList&lt;Runnable&gt;(); /** * Create a new instance for the given request/response pair. * @param request current HTTP request * @param response current HTTP response */ public StandardServletAsyncWebRequest(HttpServletRequest request, HttpServletResponse response) &#123; super(request, response); &#125; /** * &#123;@inheritDoc&#125; * &lt;p&gt;In Servlet 3 async processing, the timeout period begins after the * container processing thread has exited. */ @Override public void setTimeout(Long timeout) &#123; Assert.state(!isAsyncStarted(), "Cannot change the timeout with concurrent handling in progress"); this.timeout = timeout; &#125; @Override public void addTimeoutHandler(Runnable timeoutHandler) &#123; this.timeoutHandlers.add(timeoutHandler); &#125; @Override public void addCompletionHandler(Runnable runnable) &#123; this.completionHandlers.add(runnable); &#125; @Override public boolean isAsyncStarted() &#123; return ((this.asyncContext != null) &amp;&amp; getRequest().isAsyncStarted()); &#125; /** * Whether async request processing has completed. * &lt;p&gt;It is important to avoid use of request and response objects after async * processing has completed. Servlet containers often re-use them. */ @Override public boolean isAsyncComplete() &#123; return this.asyncCompleted.get(); &#125; @Override public void startAsync() &#123; Assert.state(getRequest().isAsyncSupported(), "Async support must be enabled on a servlet and for all filters involved " + "in async request processing. This is done in Java code using the Servlet API " + "or by adding \"&lt;async-supported&gt;true&lt;/async-supported&gt;\" to servlet and " + "filter declarations in web.xml."); Assert.state(!isAsyncComplete(), "Async processing has already completed"); if (isAsyncStarted()) &#123; return; &#125; this.asyncContext = getRequest().startAsync(getRequest(), getResponse()); this.asyncContext.addListener(this); if (this.timeout != null) &#123; this.asyncContext.setTimeout(this.timeout); &#125; &#125; @Override public void dispatch() &#123; Assert.notNull(this.asyncContext, "Cannot dispatch without an AsyncContext"); this.asyncContext.dispatch(); &#125; // --------------------------------------------------------------------- // Implementation of AsyncListener methods // --------------------------------------------------------------------- @Override public void onStartAsync(AsyncEvent event) throws IOException &#123; &#125; @Override public void onError(AsyncEvent event) throws IOException &#123; &#125; @Override public void onTimeout(AsyncEvent event) throws IOException &#123; for (Runnable handler : this.timeoutHandlers) &#123; handler.run(); &#125; &#125; @Override public void onComplete(AsyncEvent event) throws IOException &#123; for (Runnable handler : this.completionHandlers) &#123; handler.run(); &#125; this.asyncContext = null; this.asyncCompleted.set(true); &#125;&#125; 这里的代码比较长，不过很容易理解，它里面封装了个AsyncContext类型的属性asyncContext，在startAsync方法中会将Request#startAsync返回的AsyncContext设置给它，然后在别的地方主要使用它来完成各种功能。 另外，南于StandardServletAsyncWebRequest实现了AsyncListener接口，所以它自己就是一个监听器，而且在startAsync方法中在创建出AsyncContext后会将自己作为监听器添加进去。监听器实现方法中onStartAsync方法和onError方法是空实现，onTimeout方法和onComplete方法分别调用了封装的两个List类型的属性timeoutHandlers和completionHandlers所保存的Runnable方法，这样在使用时只需要简单地将需要监听超时和处理完成的监听方法添加到这两个属性中就可以了。 WebAsyncManager WebAsyncManager是Spring MVC处理异步请求过程中最核心的类，它管理着整个异步处理的过程。 WebAsyncManager中最重要的两个方法是startCallableProcessing和startDeferredResultProcessing，这两个方法是启动异步处理的人口方法，它们一共做了三件事：①启动异步处理；②给Request设置相应属性（主要包括timeout、timeoutHandler和completionHandler）；③在相应位置调用相应的拦截器。这里的拦截器是Spring MVC自己定义的。 startCallableProcessing方法用于处理Callable和WebAsyncTask类型的异步请求，使用的拦截器类型是CallableProcessingInterceptor，拦截器封装在CallablelnterceptorChain粪型的拦截器链中统一调用。 startDeferredResultProcessing方法用于处理DeferredResult和ListenableFuture类型的异步请求，使用的拦截器是DeferredResultProcessinglnterceptor拦截器，拦截器封装在DeferredResultlnterceptorChain类型的拦截器链中统一调用。 这两个拦截器的定义如下：1234567891011121314151617public interface CallableProcessingInterceptor &#123; static final Object RESULT_NONE = new Object(); static final Object RESPONSE_HANDLED = new Object(); &lt;T&gt; void beforeConcurrentHandling(NativeWebRequest request, Callable&lt;T&gt; task) throws Exception; &lt;T&gt; void preProcess(NativeWebRequest request, Callable&lt;T&gt; task) throws Exception; &lt;T&gt; void postProcess(NativeWebRequest request, Callable&lt;T&gt; task, Object concurrentResult) throws Exception; &lt;T&gt; Object handleTimeout(NativeWebRequest request, Callable&lt;T&gt; task) throws Exception; &lt;T&gt; void afterCompletion(NativeWebRequest request, Callable&lt;T&gt; task) throws Exception;&#125; 拦截器的作用就是在不同的时间点通过执行相应的方法来做一些额外的事情，所以要学习一种拦截器主要就是要理解它里边的各个方法执行的时间点。这两拦截器都定义了5个方法，方法名也都一样，而且从名字就很容易理解它们执行的时间点，就不分别解释了。需要注意的是，beforeConcurrentHandling方法是在并发处理前执行的，也就是会在主线程中执行，其他方法都在具体处理请求的子线程中执行。 CallableInterceptorChain和DeferredResultlnterceptorC hain分别用于封装两个Interceptor，它们都是将多个相应的拦截器封装到一个List类型的属性，然后在相应的方法中调用所封装的Interceptor相应方法进行处理。大家是不是很熟悉？它跟前面多次便用的XXXComposite组件类似，也是责任链模式。不过和XXXComposite组件不同的是，这里的方法名与Interceptor中稍有区别，它们的对应关系如下： applyBe foreConcurrentHandling：对应Interceptor中的beforeConcurrentHandling方法。 applyPreProcess：对应Interceptor中的preProcess方法。 applyPostProcess：对应Interceptor中的postProcess方法。 triggerAfterTimeout:对应Interceptor中的afierTimeout方法。 triggerAfterCompletion：对应Interceptor中的afterCompletion方法。 理解了这些方法就知道Interceptor和InterceptorChain的作用了，它们都是在WebAsyncManager中相应位置调用的。 在正式分析WebAsyncManager前再看一下WebAsyncTask类，只有理解了这个类才能看明白WebAsyncManager中酌stariCallableProcessing方法。WebAsyncTask的作用主要是封装Callable方法，并且提供了一些异步调用相关的属性，理解了其中包含的属性就明白这个类了，其中属性定义如下：12345678910111213private final Callable&lt;V&gt; callable;private Long timeout;private AsyncTaskExecutor executor;private String executorName;private BeanFactory beanFactory;private Callable&lt;V&gt; timeoutCallback;private Runnable completionCallback; callable用来实际处理请求；timeout用来设置超时时间；executor用来调用callable；executorName用来用容器中注册的名字配置executor；beanFactory用于根据名字获取executor; timeoutCallback相completionCallback分别用于执行超时和请求处理完成的回调。 这里的executor可以直接设置到WebAsyncTask中，也可以使用注册在容器中的名字来设置executorName属性，如果是使用名字来设置的WebAsyncTask的getExecutor方法会从beanFactory中根据名字executorName获取AsyncTaskExecutor，代码如下：123456789101112public AsyncTaskExecutor getExecutor() &#123; if (this.executor != null) &#123; return this.executor; &#125; else if (this.executorName != null) &#123; Assert.state(this.beanFactory != null, "BeanFactory is required to look up an executor bean by name"); return this.beanFactory.getBean(this.executorName, AsyncTaskExecutor.class); &#125; else &#123; return null; &#125;&#125; 多知道点 如何在Java中使用并发处理 并发处理是通过多线程完成的，在Java中定义一个多线程的任务可以通过实现Runnable或者Callable接口完成，先来看一下Runnable接定义如下：123456789101112131415@FunctionalInterfacepublic interface Runnable &#123; /** * When an object implementing interface &lt;code&gt;Runnable&lt;/code&gt; is used * to create a thread, starting the thread causes the object's * &lt;code&gt;run&lt;/code&gt; method to be called in that separately executing * thread. * &lt;p&gt; * The general contract of the method &lt;code&gt;run&lt;/code&gt; is that it may * take any action whatsoever. * * @see java.lang.Thread#run() */ public abstract void run();&#125; Runnable里只有一个run方法，我们只需要将需要执行的代码放到里面即可，行需要新建一个线程来调用，示例如下：12345678Runnable task = new Runnable()&#123; @Override public void run() System.out.println("do task"); &#125; Thread thread = new Thread(task); thread.start();&#125; 这里新建了task的Runnable类型任务，然后使用它创建了Thread并调用start方法执行了任务。需要说明的是，Thread本身也继承了Runnable接口，所以直接使用Thread来创建Runnable类型的任务然后执行，比如，上面的代码可以修改为：1234567new Thread()&#123; @Override public void run() &#123; System.out.println("do task"); &#125;&#125;.start(); 这样一句代码就可以完成了。 在JavaI.5中新增了Callable接口，定义如下：123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; Callable里面是call方法，而且可以有返回值还可以处理异常。Callable的执行需要有一个Executor容器来调用，就像Runnable任务需要Thread来调用一样，而且Executor也可以调用Runnable类型的任务。ExecutoriB用后会返回一个Future类型的返回值，我们可以调用Future的get方法来获取Callable中call方法的返回值，不过这个方法是阻塞的，只有call方法执行完后才会返回，示例如下：1234567891011121314ExecutorsService = Executors.newCachedThreadPool();Callable callableTask = new Callable&lt;String&gt;() &#123; public String call() throws Exception&#123; Thread.sleep(1000); System.out.println("do task"); return "ok"; &#125;&#125;;Future&lt;String&gt; future = executor.submit(callableTask);System.out.println("after submit task");String result = future.get();System.out.println("after future.get()");System.out.println("result="+result);executor.shudown(); 这里定义了一个Callable类型的callableTask任务，在其call方法中会等待1秒然后输出dotask并返回ok。Executor调用submit方法提交任务后主程序输出aftersubmittask，这个应该在异步任务返回之前输出，因为方法需要等待1秒，输出aftersubmittask后调用future.get()，这时主线程会阻塞,直到call方法返回，然后输出”afterfuture.get()”，最后输出call返回的结果”ok”，程序运行后控制台打印如下： after submit taskdo taskafter future.get()result=ok 下面来看WebAsyncManager，首先介绍它里面的几个重要属性： timeoutCallablelnterceptor：CallableProcessinglnterceptor类型,专门用于Callable和WebAnsyncTask类型超时的拦截器 timeoutDeferredResultlnterceptor：DeferredResultProcessinglnterceptor类型，专门用于DeferredResult和ListenableFuture类型超时的拦截器。 callablelnterceptors: Map类型，用于所有Callable和WebAsyncTask类型的拦截器。 deferredResultlnterceptors：Map类型，用于所有DeferredResult和ListenableFuture类型的拦截器。 asyncWebRequest：为了支持异步处理而封装的request。 taskExecutor：用于执行Callable和WebAsyncTask类型处理，如果WebAsyncTask中没有定义executor则使用WebAsyncManager中的taskExecutor。 下面分析WebAsyncManager里最核心的两个方法startCallableProcessing和startDeferredResultProcessing，这两个方法的逻辑基本一样，选择其中的startCallableProcessing来分析，这个方法用于启动Callable和WebAsyncTask类型的处理，代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * Use the given &#123;@link WebAsyncTask&#125; to configure the task executor as well as * the timeout value of the &#123;@code AsyncWebRequest&#125; before delegating to * &#123;@link #startCallableProcessing(Callable, Object...)&#125;. * @param webAsyncTask a WebAsyncTask containing the target &#123;@code Callable&#125; * @param processingContext additional context to save that can be accessed * via &#123;@link #getConcurrentResultContext()&#125; * @throws Exception if concurrent processing failed to start */ public void startCallableProcessing(final WebAsyncTask&lt;?&gt; webAsyncTask, Object... processingContext) throws Exception &#123; Assert.notNull(webAsyncTask, "WebAsyncTask must not be null"); Assert.state(this.asyncWebRequest != null, "AsyncWebRequest must not be null"); Long timeout = webAsyncTask.getTimeout(); if (timeout != null) &#123; this.asyncWebRequest.setTimeout(timeout); &#125; AsyncTaskExecutor executor = webAsyncTask.getExecutor(); if (executor != null) &#123; this.taskExecutor = executor; &#125; List&lt;CallableProcessingInterceptor&gt; interceptors = new ArrayList&lt;CallableProcessingInterceptor&gt;(); interceptors.add(webAsyncTask.getInterceptor()); interceptors.addAll(this.callableInterceptors.values()); interceptors.add(timeoutCallableInterceptor); final Callable&lt;?&gt; callable = webAsyncTask.getCallable(); final CallableInterceptorChain interceptorChain = new CallableInterceptorChain(interceptors); this.asyncWebRequest.addTimeoutHandler(new Runnable() &#123; @Override public void run() &#123; logger.debug("Processing timeout"); Object result = interceptorChain.triggerAfterTimeout(asyncWebRequest, callable); if (result != CallableProcessingInterceptor.RESULT_NONE) &#123; setConcurrentResultAndDispatch(result); &#125; &#125; &#125;); this.asyncWebRequest.addCompletionHandler(new Runnable() &#123; @Override public void run() &#123; interceptorChain.triggerAfterCompletion(asyncWebRequest, callable); &#125; &#125;); interceptorChain.applyBeforeConcurrentHandling(this.asyncWebRequest, callable); startAsyncProcessing(processingContext); this.taskExecutor.submit(new Runnable() &#123; @Override public void run() &#123; Object result = null; try &#123; interceptorChain.applyPreProcess(asyncWebRequest, callable); result = callable.call(); &#125; catch (Throwable ex) &#123; result = ex; &#125; finally &#123; result = interceptorChain.applyPostProcess(asyncWebRequest, callable, result); &#125; setConcurrentResultAndDispatch(result); &#125; &#125;); &#125; 通过注释可以看到startCallableProcessing方法主要做了5件事：①将webAsyncTask中相关属性取出并设置到对应的地方；②初始化拦截器链；③给asyncWebRequest设置timeoutHandler和completionHandler；④执行处理器链中相应方法；⑤启动异步处理并使用taskExecutor提交任务。 对其中的启动处理和执行处理详细解释一下，启动处理是调用了startAsyncProcessing方法，其中做了三件事：①调用clearConcurrentResult方法清空之前并发处理的结果；②谰用asyncWebRequest的startAsync方法启动异步处理；③将processingContext设置给concurrentResultContext属性。startAsyncProcessing方法的代码如下：123456789101112131415161718192021private void startAsyncProcessing(Object[] processingContext) &#123; clearConcurrentResult(); this.concurrentResultContext = processingContext; this.asyncWebRequest.startAsync(); if (logger.isDebugEnabled()) &#123; HttpServletRequest request = this.asyncWebRequest.getNativeRequest(HttpServletRequest.class); String requestUri = urlPathHelper.getRequestUri(request); logger.debug("Concurrent handling starting for " + request.getMethod() + " [" + requestUri + "]"); &#125;&#125;/** * Clear &#123;@linkplain #getConcurrentResult() concurrentResult&#125; and * &#123;@linkplain #getConcurrentResultContext() concurrentResultContext&#125;. */public void clearConcurrentResult() &#123; this.concurrentResult = RESULT_NONE; this.concurrentResultContext = null;&#125; processingContext参数传进来的是处理器中使用的ModelAndViewContainer，concurrentResultContext用来在WebAsyncManager中保存ModelAndViewContainer，在请求处理完成后会设置到RequestMappingHandlerAdapter中，具体过程后面再分析。 下面再来说一下执行处理，执行处理使用的是taskExecutor，不过需要注意的是，这里并没直接使用taskExecutor.submit(callable)来提交，而是提交了新建的Runnable，并将Callable的call方法直接放在run方法里调用。代码如下：1234567891011121314151617this.taskExecutor.submit(new Runnable() &#123; @Override public void run() &#123; Object result = null; try &#123; interceptorChain.applyPreProcess(asyncWebRequest, callable); result = callable.call(); &#125; catch (Throwable ex) &#123; result = ex; &#125; finally &#123; result = interceptorChain.applyPostProcess(asyncWebRequest, callable, result); &#125; setConcurrentResultAndDispatch(result); &#125; &#125;); 这么做主要有两个作用：①可以在处理过程中的相应位置调用拦截器链中相应的方法；②在call方法执行完之前不会像Future#get()那样阻塞线程。 不过Runnable是没有返回值的，所以Callable处理的结果需要自己从run方法内部传递出来，WebAsyncManager中专门提供了一个setConcurrentResultAndDispatch方洪来处理返回的结果，这里边会将处理的结果传递出来，代码如下：1234567891011121314151617181920private void setConcurrentResultAndDispatch(Object result) &#123; synchronized (WebAsyncManager.this) &#123; if (hasConcurrentResult()) &#123; return; &#125; this.concurrentResult = result; &#125; if (this.asyncWebRequest.isAsyncComplete()) &#123; logger.error("Could not complete async processing due to timeout or network error"); return; &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Concurrent result value [" + this.concurrentResult + "] - dispatching request to resume processing"); &#125; this.asyncWebRequest.dispatch();&#125; concurrentResult是WebAsyncManager中用来保存异步处理结果的属性，hasConcurrentResult方法用来判断concurrentResult是否已经存在返回值。整个方法过程是：如果concurrentResult已经有返回值则直接返回，否则将传人的参数设置到concurrentResult，然后调用asyncWebRequest.isAsyncComplete()检查Request是否已设置为异步处理完成状态（网络中断会造成Request设置为异步处理完成状态），如果是则保存错误日志并返回，否则调用asyncWebRequest.dispatch0发送请求。SpringMVC申异步请求处理完成后会再次发起一个相同的请求，然后在HandlerAdapter中使用一个特殊的HandlerMethod来处理它，具体过程后面再讲解，不过通过Request的dispatch方法发起的请求使用的还是原来的Request，也就是说原来保存在Request中的属性不会丢失。 startDeferredResultProcessing方法和startCallableProcessing方法执行过程类似，只是并没有使用taskExecutor来提交执行，这是因为DeferredResult并不需要执行处理，在后面讲了DeferredResult的用法后大家就明白了。 WebAsyncManager就分析到这里，下面来看WebAsyncUtils。 WebAsyncUtils WebAsyncUtils里面提供了四个静态方法，其中一个是private权限，只供内部调用的，也就是一共提供了三个供外部使用的静态方法。它们定义如下： public static WebAsyncManager getAsyrtcManager (ServletRequest servletRequest) public static WebAsyncManager getAsyncManager (WebRequest webRequest) `public static AsyncWebRequest createAsyncWebRequest (HttpServletRequest request, HttpServletResponse response) 两重载的getAsyncManager方法通过Request获取WebAsyncManager，它们一个使用ServletRequest类型的Request，一个使用WebRequest类型的Request，获取过程都是先判断Request属性里是否有保存的WebAsyncManager对象，如果有则取出后直接返回，如果没有则新建一个设置到Request的相应属性中并返回，下次再获取时直接从Request属性中取出。 createAsyncWebRequest方法用于创建AsyncWebRequest，它使用ClassUtils.hasMethod判断传人的Request是否包含startAsync方法从而判断是否支持异步处理，如果不支持则新建NoSupportAsyncWebRequest类型的Request并返回，如果支持则调用createStandardServletAsyncWebRequest方法创建StandardServletAsync WebRequest类型的Request并返回。 22.2.2 Spring MVC对异步请求的支持Spring MVC对异步请求的处理主要在四个地方进行支持，详述如下：1)FrameworkServlet中给当前请求的WebAsyncManager添加了CallableProcessinglnterceptor类型的拦截器RequestBindinglnterceptor，这是定义在FrameworkServlet内部的一个私有的拦截器，其作用还是跟FrameworkServlet处理正常请求一样，在请求处理前将当前请求的LocaleContext和ServletRequestAttributes设置到了LocaleContextHolder和RequestContextHolder中，并在请求处理完成后恢复，添加过程在processRequest方法中，相关代码如下：123456789101112131415161718192021WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor());private class RequestBindingInterceptor extends CallableProcessingInterceptorAdapter &#123; @Override public &lt;T&gt; void preProcess(NativeWebRequest webRequest, Callable&lt;T&gt; task) &#123; HttpServletRequest request = webRequest.getNativeRequest(HttpServletRequest.class); if (request != null) &#123; HttpServletResponse response = webRequest.getNativeRequest(HttpServletResponse.class); initContextHolders(request, buildLocaleContext(request), buildRequestAttributes(request, response, null)); &#125; &#125; @Override public &lt;T&gt; void postProcess(NativeWebRequest webRequest, Callable&lt;T&gt; task, Object concurrentResult) &#123; HttpServletRequest request = webRequest.getNativeRequest(HttpServletRequest.class); if (request != null) &#123; resetContextHolders(request, null, null); &#125; &#125;&#125; 2) RequestMappingHandlerAdapter酌invokeHandleMethod方法提供了对异步请求的核心支持，其中做了四件跟异步处理相关的事情： 创建AsyncWebRequest并设置超时时间，具体时间可以通过asyncRequestTimeout属性配置到RequestMappingHandlerAdapter申。 对当前请求的WebAsyncManager设置了四个属性：taskExecutor,asyncWebRequest,callablelnterceptors和deferredResultlnterceptors，除了asyncWebRequest的另外三个都可以在RequestMappingHandlerAdapter中配置，taskExecutor如果没配置将默认使用SimpleAsyncTaskExecutor。 如果当前请求是异步请求而且已经处理出了结果，则将异步处理结果与之前保存到WebAsyncManager里的ModeIAnd\fiewContainer取出来,并将WebAsyncManager里的结果清空，然后调用ServletlnvocableHandlerMethod的wrapConcurrentResult方法创建ConcurrentResultHandlerMethod类型（ServletlnvocableHandlerMethod的内部类）的ServletlnvocableHandlerMethod来替换自己，创建出来的ConcurrentResultHandlerMethod并不执行请求，它的主要功能是判断异步处理的结果是不是异常类型，如果是则抛出，如果不是则使用ReturnValueHandler对其进行解析并返回。 如果requestMappingMethod的invokeAndHandle方法执行完后检查到当前请求已经启动了异步处理，则会直接返回null。 RequestMappingHandlerAdapter中相关代码如下：12345678910111213141516171819202122232425AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response);asyncWebRequest.setTimeout(this.asyncRequestTimeout);final WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);asyncManager.setTaskExecutor(this.taskExecutor);asyncManager.setAsyncWebRequest(asyncWebRequest);asyncManager.registerCallableInterceptors(this.callableInterceptors);asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors);if (asyncManager.hasConcurrentResult()) &#123; Object result = asyncManager.getConcurrentResult(); mavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0]; asyncManager.clearConcurrentResult(); if (logger.isDebugEnabled()) &#123; logger.debug("Found concurrent result value [" + result + "]"); &#125; requestMappingMethod = requestMappingMethod.wrapConcurrentResult(result);&#125;requestMappingMethod.invokeAndHandle(webRequest, mavContainer);if (asyncManager.isConcurrentHandlingStarted()) &#123; return null;&#125; 这里的步骤3是调用了ServletInvocableHandlerMethod的wrapConcurrentResult方法创建了新的ServletlnvocableHandlerMethod来处理异步处理的结果，代码如下：123ServletInvocableHandlerMethod wrapConcurrentResult(Object result) &#123; return new ConcurrentResultHandlerMethod(result, new ConcurrentResultMethodParameter(result)); &#125; ConcurrentResultHandlerMethod是在ServletlnvocableHandlerMethod中定义的继承白ServletInvocableHandlerMethod的内部类，代码如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private static final Method CALLABLE_METHOD = ClassUtils.getMethod(Callable.class, "call");private class ConcurrentResultHandlerMethod extends ServletInvocableHandlerMethod &#123; private final MethodParameter returnType; public ConcurrentResultHandlerMethod(final Object result, ConcurrentResultMethodParameter returnType) &#123; super(new Callable&lt;Object&gt;() &#123; @Override public Object call() throws Exception &#123; if (result instanceof Exception) &#123; throw (Exception) result; &#125; else if (result instanceof Throwable) &#123; throw new NestedServletException("Async processing failed", (Throwable) result); &#125; return result; &#125; &#125;, CALLABLE_METHOD); setHandlerMethodReturnValueHandlers(ServletInvocableHandlerMethod.this.returnValueHandlers); this.returnType = returnType; &#125; /** * Bridge to actual controller type-level annotations. */ @Override public Class&lt;?&gt; getBeanType() &#123; return ServletInvocableHandlerMethod.this.getBeanType(); &#125; /** * Bridge to actual return value or generic type within the declared * async return type, e.g. Foo instead of &#123;@code DeferredResult&lt;Foo&gt;&#125;. */ @Override public MethodParameter getReturnValueType(Object returnValue) &#123; return this.returnType; &#125; /** * Bridge to controller method-level annotations. */ @Override public &lt;A extends Annotation&gt; A getMethodAnnotation(Class&lt;A&gt; annotationType) &#123; return ServletInvocableHandlerMethod.this.getMethodAnnotation(annotationType); &#125;&#125; ConcurrentResultHandlerMethod调用父类的构造方法(super)将HandlerMethod中的Handler和Method都替换掉了，Handler用了新建的匿名Callable，Method使用了ServletInvocableHandlerMethod酌静态属性CALLABLE—METHOD，它代码Callable的call方法。新建的Callable的执行逻辑也非常简单，就是判断异步处理的返回值是不是异常类型，如果是则抛出异常，不是则直接返回，然后使用和原来请求一样的返回值处理器处理返回值（因为在构造方法中将原来ServletjnvocableHandlerMethod的返回值处理器设置给了自己）。 3)返回值处理器：一共有四个处理异步请求的返回值处理器，它们分别是AsyncTaskMethodReturnValueHandler、CallableMethodReturnValueHandler、De ferredResultMethodReturn ValueHandler和ListenableFutureReturnValueHandler，每一个对应一种类型的返回值，它们的作用主要是使用WebAsyncManager启动异步处理，后面依次对每一类返回值进行分析。 4)在DispatcherServlet的doDispatch方法中，当HandlerAdapter使用Handler处理完请求耐，会检查是否已经启动了异步处理，如果启动了则不再往下处理，直接返回，相关代码如下：123456// Actually invoke the handler.mv = ha.handle(processedRequest, response, mappedHandler.getHandler());if (asyncManager.isConcurrentHandlingStarted()) &#123; return;&#125; 检查方法是调用的WebAsyncManager的isConcurrentHandlingStarted方法，其实内部就是调用的request的isAsyncStarted方法，代码如下：1234567891011/** * Whether the selected handler for the current request chose to handle the * request asynchronously. A return value of "true" indicates concurrent * handling is under way and the response will remain open. A return value * of "false" means concurrent handling was either not started or possibly * that it has completed and the request was dispatched for further * processing of the concurrent result. */public boolean isConcurrentHandlingStarted() &#123; return ((this.asyncWebRequest != null) &amp;&amp; this.asyncWebRequest.isAsyncStarted());&#125; Spring MVC中跟异步请求处理相关的四个位置孰分析完了。主要处理流程是这样的：首先在处理器中返回需要启动异步处理的类型时（四种类型）相应返同值处理器会调用WebAsyncManager的相关方法启动异步处理，然后在DispatcherServlet中将原来请求直接返回，当异步处理完成后会重新发出一个相同的请求，这时在RequestMappingHandlerAdapter中会使用特殊的ServletlnvocableHandlerMethod来处理请求，处理方法是：如果异步处理返回的结果是异常类型则抛出异常，否则直接返回异步处理结果，然后使用返回值处理器处理，接着返回DispatcherServlet中按正常流程往下处理。 异步处理完成后会重新发起一个请求，这时会重新查找HandlerMethod并初始化PathVariable、MatrixVariable等参数，重新初始化Model中的数据并再次执行Handler-Interceptor中相应的方法。这么做主要是可以复用原来的那套组件进行处理而不需要重新定义。不过新请求的HandlerMethod是用的专门的类型，而Model是使用的原来保存在WebAsyncManager的concurrentResultContext届性中的ModelAndViewContainer所保存的Model，所以这里的查找HandlerMethod和初始化Model的过程是没用的，在这里可以进行一些优化，比如，将创建ConcurrentResultHandlerMethod的过程放在HandlerMapping中（这样也更符合组件的功能），然后在调用ModeIFactory的initModel方法前判断是不是异步处理dispatcher过来的请求，如果是则不再初始化了，或者干脆创建新的HandlerAdapter来处理。 除了上述可以优化的地方，这里还有两个漏洞，第一个是相应的拦截器里的方法会被调用两次，这是不合适的，而且有的时候还会出问题，比如，如果用了拦截器来检查Token．那么第一次检查通过后就会将相应内容删除，第二次再检查的时候就检查失败了，这就有问题了。第二个是通过FlashMap传递Redirect参数的情况，在前面分析FlashMapManager获取FlashMap的时候说过，每次获取后就会将相应的FlashMap删除，但异步请求会获取两次，如果异步处理器是Redirect刭的结果处理器，并且使用FlashMap传递了参数，这种情况下如果在第二次获取FlashMap的时候（异步请求处理完了）正好用户又发了一个相同的请求，而且RedirectView已经将FlashMap设置到了Session，在获取之前可能被前面的请求获取删除，导致自己获取不到，这么说不容易理解，下面将两个请求的处理过程列出来大家就容易理解了： 请求1 请求2 saveOutputFlashMap 设置FM1 retrieveAndUpdate 获取到FM1 saveOutputFlashMap 设置FM2 retrieveAndUpdate 获取到FM2 retrieveAndUpdate 获取到null retrieveAndUpdate 获取到null 这样请求2设置的FlashMap就会被请求1的第二次retrieveAndUpdate获取到并从Session中删除，请求2就获取不到了，这样两个请求的值就都出了问题了。 这里的第二个漏洞只是从原理上来说存在，一般不会造成什么影响，因为这种情况发生的概率非常小，但第一个漏洞是比较严重的，如果真正使用了类似判断Token等的拦截器需要在具体方法内部自己处理一下。 异步处理流程就说到这里，下面分析每一类返回值的具体处理过程。 22.2.3 WebAsyncTask和Calla ble类型异步请求的处理过程及用法当处理器方法返回WebAsyncTask或Callable类型时将自动启用异步处理。下面来看一下处理WebAsyncTask类型返回值的处理器AsyncTaskMethodReturnValueH andler．它的handleReturnValue方法如下：12345678910111213@Overridepublic void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123; if (returnValue == null) &#123; mavContainer.setRequestHandled(true); return; &#125; WebAsyncTask&lt;?&gt; webAsyncTask = (WebAsyncTask&lt;?&gt;) returnValue; webAsyncTask.setBeanFactory(this.beanFactory); WebAsyncUtils.getAsyncManager(webRequest).startCallableProcessing(webAsyncTask, mavContainer);&#125; 如果返回值为null，就会给mavContainer设置为请求已处理，然后返回。如果返回值不为null，调用WebAsyncManager的startCallableProcessing方法处理请求。WebAsyncManager是使用WebAsyncUtils获取的。下面来看一个例子，首先给配置Spring MVC的Servlet添加异步处理支持，也就是添加async-supported属性，代码如下：123456789&lt;servlet&gt; &lt;servlet-name&gt;let'sGo&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;WEB-INF/let'sGo-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;async-supported&gt;true&lt;/async-supported&gt;&lt;/servlet&gt; 接下来写一个AsyncController，代码如下:123456789101112131415161718192021222324252627package com.excelib.controller;import javax.servlet.*;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;@Controllerpublic class AsyncController &#123; @ResponseBody @RequestMapping(value = "/webasynctask",produces = "text/plain; charset=UTF-8") public WebAsyncTask&lt;String&gt; webAsyncTask()&#123; System.out.println("WebAsyncTask处理器主线程进入"); WebAsyncTask&lt;String&gt; task = new WebAsyncTask&lt;String&gt;(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; Thread.sleep(5*1000L); System.out.println("WebAsyncTask处理执行中。。。"); return "久等了"; &#125; &#125;); System.out.println("WebAsyncTask处理器主线程退出"); return task; &#125;&#125; 这里新建了WebAsyncTask，并使用匿名类建了Callable进行异步处理，实际使用中可以在其中写数据库请求等耗时的业务，这里直接等了5秒来模拟。处理器注释了@ResponseBody，其返回值会直接返回给浏览器。当调用http://localhost:8080/ webasynctask时，会在等待大约5秒后返回给浏览器久等了三个字。 现在再返回去看WebAsyncManager的startCallableProcessing方法就容易理解了，其实就是先添加拦截器，并在相应的地方执行拦截器里的方法，最后使用taskExecutor调用返回WebAsyncTask申的Callable处理。 当然这里只是给WebAsyncTask设置了Callable，除此之外还可以设置executor、timeout、timeoutCallback和completionCallback等属性。 Callable的处理其实是在WebAsyncManager内部封装成WebAsyncTask后再处理的。当处理器中返回Callable类型的返回值时，Spring MVC会使用CallableMethodReturnValueHandler来处理返回值，它的handleReturnValue方法代码如下：123456789101112131415161718192021public class CallableMethodReturnValueHandler implements HandlerMethodReturnValueHandler &#123; @Override public boolean supportsReturnType(MethodParameter returnType) &#123; return Callable.class.isAssignableFrom(returnType.getParameterType()); &#125; @Override public void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123; if (returnValue == null) &#123; mavContainer.setRequestHandled(true); return; &#125; Callable&lt;?&gt; callable = (Callable&lt;?&gt;) returnValue; WebAsyncUtils.getAsyncManager(webRequest).startCallableProcessing(callable, mavContainer); &#125;&#125; 这里直接调用了WebAsyncManager的startCallableProcessing方法进行处理，不过这是一个重载的第一个参数是Callable类型的startCallableProcessing方法，其代码如下:1234public void startCallableProcessing(Callable&lt;?&gt; callable, Object... processingContext) throws Exception &#123; Assert.notNull(callable, "Callable must not be null"); startCallableProcessing(new WebAsyncTask(callable), processingContext);&#125; 它还是将Callable封装成了WebAsyncTask然后处理的。如果WebAsyncTask中只有Callable而没有别的属性的时候可以直接返回Callable，比如前面的处理器可以修改为：1234567891011121314151617181920212223242526package com.excelib.controller;import javax.servlet.*;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;public class AsyncController &#123; @ResponseBody @RequestMapping(value = "/callable",produces = "text/plain; charset=UTF-8") public Callable&lt;String&gt; callable()&#123; System.out.println("Callable处理器主线程进入"); Callable&lt;String&gt; callable = new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; Thread.sleep(5 * 1000L); System.out.println("Callable处理执行中。。。"); return "久等了"; &#125; &#125;; System.out.println("Callable处理器主线程退出"); return callable; &#125;&#125; 它和前面使用WebAsyncTask执行的效果是一样的。 22.2.4 DeferredResult类型异步请求的处理过程及用法DeferredResult是spring提供的一种用于保存延迟处理结果的类，当一个处理器返回DeferredResult类型的返回值时将启动异步处理。 不过DeferredResult和WebAsyncTask的使用方法完全不同，DeferredResult并不是用于处理请求的，而且也不包含请求的处理过程，它是用来封装处理结果的，有点像Java中的Future，但不完全一样。 使用DeferredResult的难点就在理解其含义，对其含义理解了之后就会觉得非常简单，而且使用起来也很方便。在返回WebAsyncTask时是因为处理的时间过长所以使用了异步处理，但其实还是自己来处理的（因为WebAsyncTask需要提供Callable），而返回DeferredResult表示要将处理交个别人了，什么时候处理完、怎么处理的自己并不需要知道，这就好像在单位经常用到的“妥否，请批示”的请示报告，自己并不知道什么时候能批下来，而且也不需要知道具体批示过程，只需要知道最后的结果就可以了。DeferredResult就是来保存结果的，当处理完之后调用它的setResult方法将结果设置给它就可以了。 DeferredResult还提供了一些别的属性，如resultHandler可以在设置了结果之后对结果进行处理、timeout设置超时时间、timeoutCallback设置超时处理方法、completionCallback设置处理完成后酌处理方法、timeoutResult设置超时后返回的结果等。 下面看一下Spring MVC中处理DeferredResult返回值的DeferredResultMethodReturnValueHandler处理器，它的handleReturnValue方法如下：123456789101112131415161718192021public class DeferredResultMethodReturnValueHandler implements HandlerMethodReturnValueHandler &#123; @Override public boolean supportsReturnType(MethodParameter returnType) &#123; return DeferredResult.class.isAssignableFrom(returnType.getParameterType()); &#125; @Override public void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123; if (returnValue == null) &#123; mavContainer.setRequestHandled(true); return; &#125; DeferredResult&lt;?&gt; deferredResult = (DeferredResult&lt;?&gt;) returnValue; WebAsyncUtils.getAsyncManager(webRequest).startDeferredResultProcessing(deferredResult, mavContainer); &#125;&#125; 这里直接凋用了WebAsyncManager的startDeferredResultProcessing方法进行处理。 下面来看一个返回值为DeferredResult的处理器的例子。123456789101112131415161718192021222324252627282930313233package com.excelib.controller;import javax.servlet.*;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;@Controllerpublic class AsyncController &#123; @ResponseBody @RequestMapping(value = "/deferred",produces = "text/plain; charset=UTF-8") public DeferredResult&lt;String&gt; deferredResultExam() &#123; final DeferredResult&lt;String&gt; result = new DeferredResult&lt;String&gt;(7*1000L, "超时了"); approve(result); return result; &#125; private void approve(DeferredResult&lt;String&gt; result)&#123; Runnable r = new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(5 * 1000L); result.setResult("同意 "+new SimpleDateFormat("yyyy-MM-dd").format(new Date())); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;; new Thread(r).start(); &#125;&#125; 在处理器方法中直接新建了个DeferredResult类型的result代表处理结果，构造方法的两个参数分别表示超时时间和超时后返回的结果，建出来后将其交给approve方法进行处理（审批），当approve方法给result使用setResult方法设置了值后异步处理就完成了。 approve方法启动了一个新线程，然后在里面等待5秒后给result设置值。因为这里的处理器有@ResponseBody注释，所以返回值会直接显示到浏览器，当调用http://localhost:8080/deferred时，浏览器会在过大约5秒后显示同意2015-04-02。 现在大家再返回去看WebAsyncManager酌startDeferredResultProcessing方法就容易理解了，它并没有而且也不需要执行，只需要等待别的线程给设置返回值就可以了。方法中给result设置了处理返回值的处理器，当有返回值返回时会自动调用，代码如下：1234567deferredResult.setResultHandler(new DeferredResultHandler() &#123; @Override public void handleResult(Object result) &#123; result = interceptorChain.applyPostProcess(asyncWebRequest, deferredResult, result); setConcurrentResultAndDispatch(result); &#125;&#125;); 这里的处理器中首先调用了拦截器链中的applyPostProcess方法，然后调用setConcurrentResultAndDispatch万法处理了返回值，setConcurrentResultAndDispatch方法前面已经说过了。 现在大家应该对DeferredResult返回值的异步处理就理解了，DeferredResult是一个用于保存返回值的类，只需要在业务处理完成后调用其setResult方法设置结果就可以了，至于怎么处理的、在哪里处理的它并不关心，这也就给我们带来了很大的自由。 22.2.5 ListenableFuture类型异步请求的处理过程及用法ListenableFuture继承自Future，Future在前面已经介绍过了，它用来保存Callable的处理结果，它提供了get方法来获取返回值，不过Future并不会在处理完成后主动提示。ListenableFuture在Future基础上增加了可以添加处理成功和处理失败回调方法的方法，代码如下：1234567public interface ListenableFuture&lt;T&gt; extends Future&lt;T&gt; &#123; void addCallback(ListenableFutureCallback&lt;? super T&gt; callback); void addCallback(SuccessCallback&lt;? super T&gt; successCallback, FailureCallback failureCallback);&#125; ListenableFutureCallback继承自SuccessCallback和FailureCallback接口，后两个接口分别有一个onSuccess方法和onFailure方法，用于处理异步处理成功的返回值和异步处理失败的返回值，就和DeferredResult中的resultHandler差不多，它们定义如下：12345678910111213141516171819202122public interface ListenableFutureCallback&lt;T&gt; extends SuccessCallback&lt;T&gt;, FailureCallback &#123;&#125;public interface SuccessCallback&lt;T&gt; &#123; /** * Called when the &#123;@link ListenableFuture&#125; successfully completes. * @param result the result */ void onSuccess(T result);&#125;public interface FailureCallback &#123; /** * Called when the &#123;@link ListenableFuture&#125; fails to complete. * @param ex the exception that triggered the failure */ void onFailure(Throwable ex);&#125; ListenableFuture足spring4.0新增的接口，它主要使用在需要调用别的服务的时候，spring还同时提供了AsyncRestTemplate，用它可以方便地发起各种Http请求，不同类型的请求（如Get、Post等）都有不同的方法，而且还可以使用url的模板参数uriVariables（类似于处理器参数中的pathVariables】，它的返回值就是ListenableFuture类型，比如，可以这样使用12ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; futureEntity = template.getForEntity("http://localhost:8080/students/&#123;studentld&#125;/books/&#123;bookldl" , String.class, "176", "7"); 这样就可以返回http://localhost:808 0/students/1 7 6/books/7的Get请求结果，而且是非阻塞的异步调用。 下面看一下处理ListenableFuture返回值的处理器ListenableFutureReturnValueHandler，它的handleReturnValue方法代码如下：123456789101112131415161718192021222324@Overridepublic void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123; if (returnValue == null) &#123; mavContainer.setRequestHandled(true); return; &#125; final DeferredResult&lt;Object&gt; deferredResult = new DeferredResult&lt;Object&gt;(); WebAsyncUtils.getAsyncManager(webRequest).startDeferredResultProcessing(deferredResult, mavContainer); ListenableFuture&lt;?&gt; future = (ListenableFuture&lt;?&gt;) returnValue; future.addCallback(new ListenableFutureCallback&lt;Object&gt;() &#123; @Override public void onSuccess(Object result) &#123; deferredResult.setResult(result); &#125; @Override public void onFailure(Throwable ex) &#123; deferredResult.setErrorResult(ex); &#125; &#125;);&#125; 可以看到在ListenableFuture的返回值处理器里实际使用了DeferredResult．首先新建了DeferredResult类型的deferredResult，接着调用了WebAsyncManager的startDeferredResultProcessing方法进行处理，然后给ListenableFuture类型的返回值添加了回调方法，在回调方法中对deferredResult设置了返回值。可以说ListenableFuture类型的返回值只是DeferredResult类型返回值处理器的一种特殊使用方式。大家好好体会这里的处理过程就可以对DeferredResult跟具体处理过程无关这一点理解得更加深入。 下面来看一个ListenableFuture类型返回值处理器的例子。123456789101112131415161718package com.excelib.controller;import javax.servlet.*;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;@Controllerpublic class AsyncController &#123; @RequestMapping(value = "/listenable",produces = "text/plain; charset=UTF-8") public ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; listenableFuture() &#123; ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; future = new AsyncRestTemplate().getForEntity( "http://localhost:8080/index", String.class); return future; &#125;&#125; 这里处理器的返回值ListenableFuture的泛型是ResponseEntity类型，所以不需要使用@ResponseBody注释也会将返回值直接显示到浏览器。当调用http://localhost:8080/listenable时，浏览器会显示excelibGoGoGo!，也就是http://localhost:8080/index的返回结果.。 多知道点 ListenableFuture和Future的比较 ListenableFuture在Future的基础上增加了可以添加处理成功和处理失败回调方法的方法，这就从Future的“拉”模式变成了ListenableFuture的“推”模式。 Future只能调用get方法来主动拉数据，而且get方法还是阻塞的，而ListenableFuture可以等待处理完成后自己将结果推过来，而且不会阻塞线程，这么看好像ListenableFuture比Future更好用。其实在很多地方Future中阻塞的get方法才是真正需要的，因为很多时候都需要等到线程处理的结果才可以向下进行，比如，要找四个数中最大的那个，可以将四个数分成两组然后启动两个线程分别选出每组中比较大的数，然后再启动一个线程取出两个结果中比较大的，那就是四个数中最大的数，代码如下：12345678910111213141516171819202122232425262728293031public class ObtainBigger &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ExecutorService executor = Executors.newCachedThreadPool(); // 需要查找最大数的数组 Double data[] = new Double[]&#123;210.32, 517.96, 986.77, 325.13&#125;; // 获取前两个里较大的 BiggerCallable c1 = new BiggerCallable(data[0],data[1]); Future&lt;Double&gt; bigger1 = executor.submit(c1); // 获取后两个里较大的 BiggerCallable c2 = new BiggerCallable(data[2],data[3]); Future&lt;Double&gt; bigger2 = executor.submit(c2); // 获取两个结果中较大的，这时会阻塞，只有前面两个结果都返回时才会往下进行 BiggerCallable c = new BiggerCallable(bigger1.get(), bigger2.get()); Future&lt;Double&gt; bigger = executor.submit(c); // 输出结果 System.out.println(bigger.get()); executor.shutdown(); &#125; private static class BiggerCallable implements Callable &#123; Double d1, d2; public BiggerCallable(Double d1, Double d2)&#123; this.d1 = d1; this.d2 = d2; &#125; @Override public Object call() throws Exception &#123; return d1&gt;d2?d1:d2; &#125; &#125;&#125; 这里使用了内部类BiggerCallable来比较，第三个BiggerCallable创建时前两个cl）c2必须已经执行完才可以，否则就会出问题，所以在这种情况下阻塞就是必要的，而且这种需要线程返回结果后才能往下进行的情况很多。而ListenableFuture的典型用法就是Web异步请求这种并不需要对线程返回的结果进一步处理，而且线程在返回之前主线程可以继续往下走的情况，这时如果程序阻塞就起不到应有的作用了。 22.3小结本章系统地介绍了Servlet和SpringMVC中异步处理的原理和使用方法，首先介绍了Servlet3.0中对异步请求的支持及其使用方法，然后又分析了SpringMVC中异步处理的执行过程并编写了示例程序。 Servlet中使用异步请求非常方便，只需要调用request的startAsync方法，然后对其返回值AsyncContext进行处理，如果需要还可以为其添加AsyncListener监听器，它可以监听异步请求的启动、超时、处理完成和处理异常四个节点。 Spring MVC为异步请求提供了专门的工具，并对处理器默认提供了四种用于异步处理的返回值： 1. Callable、 2. WebAsyncTask、 3. DeferredResult 4. ListenableFuture。 对异步请求的支持主要在RequestMappingHandlerAdapter中，启动异步处理在各返回值对应的返回值处理器中。 原文链接：https://github.com/sixtrees/kantouspringmvc/blob/master/%E7%AC%AC22%E7%AB%A0%20%E5%BC%82%E6%AD%A5%E8%AF%B7%E6%B1%82.md]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[(译)JVM Concurrent Mark Sweep (CMS) Collector 1.8]]></title>
      <url>%2F2017%2F05%2F22%2F%E8%AF%91-JVM-Concurrent-Mark-Sweep-CMS-Collector-1-8%2F</url>
      <content type="text"><![CDATA[最近线上JDK升级到啦1.8，应用在发布时，总会发生Full GC报警，看了下GC日志，发现应用重启时会接连发生4次Full GC，但是这4次GC后很久一段时间（第二天再次查看GC日志和jstat的统计）没有再发生Full GC，查了下官方资料，顺便翻译出来，方便以后阅读。翻译的不好，请见谅，也欢迎提出建议，在下将不胜感激。 原文链接：https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html The Concurrent Mark Sweep (CMS) collector is designed for applications that prefer shorter garbage collection pauses and that can afford to share processor resources with the garbage collector while the application is running. Typically applications that have a relatively large set of long-lived data (a large tenured generation) and run on machines with two or more processors tend to benefit from the use of this collector. However, this collector should be considered for any application with a low pause time requirement. The CMS collector is enabled with the command-line option -XX:+UseConcMarkSweepGC. CMS收集器特点：1.更短的垃圾回收暂停(stop the world) 2.垃圾收集器能够在应用运行时与其共享处理器资源。通常，一个运行在多处理器机器上并且其中有长期存活的大集合(较大的老生代)的应用可以考虑使用CMS收集器。当然，对于具有低暂停时间要求的应用，都可以考虑使用该收集器。使用-XX:+UseConcMarkSweepGC来启用CMS收集器。 Similar to the other available collectors, the CMS collector is generational; thus both minor and major collections occur. The CMS collector attempts to reduce pause times due to major collections by using separate garbage collector threads to trace the reachable objects concurrently with the execution of the application threads. During each major collection cycle, the CMS collector pauses all the application threads for a brief period at the beginning of the collection and again toward the middle of the collection. The second pause tends to be the longer of the two pauses. Multiple threads are used to do the collection work during both pauses. The remainder of the collection (including most of the tracing of live objects and sweeping of unreachable objects is done with one or more garbage collector threads that run concurrently with the application. Minor collections can interleave with an ongoing major cycle, and are done in a manner similar to the parallel collector (in particular, the application threads are stopped during minor collections). 和其他收集器一样，CMS是分代的，因此，新生代和老年代都会发生回收。CMS尝试通过多线程并发的方式来跟踪对象的可达性，以便减少老生代的收集时间。在老年代垃圾回收期间，CMS会发生两次STW：1.收集开始首次标记时（initial-mark）2.重新标记时（remark）。第二次暂停的时间往往比第一次要长。这两次标记均使用多线程。其余的收集（包括大多存活对象跟踪和不可达对象的清除）使用一个或多个线程和应用并发执行。新生代的回收可以和正在执行老年年代回收交错执行，类似于并行收集器（在新生代回收期间应用程序线程被停止STW）。 Concurrent Mode FailureThe CMS collector uses one or more garbage collector threads that run simultaneously with the application threads with the goal of completing the collection of the tenured generation before it becomes full. As described previously, in normal operation, the CMS collector does most of its tracing and sweeping work with the application threads still running, so only brief pauses are seen by the application threads. However, if the CMS collector is unable to finish reclaiming the unreachable objects before the tenured generation fills up, or if an allocation cannot be satisfied with the available free space blocks in the tenured generation, then the application is paused and the collection is completed with all the application threads stopped. The inability to complete a collection concurrently is referred to as concurrent mode failure and indicates the need to adjust the CMS collector parameters. If a concurrent collection is interrupted by an explicit garbage collection (System.gc()) or for a garbage collection needed to provide information for diagnostic tools, then a concurrent mode interruption is reported. CMS使用一个或多个线程和应用线程并发进行，目标是在老生代被消耗完之前完成垃圾回收。如前所述，在正常操作中，CMS收集器执行大部分追踪和清理工作时，应用程序线程仍在运行，因此应用线程只会短暂暂停。但是，如果在垃圾回收完成前，老生代被耗尽，或者老生代无法分配足够的空间，此时会暂停所有的应用线程（导致了STW）直到垃圾回收完成。没有在并发期间完成垃圾回收工作称为concurrent mode failure，这个失败表明我们需要调整CMS收集器的参数。如果并发回收被显示调用(System.gc()) 或者为了给诊断工具提供信息而发生中断，则会报告并发模式中断。 Excessive GC Time and OutOfMemoryErrorExcessive GC Time and OutOfMemoryErrorThe CMS collector throws an OutOfMemoryError if too much time is being spent in garbage collection: if more than 98% of the total time is spent in garbage collection and less than 2% of the heap is recovered, then an OutOfMemoryError is thrown. This feature is designed to prevent applications from running for an extended period of time while making little or no progress because the heap is too small. If necessary, this feature can be disabled by adding the option -XX:-UseGCOverheadLimit to the command line. The policy is the same as that in the parallel collector, except that time spent performing concurrent collections is not counted toward the 98% time limit. In other words, only collections performed while the application is stopped count toward excessive GC time. Such collections are typically due to a concurrent mode failure or an explicit collection request (for example, a call to System.gc). 当GC时间太久（垃圾收集花费时间，超过了总时间的98%，但是回收的堆少于2%,总时间究竟是相对哪个时间而言？在下还未找到解释。），CMS会抛出OutOfMemoryError。这个特性旨在避免由于堆空间过小而导致应用程序业务处理缓慢或者无进展。这个特性可以用-XX:-UseGCOverheadLimit禁用。 这个策略和并行收集器一致，只是并发回收垃圾的时间不计入98%的时间消耗中。换句话讲，只有发生了STW情况下的收集时间（两次标记的时间）会计入这98%的时间限制内。这种长时间回收通常是由于concurrent mode failure或者回收请求（比如：显示调用System.gc）导致的。 Floating GarbageThe CMS collector, like all the other collectors in Java HotSpot VM, is a tracing collector that identifies at least all the reachable objects in the heap. In the parlance of Richard Jones and Rafael D. Lins in their publication Garbage Collection: Algorithms for Automated Dynamic Memory, it is an incremental update collector. Because application threads and the garbage collector thread run concurrently during a major collection, objects that are traced by the garbage collector thread may subsequently become unreachable by the time collection process ends. Such unreachable objects that have not yet been reclaimed are referred to as floating garbage. The amount of floating garbage depends on the duration of the concurrent collection cycle and on the frequency of reference updates, also known as mutations, by the application. Furthermore, because the young generation and the tenured generation are collected independently, each acts a source of roots to the other. As a rough guideline, try increasing the size of the tenured generation by 20% to account for the floating garbage. Floating garbage in the heap at the end of one concurrent collection cycle is collected during the next collection cycle. CMS和其他Java HotSpot VM中回收器一样，是一个会标记堆中所有可达对象的追踪回收器。在《Algorithms for Automated Dynamic Memory》中CMS被称作增量收集器。因为应用线程和垃圾回收线程在老年代回收时是并发运行的，所以，那些被垃圾回收线程追踪的对象在回收结束时可能会变得不可达。像这些尚未被回收并且不可达的引用被称为浮动垃圾。浮动垃圾的数量取决于并发收集周期的持续时间以及应用程序的引用更新频率（也称为突变）。此外，因为新生代和老年代的垃圾回收是相互独立的，所以，根据经验建议将老年代增加20%的空间来承载浮动垃圾。一个并发回收周期节后产生的浮动垃圾会在下个垃圾回收中回收。 PausesThe CMS collector pauses an application twice during a concurrent collection cycle. The first pause is to mark as live the objects directly reachable from the roots (for example, object references from application thread stacks and registers, static objects and so on) and from elsewhere in the heap (for example, the young generation). This first pause is referred to as the initial mark pause. The second pause comes at the end of the concurrent tracing phase and finds objects that were missed by the concurrent tracing due to updates by the application threads of references in an object after the CMS collector had finished tracing that object. This second pause is referred to as the remark pause. CMS在一次回收的过程中会两次暂停（STW）应用。第一次是标记从GC root（比如：被应用线程栈引用的对象和registers，静态的对象等等）可以直接到达的对象和来自堆的其他地方（比如：新生代）的对象。第一次暂停叫做初始标记暂停（initial mark pause）。第二次暂停发生在并发追踪阶段结束后，这次暂停是为了标记那些在并发追踪期间因为被应用线程更新引用而错过的对象。第二次暂停叫做重新标记暂停（remark pause）。 Concurrent PhasesThe concurrent tracing of the reachable object graph occurs between the initial mark pause and the remark pause. During this concurrent tracing phase one or more concurrent garbage collector threads may be using processor resources that would otherwise have been available to the application. As a result, compute-bound applications may see a commensurate fall in application throughput during this and other concurrent phases even though the application threads are not paused. After the remark pause, a concurrent sweeping phase collects the objects identified as unreachable. Once a collection cycle completes, the CMS collector waits, consuming almost no computational resources, until the start of the next major collection cycle. 并发追踪可达对象发生在初始标记（initial mark）和重新标记（remark）之间。在并发标记阶段会有一个或者多个垃圾回收线程在使用处理器资源，否则处理器资源对应用而言是可用的。因此，在垃圾回收期间计算密集型应用吞吐量会下降，即使应用线程没有被暂停。在重新标记阶段后，会并发清理那些被被标记为不可达的对象。垃圾回收完成后，CMS进入等待，几乎不消耗任何计算资源，直到下一个老年代回收开始。 Starting a Concurrent Collection CycleWith the serial collector a major collection occurs whenever the tenured generation becomes full and all application threads are stopped while the collection is done. In contrast, the start of a concurrent collection must be timed such that the collection can finish before the tenured generation becomes full; otherwise, the application would observe longer pauses due to concurrent mode failure. There are several ways to start a concurrent collection. Based on recent history, the CMS collector maintains estimates of the time remaining before the tenured generation will be exhausted and of the time needed for a concurrent collection cycle. Using these dynamic estimates, a concurrent collection cycle is started with the aim of completing the collection cycle before the tenured generation is exhausted. These estimates are padded for safety, because concurrent mode failure can be very costly. A concurrent collection also starts if the occupancy of the tenured generation exceeds an initiating occupancy (a percentage of the tenured generation). The default value for this initiating occupancy threshold is approximately 92%, but the value is subject to change from release to release. This value can be manually adjusted using the command-line option -XX:CMSInitiatingOccupancyFraction=, where is an integral percentage (0 to 100) of the tenured generation size. 老年代串行垃圾收集器在老年代即将耗尽时开始工作，此时所有应用线程都会暂停直到垃圾回收完成。与之相反，CMS从开始并发回收时进行计时，以使回收在老年代耗尽之前完成，否则会因为concurrent mode failure使得应用暂停更长时间。有几种方式可以开始一个并发回收。 基于最近的回收历史，CMS会维护两个预估时间：老年代多久会被耗尽；完成一次老年代的回收需要多久。依据这些动态估计值，在老年代耗尽前适时开始老年代的回收。这些预估值是为了避免耗时的concurrent mode failure。 如果老年代占用的空间超过了启动设置的大小（一个老生代的占用比）。默认的启动设置的阀值是92%，但是这个值会随着版本发布改变。这个值可以通过-XX:CMSInitiatingOccupancyFraction=配置，N是占用老生代大小的百分比（0-100）。 Scheduling PausesThe pauses for the young generation collection and the tenured generation collection occur independently. They do not overlap, but may occur in quick succession such that the pause from one collection, immediately followed by one from the other collection, can appear to be a single, longer pause. To avoid this, the CMS collector attempts to schedule the remark pause roughly midway between the previous and next young generation pauses. This scheduling is currently not done for the initial mark pause, which is usually much shorter than the remark pause. 老年代和新生代垃圾回收引起的暂停是独立的。它们不会重叠，但是可能会快速连续发生，比如：一个回收暂停结束后另一个回收又立刻导致暂停，看起来就像单独一个很长的暂停。为了避免这种情况，CMS尝试规划将remark暂停放在两次新生代回收（Young GC）之间。这个规划尚未在初始标记暂停（initial mark pause）使用，因为初始标记暂停（initial mark pause）通常比remark pause要短。 Incremental ModeNote that the incremental mode is being deprecated in Java SE 8 and may be removed in a future major release. 请注意，增量模式在Java SE 8中已被弃用，并可能在将来的主要版本中被删除，所以不在翻译和i-cms有关部分。 MeasurementsExample 8-1, “Output from the CMS Collector” is the output from the CMS collector with the options -verbose:gc and -XX:+PrintGCDetails, with a few minor details removed. Note that the output for the CMS collector is interspersed with the output from the minor collections; typically many minor collections occur during a concurrent collection cycle. CMS-initial-mark indicates the start of the concurrent collection cycle, CMS-concurrent-mark indicates the end of the concurrent marking phase, and CMS-concurrent-sweep marks the end of the concurrent sweeping phase. Not discussed previously is the precleaning phase indicated by CMS-concurrent-preclean. Precleaning represents work that can be done concurrently in preparation for the remark phase CMS-remark. The final phase is indicated by CMS-concurrent-reset and is in preparation for the next concurrent collection. Example 8-1 Output from the CMS Collector [GC [1 CMS-initial-mark: 13991K(20288K)] 14103K(22400K), 0.0023781 secs] [GC [DefNew: 2112K-&gt;64K(2112K), 0.0837052 secs] 16103K-&gt;15476K(22400K), 0.0838519 secs] ... [GC [DefNew: 2077K-&gt;63K(2112K), 0.0126205 secs] 17552K-&gt;15855K(22400K), 0.0127482 secs] [CMS-concurrent-mark: 0.267/0.374 secs] [GC [DefNew: 2111K-&gt;64K(2112K), 0.0190851 secs] 17903K-&gt;16154K(22400K), 0.0191903 secs] [CMS-concurrent-preclean: 0.044/0.064 secs] [GC [1 CMS-remark: 16090K(20288K)] 17242K(22400K), 0.0210460 secs] [GC [DefNew: 2112K-&gt;63K(2112K), 0.0716116 secs] 18177K-&gt;17382K(22400K), 0.0718204 secs] [GC [DefNew: 2111K-&gt;63K(2112K), 0.0830392 secs] 19363K-&gt;18757K(22400K), 0.0832943 secs] ... [GC [DefNew: 2111K-&gt;0K(2112K), 0.0035190 secs] 17527K-&gt;15479K(22400K), 0.0036052 secs] [CMS-concurrent-sweep: 0.291/0.662 secs] [GC [DefNew: 2048K-&gt;0K(2112K), 0.0013347 secs] 17527K-&gt;15479K(27912K), 0.0014231 secs] [CMS-concurrent-reset: 0.016/0.016 secs] [GC [DefNew: 2048K-&gt;1K(2112K), 0.0013936 secs] 17527K-&gt;15479K(27912K), 0.0014814 secs] The initial mark pause is typically short relative to the minor collection pause time. The concurrent phases (concurrent mark, concurrent preclean and concurrent sweep) normally last significantly longer than a minor collection pause, as indicated by Example 8-1, “Output from the CMS Collector”. Note, however, that the application is not paused during these concurrent phases. The remark pause is often comparable in length to a minor collection. The remark pause is affected by certain application characteristics (for example, a high rate of object modification can increase this pause) and the time since the last minor collection (for example, more objects in the young generation may increase this pause). 例子8-1是打开-verbose:gc和-XX:+PrintGCDetails选项后的gc打印日志，例子中略去了一些新生代的收集细节。注意，CMS收集器打印的日志和新生代回收打印的日志是穿插在一起的，通常在一个老年代回收周期中会发生多次新生代回收。CMS-initial-mark表明一个并发收集周期的开始，CMS-concurrent-mark表明并发标记阶段已经完成，CMS-concurrent-sweep说明并发清除阶段已经结束。CMS-concurrent-preclean是预清理阶段。预清理工作并发进行，是CMS-remark阶段的前置操作。CMS-concurrent-reset是老年代垃圾回收的最后一个阶段也是为下次回收做预备工作。 初始标记阶段耗时通常比年轻代暂停时间短。从例8-1我们不难发现，并发阶段（并发标记，并发预清理和并发清除）通常耗时比新生代回收时间长。但是，应用在这些阶段中并没有暂停。重新标记耗时与新生代回收耗时差不多。重新标记的耗时会受某些应用特性（比如：高对象修改率会增加此阶段耗时）和距离上次老年代收集时间（比如：新生代有了更多的对象会增加此阶段耗时）的影响。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK源码 Hash杂记]]></title>
      <url>%2F2017%2F05%2F11%2FJDK%E6%BA%90%E7%A0%81-hash%E6%9D%82%E8%AE%B0%2F</url>
      <content type="text"><![CDATA[最早了解Hash的用法，是一次分表的经历，公司用户表数据有几千万，查询的效率已经比较低了，需要做拆分处理，之前系统中已经有分表的数据，处理方式比较简单，没有使用中间件，按照商家的ID（32位字符串）做Hash然后取模，算出其落在表的编号，然后加上前缀得到最终表名。 最近在了解zk分布式锁时，为了避免一种实现方式的羊群效应，其改进思路类似一致性哈希算法。于是，便看了下Hash相关的知识，并用Java做了简单实现。 哈希简介哈希算法将任意长度的二进制值映射为较短的固定长度的二进制值，这个小的二进制值称为哈希值。哈希值是一段数据唯一且极其紧凑的数值表示形式。如果散列一段明文而且哪怕只更改该段落的一个字母，随后的哈希都将产生不同的值。要找到散列为同一个值的两个不同的输入，在计算上是不可能的，所以数据的哈希值可以检验数据的完整性。一般用于快速查找和加密算法。 简单的Hash应用类似开头我们的场景，我们根据Hash的特性用代码来模拟下。 123456789101112131415161718192021/** * 表，实际存储 * Created by childe on 2017/5/14. */public class Table &#123; private String name; Map&lt;String,Merchant&gt; merchantMap; Table(String name) &#123; this.name = name; merchantMap = new HashMap&lt;&gt;(); &#125; public void insert(Merchant merchant) &#123; merchantMap.put(merchant.getId(),merchant); &#125; public Merchant select(String id) &#123; return merchantMap.get(id); &#125;&#125; 12345678910111213141516171819/** * 商家 * Created by childe on 2017/5/14. */public class Merchant &#123; private String id; public Merchant(String id) &#123; this.id = id; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 表路由 * Created by childe on 2017/5/14. */public class TableRoute &#123; private static final int TABLE_SIZE_MAX = 512; private Table[] tables = new Table[TABLE_SIZE_MAX]; private int size = 0; public void insert(Merchant merchant) &#123; //以merchant的ID为key，其不能为空 if (merchant == null &amp;&amp; StringUtils.isEmpty(merchant.getId())) &#123; return; &#125; int index = merchant.getId().hashCode() % size; Table table = tables[index]; table.insert(merchant); &#125; public Merchant select(String id) &#123; if (StringUtils.isEmpty(id)) &#123; return null; &#125; int index = id.hashCode() % size; Table table = tables[index]; return table.select(id); &#125; public void addTable(Table table) &#123; if (table == null) &#123; return; &#125; tables[size++] = table; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Created by childe on 2017/5/14. */public class Main &#123; static int tableNum = 3; static int merchantNum = 100; public static void main(String[] args) &#123; //初始化表 TableRoute tableRoute = creatTableRoute(tableNum); //插入数据 for (int i = 0; i &lt; merchantNum; i++) &#123; Merchant merchant = new Merchant(String.valueOf(i)); tableRoute.insert(merchant); &#125; //有效数据统计 validCount(tableRoute); //增加一个表 tableRoute.addTable(new Table("merchant_100")); System.out.println("after add a table"); //有效数据统计 validCount(tableRoute); &#125; private static void validCount(TableRoute tableRoute) &#123; int validNum = 0; //获取数据 for (int i = 0; i &lt; merchantNum; i++) &#123; Merchant merchant = tableRoute.select(String.valueOf(i)); if (merchant != null) &#123; validNum++; &#125; &#125; System.out.println("vaild merchant : " + validNum + ", total merchant : " + merchantNum); &#125; public static TableRoute creatTableRoute(int tableNum) &#123; TableRoute tableRoute = new TableRoute(); for (int i = 0; i &lt; tableNum; i++) &#123; tableRoute.addTable(new Table("merchant_" + String.valueOf(i))); &#125; return tableRoute; &#125;&#125; 在上述代码中我们我们模拟了分表插入和查找的过程，最终输出如下：123vaild merchant : 100, total merchant : 100after add a tablevaild merchant : 24, total merchant : 100 在Main中两次统计了表中有效的数据个数，两次差别还是比较大的，为什么新加入一个表会导致这么多数据实效呢？很简单，因为我们是以分表的个数取模的，当表的数量增加后，当然会造成数据失效。还以开篇的分表为例，如果商家的数据再次很快的增长，那么商家的用户数据当然会更多（商家:用户=1:n），当某个分表记录再次到达千万级别，此时就又面临分表的可能，那么此时就面临数据迁移的问题，否则就会出现我们模拟的状况，从实验上来看，失效的比例还是很高的，迁移就会比较头疼。当然，牵扯到实际问题需要我们对业务的增长有个大概的预测，来计算初次分表的数量。但是大量数据的迁移还是难以避免。 一致性哈希上面我们看到一旦表的数量增加数据失效比例很高，就需要面临大量的数据迁移，这是难以忍受的。 在应用中还有其他一些类似的场景，比如：缓存（假设我们缓存按照上述方式存放）。本来是为了减轻后方服务的压力，如果缓存的机器挂掉了一台或者我们需要新增加一台，那么，后端服务将面临大量缓存失效而带来的压力，甚至造成雪崩。 一致性哈希很好的解决了这个问题，什么是一致性哈希呢？一致性哈希将整个哈希值空间组织成一个虚拟的圆环，所有待落到该环上的节点（包括存储节点）均需要按照同一套Hash算法得出落点位置。节点落入到闭环后，按照顺时针的方向存储到离自己最近的一个存储节点。因为存储节点可能比较少，可能会导致存储节点存储数据不均衡，所以需要引入虚拟存储节点。比如：有A、B两台机器提供存储，我们一般使用机器的IP来计算机器的Hash，如果A、B两台机器的hash值比较靠近，数据存储就会出现倾斜，要尽可能保证数据的均匀分布，我们可以再做一层映射，在闭环上放置4个（A#0、A#1、B#0、B#1）或者更多存储节点（使得数据分布约趋于均匀）。 我们简单模拟下一致性哈希的实现：1234567891011121314151617181920212223242526/** * 模拟缓存机器 * Created by childe on 2017/5/14. */public class Server &#123; private String name; private Map&lt;String, Entry&gt; entries; Server(String name) &#123; this.name = name; entries = new HashMap&lt;&gt;(); &#125; public void put(Entry e) &#123; entries.put(e.getKey(), e); &#125; public Entry get(String key) &#123; return entries.get(key); &#125; public int hashCode() &#123; return name.hashCode(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 缓存集群 * Created by childe on 2017/5/14. */public class Cluster &#123; private static final int SERVER_SIZE_MAX = 1024; private SortedMap&lt;Integer, Server&gt; servers = new TreeMap&lt;&gt;(); private int size = 0; public void put(Entry e) &#123; routeServer(e.getKey().hashCode()).put(e); &#125; public Entry get(String key) &#123; return routeServer(key.hashCode()).get(key); &#125; private Server routeServer(int hash) &#123; if (servers.isEmpty())&#123; return null; &#125; /** * 顺时针找到离该hash最近的slot（server） */ if (!servers.containsKey(hash)) &#123; SortedMap&lt;Integer, Server&gt; tailMap = servers.tailMap(hash); hash = tailMap.isEmpty() ? servers.firstKey() : tailMap.firstKey(); &#125; return servers.get(hash); &#125; public boolean addServer(Server s) &#123; if (size &gt;= SERVER_SIZE_MAX) &#123; return false; &#125; servers.put(s.hashCode(), s); size++; return true; &#125;&#125; 12345678910111213141516171819/** * 缓存实体 * Created by childe on 2017/5/14. */public class Entry &#123; private String key; Entry(String key) &#123; this.key = key; &#125; public String getKey() &#123; return key; &#125; public void setKey(String key) &#123; this.key = key; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Created by childe on 2017/5/5. */public class Main &#123; static int entryNum = 100; public static void main(String[] args) &#123; //创建缓存集群 Cluster cluster = createCluster(); //写入缓存实体 for (int i = 0; i &lt; entryNum; i++) &#123; cluster.put(new Entry(String.valueOf(i))); &#125; //有效数据统计 validCount(cluster); //新增缓存节点 cluster.addServer(new Server("C")); System.out.println("afer add a server"); //有效数据统计 validCount(cluster); &#125; private static Cluster createCluster() &#123; Cluster c = new Cluster(); c.addServer(new Server("A#1")); c.addServer(new Server("A#2")); c.addServer(new Server("B#1")); c.addServer(new Server("B#2")); return c; &#125; private static void validCount(Cluster cluster) &#123; int validNum = 0; for (int i = 0; i &lt; entryNum; i++) &#123; Entry entry = cluster.get(String.valueOf(i)); if (entry != null) &#123; validNum++; &#125; &#125; System.out.println("valid entry : " + validNum + ", total entry : " + entryNum); &#125;&#125; 1234//输出如下valid entry : 100, total entry : 100afer add a servervalid entry : 90, total entry : 100 从输出结果我们看到失效率明显降低。据了解，Memcahce中便采用了一致性哈希的算法。 HashMapJDK中我们常用的HashMap也是基于哈希实现，JDK1.8以前采用数组和链表来组织数据，1.8中引入了红黑树对链表部分进行了优化。为什么HashMap要采用链表和红黑树呢？因为我们得到某个key的HashCode需要落到具体的桶中，而桶的数量是有限并且固定的，所以难免遇到不同的key却落到相同的桶中，于是就需要链表将这些数据链接起来，这也就是为什么当碰撞比较严重时，HashMap查询变慢的原因，在JDK1.8在处理冲突时采用链表加红黑树，当链表长度大于8时，就将链表转换为红黑树，从而达到加速查找的目的。 JDK1.8中还对HashMap的扩容做了优化，在1.8以前扩容时，需要重新计算每个key的HashCode然后入桶，所以扩容是一个耗时的操作，在1.8中避免了重新计算Hash，加快了扩容操作。 不管是JDK1.7还是1.8我们使用HashMap时最好对需要的容量进行评估，尽量避免扩容操作。JDK1.8对HashMap的优化，想深入了解的可参考美团点评团队的这篇博客 参考：http://wiki.mbalib.com/wiki/%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95http://www.berlinix.com/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK源码 Java Reference]]></title>
      <url>%2F2017%2F04%2F24%2FJDK%E6%BA%90%E7%A0%81-java%E7%9A%84%E5%9B%9B%E7%A7%8DReference%2F</url>
      <content type="text"><![CDATA[之前探讨过一次JAVA的FinalReference，这次我们来看下java.lang.ref包下对应的其他三种引用。 走近引用Reference和ReferenceQueue在使用中一定是结伴出现的，当一个Reference确定要被GC回收，GC便会把Reference加入到与之关联的ReferenceQueue中。注意：在Reference的构造方法中，我们可以传入一个注册队列ReferenceQueue，这个队列我们稍后会具体看，需要主要的是，这个队列需要单独的线程去做消费，否则会存在OOM的隐患。 这些引用可用来实现不同的缓存类型（内存敏感和内存不敏感），大名鼎鼎的Guava cache就是基于引用的这些特性来实现高速本地缓存。 StrongReference（强引用）我们平时开发中new一个对象出来，这种引用便是强引用。 JVM 系统采用 Finalizer 来管理每个强引用对象 , 并将其被标记要清理时加入 ReferenceQueue, 并逐一调用该对象的 finalize() 方法。具体详见我的前一篇博客：JDK源码 FinalReference SoftReference（软引用）当内存足够的时候，软引用所指向的对象没有其他强引用指向的话，GC的时候并不会被回收，当且只当内存不够时才会被GC回收（调用finalize方法）。强度仅次于强引用。GC回收前，会将那些已经向引用队列注册的新清除的软引用加入队列。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class ClassSoft &#123; public static class Referred &#123; /** * 不是必须实现，和Strong不同。 * 实现该方法是为了追踪GC， * 实现后也会被当作Finalizer * @throws Throwable */ @Override protected void finalize() throws Throwable &#123; System.out.println("Referred对象被垃圾收集"); &#125; @Override public String toString() &#123; return "I am Referred"; &#125; &#125; public static void collect() throws InterruptedException &#123; System.gc(); Thread.sleep(2000); &#125; static class CheckRefQueueThread extends Thread&#123; @Override public void run() &#123; Reference&lt;Referred&gt; obj = null; try &#123; obj = (Reference&lt;Referred&gt;)softQueue.remove(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if(obj != null) &#123; try &#123; Field referent = Reference.class.getDeclaredField("referent"); referent.setAccessible(true); Object result = referent.get(obj); //此处异常可以说明，在被放入队列之前referent已经被JVM置为null System.out.println("gc will collect: " + result.getClass() + "@" + result.hashCode()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println("Object for SoftReference is " + obj.get()); &#125; &#125; &#125; //如果我们使用了自定义的注册队列，一定要启动一个线程来处理该队列 //JVM只负责像队列中放入对象，不负责清理 static ReferenceQueue&lt;Referred&gt; softQueue = new ReferenceQueue&lt;&gt;(); /** * JVM配置 * -Xms4m -Xmx4m * -XX:+PrintGCDetails -Xloggc:/Users/childe/logs/gc-f.log * 务必加上该参数，以确定collect方法后GC被执行 * @param args * @throws InterruptedException */ public static void main(String[] args) throws InterruptedException &#123; System.out.println("创建软引用"); Referred strong = new Referred(); SoftReference&lt;Referred&gt; soft = new SoftReference&lt;&gt;(strong,softQueue); new CheckRefQueueThread().start(); ClassSoft.collect(); System.out.println("切断强引用"); strong = null; ClassSoft.collect(); System.out.println("GC之前，软引用值：" + soft.get().toString()); System.out.println("开始堆占用"); try &#123; List&lt;byte[]&gt; bytes = new ArrayList&lt;&gt;(); while (true) &#123; bytes.add(new byte[1024*1024]); ClassSoft.collect(); &#125; &#125; catch (OutOfMemoryError e) &#123; // 软引用对象应该在这个之前被收集 System.out.println("内存溢出..."); &#125; System.out.println("Done"); &#125;&#125; 程序输出如下：12345678910创建软引用切断强引用GC之前，软引用值：I am Referred开始堆占用java.lang.NullPointerExceptionReferred对象被垃圾收集 at com.cxd.jvm.references.ref.ClassSoft$CheckRefQueueThread.run(ClassSoft.java:54)Object for SoftReference is null内存溢出...Done 我们可以看到，软引用在GC回收前，调用get方法是可以返回其关联的实际对象的，当其被GC加入ReferenceQueue前，JVM会将其关联的对象置为null。 WeakReference（弱引用）弱引用指向的对象没有任何强引用指向的话，GC的时候会进行回收。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * * Created by childe on 2017/3/31. */public class ClassWeak &#123; public static class Referred &#123; /** * 不是必须实现，和Strong不同。 * 实现该方法是为了追踪GC * 实现后也会被当作Finalizer * @throws Throwable */ @Override protected void finalize() throws Throwable &#123; System.out.println("Referred对象被垃圾收集"); &#125; @Override public String toString() &#123; return "I am weak"; &#125; &#125; public static void collect() throws InterruptedException &#123; System.gc(); Thread.sleep(2000); &#125; /** * JVM配置 * -XX:+PrintGCDetails -Xloggc:/Users/childe/logs/gc-f.log * 务必加上该参数，以确定collect方法后GC被执行 * @param args * @throws InterruptedException */ public static void main(String[] args) throws InterruptedException &#123; System.out.println("创建一个弱引用"); Referred strong = new Referred(); WeakReference&lt;Referred&gt; weak = new WeakReference&lt;&gt;(strong); ClassWeak.collect(); System.out.println("切断强引用"); strong = null; System.out.println("GC之前，弱引用值：" + weak.get().toString()); ClassWeak.collect(); System.out.println("Done"); &#125;&#125; 程序输出如下：12345创建一个弱引用切断强引用GC之前，弱引用值：I am weakReferred对象被垃圾收集Done PhantomReference（虚引用）如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。这个特性，决定了他的get方法每次调用均会返回null。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * Created by childe on 2017/3/31. */public class ClassPhantom &#123; public static class Referred &#123; @Override protected void finalize() throws Throwable &#123; System.out.println("Referred对象被垃圾收集"); &#125; @Override public String toString() &#123; return "Referredqq"; &#125; &#125; public static void collect() throws InterruptedException &#123; System.gc(); Thread.sleep(2000); &#125; static class CheckRefQueueThread extends Thread&#123; @Override public void run() &#123; Reference&lt;Referred&gt; obj = null; try &#123; obj = (Reference&lt;Referred&gt;) phantomQueue.remove(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if(obj != null) &#123; //因为虚引用的指示对象总是不可到达的，所以此方法总是返回 null System.out.println("Object for phantomReference is " + obj.get()); try &#123; Field referent = Reference.class.getDeclaredField("referent"); referent.setAccessible(true); Object result = referent.get(obj); System.out.println("gc will collect: " + result.getClass() + "@" + result.toString()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;; &#125; static ReferenceQueue&lt;Referred&gt; phantomQueue = new ReferenceQueue&lt;&gt;(); /** * -Xms4m -Xmx4m * @param args * @throws InterruptedException */ public static void main(String[] args) throws InterruptedException &#123; System.out.println("创建一个软引用"); Referred strong = new Referred(); PhantomReference&lt;Referred&gt; soft = new PhantomReference&lt;&gt;(strong, phantomQueue); new CheckRefQueueThread().start(); collect(); System.out.println("切断强引用"); strong = null; collect(); System.out.println("开始堆占用"); try &#123; List&lt;byte[]&gt; bytes = new ArrayList&lt;&gt;(); while (true) &#123; bytes.add(new byte[1024*1024]); collect(); &#125; &#125; catch (OutOfMemoryError e) &#123; // 软引用对象应该在这个之前被收集 System.out.println("内存溢出..."); &#125; System.out.println("Done"); &#125;&#125; 输出如下：12345678创建一个软引用切断强引用Referred对象被垃圾收集开始堆占用Object for phantomReference is nullgc will collect: class com.cxd.jvm.references.ref.ClassPhantom$Referred@Referredqq内存溢出...Done 引用间的差别我们注意到虚引用在被加入到ReferenceQueue中后，关联对象并没有被置为null，这点和弱引用及软引用不同。这也是我开头说的潜在OOM的最大风险。当然，这种现象只是加速了OOM问题的暴露，并不是根本原因。JVM GC的这个模型可以看作是生产-消费模型，GC是生产者，我们自己起的线程是消费者（Finalizer中JDK自带线程），当只有生产者时，OOM是迟早的事情。 ReferenceQueue我们介绍的这四种引用都从java.lang.ref.Reference继承，Reference是个单向链表，ReferenceQueue利用Reference的这个特性来维护先进后出单向队列（类似栈）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public abstract class Reference&lt;T&gt; &#123; //...... //引用有4中概念上的状态：Active、Pending、 Enqueued 、Inactive //引用的初始态为Active或者Pending，它的生命后期为：（Active || Pending）-&gt; Enqueued -&gt; Inactive private T referent; /* Treated specially by GC 由GC专门处理*/ ReferenceQueue&lt;? super T&gt; queue; /* Reference 关联的引用队列 */ Reference next; /* 指向下一个引用 */ //......&#125;public class ReferenceQueue&lt;T&gt; &#123; //...... //如果我们构造Reference时，未传入自定义队列，默认使用此队列。 private static class Null extends ReferenceQueue &#123; //入队操作直接返回 boolean enqueue(Reference r) &#123; return false; &#125; &#125; static ReferenceQueue NULL = new Null(); static ReferenceQueue ENQUEUED = new Null(); boolean enqueue(Reference&lt;? extends T&gt; r) &#123; /* Called only by Reference class 只会对Reference类调用该方法 */ synchronized (r) &#123; //以入队的引用不多次入队 if (r.queue == ENQUEUED) return false; synchronized (lock) &#123; //修改引用入队状态为Enqueued r.queue = ENQUEUED; //插入对头 r.next = (head == null) ? r : head; head = r; queueLength++; if (r instanceof FinalReference) &#123; sun.misc.VM.addFinalRefCount(1); &#125; //通知等待在锁上的线程ReferenceQueue.remove() lock.notifyAll(); return true; &#125; &#125; &#125; private Reference&lt;? extends T&gt; reallyPoll() &#123; /* Must hold lock 必须在持有lock锁的情况下执行，lock由其外层方法获取 */ if (head != null) &#123; //获取队头 Reference&lt;? extends T&gt; r = head; head = (r.next == r) ? null : r.next; //将关联的队列置为NULL，此时r的状态为Inactive，处于此状态的引用不会再发生变化，等待被回收。 r.queue = NULL; r.next = r; queueLength--; if (r instanceof FinalReference) &#123; sun.misc.VM.addFinalRefCount(-1); &#125; return r; &#125; return null; &#125; //......&#125; 扩展WeakHashMapJDK中有对引用的具体使用，当我们需要实现一个简单的本地内存敏感缓存时，可以考虑使用WeakHashMap，此处不再分析其源码。WeakHashMap的每个Entry都是WeakReference的子类，每次put或者get或者resize扩容时，都会调用WeakHashMap的expungeStaleEntries方法，清除那些被GC加入到ReferenceQueue的Entry。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK源码 FinalReference]]></title>
      <url>%2F2017%2F04%2F01%2FJDK%E6%BA%90%E7%A0%81-FinalReference%2F</url>
      <content type="text"><![CDATA[JAVA FinalReference引入使用MAT分析dump出的内存时，常会看到java.lang.ref.Finalizer占用内存也不小，比较纳闷我们在编程中并没有用到这个东西，为什么他会出现并且占用分量不算小的一部分内存呢？1234final class Finalizer extends FinalReference &#123; private static ReferenceQueue queue = new ReferenceQueue(); //... ...&#125; 结合它的数据结构基本可以看出来，Finalizer中持有一个一个引用队列。猜测是这个队列吃掉了那些内存。 引用类型Java开发不必关心内存的释放、申请和垃圾回收，这些事情都有JVM代劳，但是JVM依然提供了一些方式，让我们能够在应用的层次利用内存或者GC特性，从而更好的使用内存。Reference(引用)就是其中一种。 StrongReference（强引用）我们平时开发中new一个对象出来，这种引用便是强引用。 JVM 系统采用 Finalizer 来管理每个强引用对象 , 并将其被标记要清理时加入 ReferenceQueue, 并逐一调用该对象的 finalize() 方法。 SoftReference（软引用）当内存足够的时候，软引用所指向的对象没有其他强引用指向的话，GC的时候并不会被回收，当且只当内存不够时才会被GC回收（调用finalize方法）。强度仅次于强引用。 WeakReference（弱引用）弱引用指向的对象没有任何强引用指向的话，GC的时候会进行回收。 PhantomReference（虚引用）如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 TODO引用详细介绍单独在另一篇作介绍 java.lang.ref包简介 ref包下对应了Java中对应几种引用类型，改包下的类的可见性均为包内可见。FinalReference可以看作是强引用的一个对应。 FinalReferenceFinalReference由JVM来实例化，VM会对那些实现了Object中finalize()方法的类实例化一个对应的FinalReference。注意：实现的finalize方法体必须非空。 FinalizerFinalizer是FinalReference的子类，该类被final修饰，不可再被继承，JVM实际操作的是Finalizer。当一个类满足实例化FinalReference的条件时，JVM会调用Finalizer.register()进行注册。(PS：后续讲的Finalizer其实也是在说FinalReference。) 何时注册（实例化FinalReference）JVM在类加载的时候会遍历当前类的所有方法，包括父类的方法，只要有一个参数为空且返回void的非空finalize方法就认为这个类在创建对象的时候需要进行注册。 对象的创建其实是被拆分成多个步骤，注册的时机可以在为对象分配好内存空间后，也可以在构造函数返回之前，这个点由-XX:-RegisterFinalizersAtInit控制，这个参数默认为true，即：在构造函数返回之前调用。注册入口是Finalizer的register()方法。 12345678910111213141516171819202122232425262728293031323334353637final class Finalizer extends FinalReference &#123; private static ReferenceQueue queue = new ReferenceQueue(); private static Finalizer unfinalized = null; private static final Object lock = new Object(); private Finalizer next = null, prev = null; //构造一个对象链表，如图 /** * +------+ prev +-----+ +-----+ *unfinalized | f3 | &lt;----&gt; | f2 | &lt;----&gt; | f1 | * +------+ next +-----+ +-----+ **/ private void add() &#123; synchronized (lock) &#123; if (unfinalized != null) &#123; this.next = unfinalized; unfinalized.prev = this; &#125; unfinalized = this; &#125; &#125; private Finalizer(Object finalizee) &#123; super(finalizee, queue); add(); &#125; /* Invoked by VM 入口在这里 */ static void register(Object finalizee) &#123; new Finalizer(finalizee); &#125; //... &#125; 何时进入ReferenceQueueGC工作时，如果发现对象只被Finalizer类引用，说明他可以被回收了，那么就把该对象从对象链中取出，放入ReferenceQueue，并通知FinalizerThread去消费。也就是说，本次GC并不能回收掉这个对象占用的内存。 ReferenceQueue是个典型的生产消费队列，此处不在赘述，可看其源码，实现很简单。 FinalizerThread线程在Finalizer类的clinit方法（静态块）里，会创建一个FinalizerThread守护线程，这个线程的优先级不是最高的，这就意味着在CPU很紧张的情况下其被调度的优先级可能会受到影响。 FinalizerThread业务很简单，从ReferenceQueue拿出Finalizer，执行finalize方法，并且忽略其抛出的所有异常。执行完毕后，该对象称为真正的垃圾对象，再次发生GC，他的一生也就结束了。 12345678910111213141516171819202122232425262728293031private static class FinalizerThread extends Thread &#123; private volatile boolean running; FinalizerThread(ThreadGroup g) &#123; super(g, "Finalizer"); &#125; public void run() &#123; if (running) return; //... running = true; for (;;) &#123; try &#123; Finalizer f = (Finalizer)queue.remove(); f.runFinalizer(jla); &#125; catch (InterruptedException x) &#123; // ignore and continue &#125; &#125; &#125; &#125; static &#123; ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); Thread finalizer = new FinalizerThread(tg); finalizer.setPriority(Thread.MAX_PRIORITY - 2); finalizer.setDaemon(true); finalizer.start(); &#125; GC回收问题 对象因为Finalizer的引用而变成了一个临时的强引用，即使没有其他的强引用，还是无法立即被回收； 对象至少经历两次GC才能被回收，因为只有在FinalizerThread执行完了f对象的finalize方法的情况下才有可能被下次GC回收，而有可能期间已经经历过多次GC了，但是一直还没执行对象的finalize方法； CPU资源比较稀缺的情况下FinalizerThread线程有可能因为优先级比较低而延迟执行对象的finalize方法； 因为对象的finalize方法迟迟没有执行，有可能会导致大部分f对象进入到old分代，此时容易引发old分代的GC，甚至Full GC，GC暂停时间明显变长，甚至导致OOM； 对象的finalize方法被调用后，这个对象其实还并没有被回收，虽然可能在不久的将来会被回收。 举个例子12345678910111213141516171819202122232425262728/** * -Xms4m -Xmx4m -XX:+PrintGCDetails -Xloggc:/Users/childe/logs/gc-f.log * -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/Users/childe/logs/oom-f.hprof * Created by childe on 2017/3/31. */public class Finalizable &#123; static AtomicInteger aliveCount = new AtomicInteger(0); Finalizable() &#123; //如果注释掉改行，在GC日志中仅能看到简单的新生代GC，程序不会因为内存问题停止 //如果未注释，程序跑上几分钟就挂掉了，因为生产和消费的能力不对等。GC日志中大部分是Full GC。 aliveCount.incrementAndGet(); &#125; @Override protected void finalize() throws Throwable &#123; Finalizable.aliveCount.decrementAndGet(); &#125; public static void main(String args[]) &#123; for (int i = 0;; i++) &#123; Finalizable f = new Finalizable(); if ((i % 100_000) == 0) &#123; System.out.format("After creating %d objects, %d are still alive.%n", new Object[] &#123;i, Finalizable.aliveCount.get() &#125;); &#125; &#125; &#125;&#125; finalizer的生存周期转自http://blog.2baxb.me/archives/974 在创建对象时，如果对象override了finalize()方法，jvm会同时创建一个Finalizer对象 所有Finalizer对象组成了一个双向链表 所有Finalizer对象都有一个名为queue的成员变量，指向的都是Finalizer类的静态Queue。 cms gc执行到mark阶段的最后时，会把需要gc的对象加入到Reference的pending list中。 有一个专门的高级别线程Reference Handler处理pending list，把pending list中的对象取出来，放到这个对象所指的Reference Queue中，对于Finalizer对象来说，这个queue指向Finalizer类的静态Queue。 Finalizer类有一个专门的线程负责从queue中取对象，并且执行finalizer引用的对象的finalize函数。 Java引用类型可参见http://benjaminwhx.com/2016/09/10/%E8%AF%A6%E8%A7%A3java-lang-ref%E5%8C%85%E4%B8%AD%E7%9A%844%E7%A7%8D%E5%BC%95%E7%94%A8/https://www.ibm.com/developerworks/cn/java/j-lo-langref/http://www.importnew.com/20468.htmlhttp://www.infoq.com/cn/articles/cf-java-garbage-references]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MAT(Memory Analyzer Tool)基本使用]]></title>
      <url>%2F2017%2F03%2F24%2FMAT-Memory-Analyzer-Tool-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[MAT Memory Analyzer Tool 基本使用简介分析和理解我们应用中内存的分布是一件极具挑战的事情。一个逻辑错误就有可能导致OutOfMemory。dump内存的方式很单：jmap -dump:format=b,file=path pid注意操作时要有正确的用户权限。本篇旨在介绍分析中涉及到的一些概念和操作方法，实际案例分析放在下篇介绍。 内存泄漏指由于疏忽或错误造成程序未能释放已经不再使用的内存。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，导致在释放该段内存之前就失去了对该段内存的控制，从而造成了内存的浪费。 Histogram 当我们用MAT工具(用的eclipse插件)打开dump文件，MAT首先给我们一个应用占用内存的预览。 中间的饼图像我们直观展示了retained size最大的对象。这意味着如果可以处理好com.cxd.jvm.mat.Controller$1 @ 0x7ffa741c8 allocator1 这个对象，我们可以腾出6.6M的内存，它占用了应用总内存的90%以上。进一步查看这个对象的一些信息我们可以使用Histogram。 这个Histogram被实例化类的名字，数量，占用的内存，默认按照内存占用降序。像char[]，String，Object[]这些看不出来有什么问题，为了更好的组织Histogram，我们可以按照包或者classLoader分组查看。 直方图还可以使用正则表达式过滤，例如我们只关心自己包下的类：.*com.cxd.jvm.* 过滤后，清楚的看到有超过15W的Listener实例存活在应用中。同时我们看到了每个对象对内存的使用情况。有两个维度的计算，Shallow Heap 和 Retained Heap。Shallow Heap是一个对象持有引用占用的内存，并不包含其引用对象所占用的内存，可以理解成对象本身的大小，Shallow Heap对实际分析没有多大用处。常规对象（非数组）的Shallow Size由其成员变量的数量和类型决定。数组的Shallow Size由数组元素的类型（对象类型、基本类型）和数组长度决定。 1234567//"Shallow size" of this obj == 24 Bytespublic final class String &#123;//8 Bytes header private char value[]; //4 Bytes private int offset; //4 Bytes private int count; //4 Bytes private int hash = 0; //4 Bytes&#125; Retained HeapRetained Heap是一个对象被GC回收时，能够释放其所有引用的Shallow Heap的总和。比如：一个ArrayList持有100,000个元素并且所有元素仅被这个ArrayList持有，每个元素16bytes，那么当该ArrayList被GC后将会释放16 x 100,000 + X，X是ArrayList的Shallow Heap。Retained Heap是Retained Set中所有对象大小的总和，一个对象的Retained Set是当该对象被GC后所要释放对象的集合。 Retained Heap有两种计算方式，一种是quick approximation（快速近似），一种是precise retained size（精确计算）。 通过精确计算可以看到各个Allocator占用了太多的内存，虽然它的Shallow Heap只有64bytes。那么我们只要管控好Controller，内存也就得到了控制。 Dominator TreeDominator Tree由对象的引用图转换而来，它可以让我们清楚的看出大块内存消耗和对象间的依赖保活关系。在对象图中，如果从某个节点（或者根节点）开始到达Y的路径都要经过X，那么X Dominator Y。另外，如果X是路径最短的Dominator，那么X Immediate Dominator Y。 通过Dominator来分析我们的项目。 我们可以明确的看到Allocator便是罪魁祸首，它下面的ArrayList持有大量Listener。 The objects belonging to the sub-tree of x (i.e. the objects dominated by x ) represent the retained set of x .If x is the immediate dominator of y , then the immediate dominator of x also dominates y , and so on.The edges in the dominator tree do not directly correspond to object references from the object graph.注意： 一个对象是X的子树（即：X Dominator 这个对象），那么，这个对象在X的retained set中； 如果X（Allocator） immediate dominator Y（Listener），那么，X的dominator（Controller）也dominator Y。换句话说，dominator具有向上传递性。 The edges in the dominator tree do not directly correspond to object references from the object graph.（dominator tree中的边不直接对应于对象图中的对象引用） Path to GC RootsDominator Tree对我们分析有帮助，但是它是向上找的一个过程，我们并不能知道Dominator的Dominator。Path to GC Roots这时候对我们会很有帮助。实操中需要结合使用。我们看下例子中Listener的GC Root： 通常在排查内存泄漏的时候，我们会选择exclude all phantom/weak/soft etc.references，意思是：查看排除虚引用/弱引用/软引用等的引用链。因为这些引用的对象可以直接被GC给回收，我们要看的就是某个对象否还存在Strong引用链（在导出HeapDump之前要手动出发GC来保证），如果有，则说明可能存在内存泄漏，然后再去排查具体引用。 查看的时候要和左边框中的一些信息结合起来，他提供了更加详细的介绍。 GC Root 定义如下（官网摘录）：A garbage collection root is an object that is accessible from outside the heap. The following reasons make an object a GC root: System ClassClass loaded by bootstrap/system class loader. For example, everything from the rt.jar like java.util.* . JNI LocalLocal variable in native code, such as user defined JNI code or JVM internal code. JNI GlobalGlobal variable in native code, such as user defined JNI code or JVM internal code. Thread BlockObject referred to from a currently active thread block. ThreadA started, but not stopped, thread. Busy MonitorEverything that has called wait() or notify() or that is synchronized. For example, by calling synchronized(Object) or by entering a synchronized method. Static method means class, non-static method means object. Java LocalLocal variable. For example, input parameters or locally created objects of methods that are still in the stack of a thread. Native StackIn or out parameters in native code, such as user defined JNI code or JVM internal code. This is often the case as many methods have native parts and the objects handled as method parameters become GC roots. For example, parameters used for file/network I/O methods or reflection. FinalizableAn object which is in a queue awaiting its finalizer to be run. UnfinalizedAn object which has a finalize method, but has not been finalized and is not yet on the finalizer queue. UnreachableAn object which is unreachable from any other root, but has been marked as a root by MAT to retain objects which otherwise would not be included in the analysis. Java Stack FrameA Java stack frame, holding local variables. Only generated when the dump is parsed with the preference set to treat Java stack frames as objects. UnknownAn object of unknown root type. Some dumps, such as IBM Portable Heap Dump files, do not have root information. For these dumps the MAT parser marks objects which are have no inbound references or are unreachable from any other root as roots of this type. This ensures that MAT retains all the objects in the dump. List ObjectList objects with （以Dominator Tree的方式查看）incoming references 引用到该对象的对象outcoming references 被该对象引用的对象 Show objects by class （以class的方式查看）incoming references 引用到该对象的对象outcoming references 被该对象引用的对象 Common Memory Anti-PatternsMAT使用Anti-Patterns给我们提供报告。这些报告对我们排查内存泄漏、优化low hanging fruit非常有帮助。 Heap Dump Overview给我们提供了系统属性、内存消耗排行等信息 Leak Suspects分析出可能存在的内存泄漏，供我们参考，通常这个功能可以帮我们直接找到问题所在 Java Collections我们可以通过Java Collections查看Map Collision Ratio(Map碰撞比率=碰撞的实体/Hash表中所有实体)、Collection Fill Ratio(集合填充率=size/capacity)、Array Fill Ratio(集合填充率)。但这种方式只能查看那些具有预分配内存能力的集合。 填充率可以作为优化的一个参考，ArrayList填充率低说明我们当初对List的初始化大小预估有误，或者HashMap的冲突较大就说明我们的Key选的有问题或者hash算法需要改进等。我们还可以通过Java Collections-&gt;Hash Entries查看key value。 Threads and Stacksdump出的文件包含了JVM运行时的所有信息，当然MAT也就可以帮我们分析出其中的线程和栈信息。 Exporting your results在我们分析完成之后，可以将我们的分析导出，分享给大家。导出有三种格式：html、cvs、txt。注意：导出的内容是你当前打开的分析窗口，如果你当前MAT没有任何分析窗口，导出的文件便为空。比如：下图中，我导出的内容就只有线程概览。 Object Query LanguageTODO 单独一篇来讲 参考整理自http://eclipsesource.com/blogs/2013/01/21/10-tips-for-using-the-eclipse-memory-analyzer/ MAT官方文档]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo源码 SPI实现之ExtensionLoader]]></title>
      <url>%2F2017%2F03%2F07%2FDubbo%E6%BA%90%E7%A0%81-SPI%E5%AE%9E%E7%8E%B0%E4%B9%8BExtensionLoader%2F</url>
      <content type="text"><![CDATA[Dubbo SPISPI 全称为 (Service Provider Interface) ，JDK也默认提供了SPI的一种实现，不过对比Dubbo的实现，JDK的实现就非常简单。 简单说下JDK默认的SPI用法。 定义Service接口 增加Service实现类 META-INF/services目录下建立以接口包全名命名的文件，文件中写入实现类的包名+类名 用Java提供的ServiceLoader来加载实现 看下如何使用ServiceLoader进行加载 123456789101112131415/*** com.cxd.spi.SayHello文件内容如下：* com.cxd.spi.impl.TomSayHello* com.cxd.spi.impl.JerrySayHello**/public class SPIMain &#123; public static void main(String[] args) &#123; ServiceLoader&lt;SayHello&gt; sayHellos = ServiceLoader.load(SayHello.class); Iterator&lt;SayHello&gt; sayHelloIterator = sayHellos.iterator(); while (sayHelloIterator.hasNext()) &#123; SayHello sayHello = sayHelloIterator.next(); sayHello.say(); &#125; &#125;&#125; ServiceLoader的实现也是比较简单，说下过程，不再列出源码。ServiceLoader根据传入的class去约定的目录下找到相应的文件逐行读取，然后用当前线程的ClassLoader加载文件中定义的实现类，通过class.newInstance()创建实例对象。ServiceLoader通过返回迭代器的方式让我们遍历所有的借口实现。 Dubbo整体思路也是如此，但是Dubbo SPI实现的功能就比较强大了。SPI通过定义文件实现，但是文件格式并没有局限，Dubbo中使用key=value的形式来进行定义，这也是dubbo能够灵活支持多种协议以及实现良好扩展性的关键所在。 在Dubbo里面使用ExtensionLoader来加载扩展点（即：接口的具体实现），每类接口Dubbo都有默认的实现，当然我们也可以根据自己的业务需要来定义自己的扩展，而扩展的方式也非常简单，SPI的方式给Dubbo提供了框架极好的扩展性。 下面我们主要来看ExtensionLoader，它是Dubbo对SPI实现的核心，也是Dubbo的核心。 每个定义的SPI的接口都会构建一个ExtensionLoader实例，ExtensionLoader采用工厂模式，以静态方法向外提供ExtensionLoader的实例。实例存储在ExtensionLoader内部静态不可变变量中。 12//ExtensionLoader.javaprivate static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt;(); 外部使用时调用：ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension()；getExtensionLoader方法创建ExtensionLoader实例，getAdaptiveExtension方法会加载扩展点中的实现类，并创建或者选择适配器。 读取SPI注解的value值，如果value不为空则作为缺省的扩展点名 依次读取指定路径下的扩展点META-INF/dubbo/internal/META-INF/dubbo/META-INF/dubbo/services/ getAdaptiveExtension方法最终调用loadFile来完成对SPI文件的读取解析。 loadFile方法逐行读取SPI文件内容并进行解析 实现类上是否含有@Adaptive注解，如果有，则将其作为适配器缓存到cachedAdaptiveClass，并进入下一行配置的解析，一个SPI只能有一个适配器，否则会报错； 如果实现类上没有@Adaptive注解，那么看其是否存在以当前获取接口类型为入参的构造器，如果有，则将其作为包装器(wrapper)存入cachedWrapperClasses变量； 如果实现类既没有@Adaptive注解，也不是包装器，那它就是扩展点的具体实现 判断扩展实现上是否有@Activate注解，如果有，将其缓存到cachedActivates(一个类型为Map的变量)中，然后将其key作为扩展点的名字，放入cachedClasses(一个类型为Holder]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[服务器Load高简单排查]]></title>
      <url>%2F2017%2F02%2F27%2F%E6%9C%8D%E5%8A%A1%E5%99%A8Load%E9%A3%99%E9%AB%98%E6%8E%92%E6%9F%A5%E6%96%B9%E6%B3%95%2F</url>
      <content type="text"><![CDATA[服务器Load飙高排查方法线上碰到CPU利用率高或者Load高的时候，排查的顺序。 拿到进程PID：ps -ef | grep java 或者 jps dump应用栈信息：jstack PID &gt; PID.stack top查看导致高CPU的进程: top 后键入 x 默认按照CPU使用率排序进程，键入c可看到commond 查看导致高CPU利用率的线程信息：top -Hp PID 查看CPU利用率高线程的栈信息，stack文件中线程号为16进制，需要top出来的线程号进行转换：printf ‘%x\n’ ThreadPID 大神有整理出脚本来简化以上操作步骤，可以直接揪出指定进程中CPU使用率较高的java线程，详情移步：查找繁忙的java线程 两个常用命令：dump内存：jmap -dump:format=b,file=/home/admin/PID.bin PID 一般dump出的文件比较大，建议压缩后传输gzip fileName 远程拷贝参考scp 结尾附上查找繁忙的java线程脚本源码，用于快速排查Java的CPU性能问题(top us值过高)，自动查出运行的Java进程中消耗CPU多的线程，并打印出其线程栈，从而确定导致性能问题的方法调用。 12345678910111213show-busy-java-threads.sh# 从 所有的 Java进程中找出最消耗CPU的线程（缺省5个），打印出其线程栈。show-busy-java-threads.sh -c &lt;要显示的线程栈数&gt;show-busy-java-threads.sh -c &lt;要显示的线程栈数&gt; -p &lt;指定的Java Process&gt;############################### 注意：############################### 如果Java进程的用户 与 执行脚本的当前用户 不同，则jstack不了这个Java进程。# 为了能切换到Java进程的用户，需要加sudo来执行，即可以解决：sudo show-busy-java-threads.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147#!/bin/bash# @Function# Find out the highest cpu consumed threads of java, and print the stack of these threads.## @Usage# $ ./show-busy-java-threads.sh## @author Jerry Leereadonly PROG=`basename $0`readonly -a COMMAND_LINE=("$0" "$@")usage() &#123; cat &lt;&lt;EOFUsage: $&#123;PROG&#125; [OPTION]...Find out the highest cpu consumed threads of java, and print the stack of these threads.Example: $&#123;PROG&#125; -c 10Options: -p, --pid find out the highest cpu consumed threads from the specifed java process, default from all java process. -c, --count set the thread count to show, default is 5 -h, --help display this help and exitEOF exit $1&#125;readonly ARGS=`getopt -n "$PROG" -a -o c:p:h -l count:,pid:,help -- "$@"`[ $? -ne 0 ] &amp;&amp; usage 1eval set -- "$&#123;ARGS&#125;"while true; do case "$1" in -c|--count) count="$2" shift 2 ;; -p|--pid) pid="$2" shift 2 ;; -h|--help) usage ;; --) shift break ;; esacdonecount=$&#123;count:-5&#125;redEcho() &#123; [ -c /dev/stdout ] &amp;&amp; &#123; # if stdout is console, turn on color output. echo -ne "\033[1;31m" echo -n "$@" echo -e "\033[0m" &#125; || echo "$@"&#125;yellowEcho() &#123; [ -c /dev/stdout ] &amp;&amp; &#123; # if stdout is console, turn on color output. echo -ne "\033[1;33m" echo -n "$@" echo -e "\033[0m" &#125; || echo "$@"&#125;blueEcho() &#123; [ -c /dev/stdout ] &amp;&amp; &#123; # if stdout is console, turn on color output. echo -ne "\033[1;36m" echo -n "$@" echo -e "\033[0m" &#125; || echo "$@"&#125;# Check the existence of jstack command!if ! which jstack &amp;&gt; /dev/null; then [ -z "$JAVA_HOME" ] &amp;&amp; &#123; redEcho "Error: jstack not found on PATH!" exit 1 &#125; ! [ -f "$JAVA_HOME/bin/jstack" ] &amp;&amp; &#123; redEcho "Error: jstack not found on PATH and $JAVA_HOME/bin/jstack file does NOT exists!" exit 1 &#125; ! [ -x "$JAVA_HOME/bin/jstack" ] &amp;&amp; &#123; redEcho "Error: jstack not found on PATH and $JAVA_HOME/bin/jstack is NOT executalbe!" exit 1 &#125; export PATH="$JAVA_HOME/bin:$PATH"fireadonly uuid=`date +%s`_$&#123;RANDOM&#125;_$$cleanupWhenExit() &#123; rm /tmp/$&#123;uuid&#125;_* &amp;&gt; /dev/null&#125;trap "cleanupWhenExit" EXITprintStackOfThreads() &#123; local line local count=1 while IFS=" " read -a line ; do local pid=$&#123;line[0]&#125; local threadId=$&#123;line[1]&#125; local threadId0x="0x`printf %x $&#123;threadId&#125;`" local user=$&#123;line[2]&#125; local pcpu=$&#123;line[4]&#125; local jstackFile=/tmp/$&#123;uuid&#125;_$&#123;pid&#125; [ ! -f "$&#123;jstackFile&#125;" ] &amp;&amp; &#123; &#123; if [ "$&#123;user&#125;" == "$&#123;USER&#125;" ]; then jstack $&#123;pid&#125; &gt; $&#123;jstackFile&#125; else if [ $UID == 0 ]; then sudo -u $&#123;user&#125; jstack $&#123;pid&#125; &gt; $&#123;jstackFile&#125; else redEcho "[$((count++))] Fail to jstack Busy($&#123;pcpu&#125;%) thread($&#123;threadId&#125;/$&#123;threadId0x&#125;) stack of java process($&#123;pid&#125;) under user($&#123;user&#125;)." redEcho "User of java process($user) is not current user($USER), need sudo to run again:" yellowEcho " sudo $&#123;COMMAND_LINE[@]&#125;" echo continue fi fi &#125; || &#123; redEcho "[$((count++))] Fail to jstack Busy($&#123;pcpu&#125;%) thread($&#123;threadId&#125;/$&#123;threadId0x&#125;) stack of java process($&#123;pid&#125;) under user($&#123;user&#125;)." echo rm $&#123;jstackFile&#125; continue &#125; &#125; blueEcho "[$((count++))] Busy($&#123;pcpu&#125;%) thread($&#123;threadId&#125;/$&#123;threadId0x&#125;) stack of java process($&#123;pid&#125;) under user($&#123;user&#125;):" sed "/nid=$&#123;threadId0x&#125; /,/^$/p" -n $&#123;jstackFile&#125; done&#125;ps -Leo pid,lwp,user,comm,pcpu --no-headers | &#123; [ -z "$&#123;pid&#125;" ] &amp;&amp; awk '$4=="java"&#123;print $0&#125;' || awk -v "pid=$&#123;pid&#125;" '$1==pid,$4=="java"&#123;print $0&#125;'&#125; | sort -k5 -r -n | head --lines "$&#123;count&#125;" | printStackOfThreads]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK源码 AQS]]></title>
      <url>%2F2017%2F02%2F14%2FJDK%E6%BA%90%E7%A0%81-AQS%2F</url>
      <content type="text"><![CDATA[AbstractQueueSynchronizer笔记在开始介绍之前我先来简单理解一下为什么会产生AQS。在我们应用内不可避免的会发生对一些资源的抢占，那么如何处理线程之间对资源的争夺呢？在Java SE 5 之前JDK可以使用synchronized来串行化对资源的操作，synchronized可以隐式的获取和释放锁，但是带来的不便就是不够灵活，可扩展性没有显式获取和释放锁的自主控制性强，另外synchronized是完全互斥的，没法达到诸如共享锁、读写锁的效果。对资源的竞争可以抽象为对变量状态的竞争，这正是AQS实现的基本原理，当然，AQS的实现是复杂的。AQS（AbstractQueueSynchronizer）俗称同步器，是JDK中用来构建同步组件的基础框架，比如JDK中已经实现的可重入锁（ReentrantLock）就是基于AQS实现的，它的关键方法在实现中使用了unsafe的CAS操作来提高性能。AQS采用模版方法的设计模式，屏蔽了同步状态管理、线程排队、等待与唤醒等底层操作，实现者只需要实现AQS定义的抽象方法即可快速实现自己的同步需求。 需要实现的模版接口以下列出的接口方法，并非需要全部实现，按照自己对同步器的要求选择相应的进行实现。以下方法AQS默认抛出UnsupportedOperationException。 1234567891011121314151617181920212223242526/******************独占式同步状态 start****************/protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125;protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125;/******************独占式同步状态 end*****************//******************共享式同步状态 start****************//***返回值大于等于0表示获取成功**/protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125;protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException();&#125;/******************共享式同步状态 end****************//******************获取同步状态模式 start**************/protected boolean isHeldExclusively() &#123; throw new UnsupportedOperationException();&#125;/******************获取同步状态模式 end**************/ 关键属性 属性类型及名称 描述 volatile int state 竞争资源的抽象。代表资源的占用状态。 volatile Node head 同步队列用来保存获取状态失败的线程数据结构，指向队列头部 volatile Node tail 同上，指向队列尾部 结合具体的一个实现（ReentrantLock）来看AQS。ReentrantLock中的公平锁和非公平锁便是AQS独占锁的一种实现，从ReentrantLock默认的非公平锁入手，因为他是ReentrantLock的默认锁。 123456789101112class X &#123; private final ReentrantLock lock = new ReentrantLock(); // ... public void m() &#123; lock.lock(); // block until condition holds try &#123; // ... method body &#125; finally &#123; lock.unlock() &#125; &#125;&#125; 上面是使用ReentrantLock的基本方式，当我们调用lock()方法时，发生了些什么事呢？123456789101112131415161718static final class NonfairSync extends Sync &#123; /** *直接加锁，不理会当前是否有其他线程在排队 *如果失败，则进入自旋状态，在自旋中检查当前线程是否应当挂起 **/ final void lock() &#123; //compareAndSetState/acquire/setExclusiveOwnerThread父类实现模版方法 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; //模版方法（子类实现，根据要实现锁的类性复写对应模版方法） protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; compareAndSetState由AQS提供，采用CAS的方式对state设值，保证操作的原子性。如果设置成功，则将当前线程作为排他线程；如果抢占式获取失败则进入等待队列，即acquire(1)。我们看下acquire的实现。12345678910AbstractQueuedSynchronizerpublic final void acquire(int arg) &#123; /** *1.尝试再次获取锁，成功-&gt;业务代码 *2.失败-&gt;将自己加入等待队列尾部，自旋获取锁，获取成功则返回，否则直到满足挂起条件把自己挂起 **/ if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 前面已经列出tryAcquire是需要子类实现的方法，我们在NonfairSync中看到正是如此，NonfairSync中tryAcquire方法调用了其父类Sync的nonfairTryAcquire。1234567891011121314151617181920212223242526ReentrantLock$Syncfinal boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); //获取当前资源状态，表格“关键属性”中列出的state值 int c = getState(); //如果为0，表明当前时刻没有线程占有竞争资源 if (c == 0) &#123; //尝试再次获取 if (compareAndSetState(0, acquires)) &#123; //获取成功-&gt;设置当前线程为占有线程 setExclusiveOwnerThread(current); return true; &#125; &#125; //如果当前线程为占有线程 //ps：可重入锁的特点 else if (current == getExclusiveOwnerThread()) &#123; //增加重入次数，最大值为Integer.MAX_VALUE int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 如果获取还是失败，就需要将当前线程加入等待队列的尾部，等待队列是一个FIFO双向队列。123456789101112131415161718192021222324252627282930313233343536373839AbstractQueuedSynchronizer /** FIFO同步队列* +------+ prev +-----+ +-----+*head | | &lt;----&gt; | | &lt;----&gt; | | tail* +------+ next +-----+ +-----+**/private Node addWaiter(Node mode) &#123; //默认为addWaiter(Node.EXCLUSIVE)排他模式 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //如果快速入队失败，则进入到完整入队过程 enq(node); return node;&#125;//不断CAS将Node安全追加到队列尾部private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize //注意初始化队列头部Node if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 简单说下Node的数据结构 属性 描述 int waitStatus 等待状态。字段的具体描述见下表（因为MD换行无法设置格式） Node prev 前驱节点 Node next 后继节点 Node nextWaiter Condition等待队列中的后继节点。如果该节点是Condition的，那么该节点表示等待在该Condition的下一个节点；如果不是，那么表示当前队列的默认mode（SHARED/EXCLUSIVE） Thread thread 当前节点包装的线程 waitStatus状态 值 描述 CANCELLED 1 由于在同步队列中等待的线程等待超时活着中断，需要从同步队列中取消等待，节点进入该状态将不会变化 SIGNAL -1 后继节点的线程处于等待状态，当当前节点的线程如果释放了同步状态活着取消，将会通知后继节点，使后继接待你的线程得以运行 CONDITION -2 节点在对应的Condition等待队列中，当其他线程对Condition调用了signal()方法后，该节点将会从等待队列中转移到同步队列中，准备开始对状态的竞争 PROPAGATE -3 表示下一次共享式同步状态获取将会无条件被传播下去（阅读ReentrantReadWriteLock可以看到运用） initial 0 Node非Condition下的初始态 我们看到addWaiter方法在队列最后追加了一个初始态的排他Node，完成此步骤后当前线程并没有直接被挂起，这是AQS和synchronized的不用点也是其高效的体现，我们知道线程的挂起和恢复是需要CPU进行上下文切换，这是一个相对耗时的操作，AQS在一个线程满足挂起条件前会不停的尝试获取锁，避免上下文的切换。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; //死循环获取锁，每次换醒后重新竞争获取锁，避免假唤醒 for (;;) &#123; //获取当前节点的前一个节点 final Node p = node.predecessor(); //如果前节点为头节点，再次尝试获取 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //获取成功后，设置当前节点为头节点，注意设置setHead细节,此处不再贴出代码 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //获取失败判断当前线程是否应当挂起，如果满足挂起条件则进行挂起 //挂起parkAndCheckInterrupt比较简单，直接调用LockSupport.park(this); //被唤醒后会返回当前线程的中断状态，然后在循环中继续竞争锁 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;/*** 只有当前一个节点的状态为Node.SIGNAL时返回true，即：应当挂起。**/private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //前一个节点的等待状态waitStatus int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. * 前一个节点已经设置为释放锁要通知随后的节点，可以安全挂起。 */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. * 前一个节点已经是取消状态，移除并且找到最近一个非取消状态的节点 */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. * 前节点等待状态此时已定为初始态（0）或者PROPAGATE，我们需要一个 * 通知，所以需要将前节点设置为Node.SIGNAL，但是当前节点还不应该 * 被挂起，被挂起前应当确定当前线程确实不能够获取锁 */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 至此，一个竞争失败的线程就被安全挂起，等待其他线程释放锁后把它唤醒，被唤醒后继续未竟事业。我们再来看下AQS锁释放的过程，还是以ReentrantLock为入口。12345ReentrantLockpublic void unlock() &#123; //ReentrantLock.unlock直接调用非公平锁的release方法，该方法是AQS实现的模版方法。 sync.release(1);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445AbstractQueuedSynchronizerpublic final boolean release(int arg) &#123; //AQS先调用由子类ReentrantLock实现的的tryRelease方法，如果释放成功，则唤醒后续节点 if (tryRelease(arg)) &#123; Node h = head; //如果头节点不为空并且等待状态不是初始态（0），则唤醒后续节点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125;private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. * 如果当前节点等待状态是负数（比如-1，需要换醒后续节点） * 尝试改变头节点等待状态，改变失败或者已经被其他线程改变也没有关系 * 因为它总会被设置为正常的状态并且被移除出队列 */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. * 找出正常的节点并且唤醒 */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; //如果下个节点不存在或者已被取消，则找出最近的等待状态小于0的节点 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; //唤醒后续节点 if (s != null) LockSupport.unpark(s.thread);&#125; 12345678910111213141516ReentrantLock$NonfairSyncprotected final boolean tryRelease(int releases) &#123; //因为当前是可重入锁，state值实际保存了当前线程的重入次数，释放的时候需要依次释放 int c = getState() - releases; //非锁持有线程释放锁会抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; //如果c为0，表明当前线程已经完全释放锁 free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 至此，排他锁的一种获取和释放就结束了。实际上AQS中还有Condition锁（称之为锁也有些不恰当），每个Condition自己又维护了一个等待队列，Condition等待队列中的Node满足条件会被转移到AQS维护的队列中来完成锁的竞争。感兴趣的同学可以看ReentrantReadWriteLock的实现，ReentrantReadWriteLock就是基于AQS的该特性实现的。 从网上摘抄过来一段对AQS的总结作为结束。 首先，AQS并不关心“是什么锁”，对于AQS来说它只是实现了一系列的用于判断“资源”是否可以访问的API,并且封装了在“访问资源”受限时将请求访问的线程的加入队列、挂起、唤醒等操作， AQS只关心“资源不可以访问时，怎么处理？”、“资源是可以被同时访问，还是在同一时间只能被一个线程访问？”、“如果有线程等不及资源了，怎么从AQS的队列中退出？”等一系列围绕资源访问的问题，而至于“资源是否可以被访问？”这个问题则交给AQS的子类去实现。 这是典型的将规则和操作分开的设计思路：规则子类定义，操作逻辑因为具有公用性，放在父类中去封装。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[test4j导致Load飙高排查]]></title>
      <url>%2F2016%2F11%2F18%2Ftest4j%E5%AF%BC%E8%87%B4Load%E9%A3%99%E9%AB%98%E6%8E%92%E6%9F%A5%2F</url>
      <content type="text"><![CDATA[记一次test4j导致CPU飙高的事故在使用Jenkins构建工程时出现服务器Load不断飙升的现象，导致构建无法正常进行，查看构建日之后发现一些应用处出现OOM的状况。于是，我就开始查找原因的漫漫长征路。首先简单了解下test4j初始化过程(忽略读取相关配置及之前)。1234Test4jCore-&gt;CoreModule:1.initSingletonInstance()CoreModule-&gt;ConfigurationLoader:2.loading()\n加载系统信息\n模块信息\n配置信息（比如：数据库）\n等CoreModule-&gt;ConfigHelper:3.logLevel()\n设置打印消息级别CoreModule-&gt;CoreModule:4.new CoreModule() CoreModule时序列图1234CoreModule-&gt;ModulesLoader:1.load()\n加载test4j模块并进行初始化(init)\n初始化Module管理器，主要管理Module监听器note right of ModulesLoader:相关模块参见test4j-default.propertiesCoreModule-&gt;CoreModule$CoreModuleListener:2.new CoreModule$CoreModuleListener()CoreModule-&gt;3.Module:afterInit() 上面简单列出test4j的初始化流程，那么这次故障原因在哪产生的呢？不着急，容我慢慢道来。 事故现场：在maven执行test生命周期的过程中，发现cpu利用率不断升高，甚至达到700%，load也随之不断飙升。 排查点一：业务需要大量计算。纵观所有单元测试，没有大量数据计算，那么业务本身原因也就排除。 排查点二：load飙高，是否有大量IO等待。查看stack及各个子线程cpu使用率后，确实有一些IO等待（redis读取等待），此点Mark。 排查点三：IO不会造成高cpu使用率，那么最可能的就是GC了。果不其然，4个GC线程cpu使用率均在100%左右。 排查点四：既然GC这么高，会不会是heap给的太小，但查看程序执行日之后基本排除此种可能，因为发现每个测试类开始test4j都会对spring重新初始化。 排查到第四点就有些兴奋了，test4j是有参数可以设定spring容器行为的，@SpringContext注解中，shared属性默认为fasle，即：spring容器在测试类之间并不共享。那么改掉它，重新跑。竟然好了！那么为什么采用默认的shared值会有问题呢？ 排查到这里基本可以确定：1.test4j配置有问题；2.test4j自身的BUG 随后查看了test4j的源码，尼玛！！share属性在程序中竟然写死为ture！！test4j一直就是在以共享spring容器的方式运行！！看到这里基本上就可以确定是test4j的问题了，毕竟这个项目最后一次更新停留在了两年前！！ 让我们重新审视test4j的启动，发现还并没有涉及到对spring的操作，因为是对spring的多次初始化，所以我们的目光可以聚焦在对SpringModule的处理上。 在test4j中每个Module均包含一个内部监听类，test4j会在不同的测试生命周期点通知到监听类，以便各个Module做出响应的行为。 下面是SpringModule的监听类部分源码： 12345678910111213141516SpringModule.javapublic void beforeClass(Class testClazz) &#123; SpringModuleHelper.resetDumpReference(); SpringInitInvoker.invokeSpringInitMethod(TestContext.currTestedObject()); //每次切换测试类，都会init，内部是怎么实现的呢？看下段源码 Test4JSpringContext springContext = SpringModuleHelper.initSpringContext(testClazz, contextFactory); MessageHelper.warn("SpringModuleHelper.initSpringContext " + SpringTestedContext.getSpringContext()); SpringTestedContext.setSpringContext(springContext);&#125;Overridepublic void afterClass(Object testedObject) &#123; //释放当前测试类Spring SpringTestedContext.removeSpringContext();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970SpringModuleHelper.javapublic static Test4JSpringContext initSpringContext(Class testClazz, ApplicationContextFactory contextFactory) &#123; //首先会从test4j自定义的上下文查找spring上下文，没找到进行创建 Test4JSpringContext springContext = SpringTestedContext.getSpringContext(); if (springContext != null) &#123; return springContext; &#125; //找出配置@SpringContext SpringContext annotation = AnnotationHelper.getClassLevelAnnotation(SpringContext.class, testClazz); Class declaredAnnotationClazz = AnnotationHelper.getClassWithAnnotation(SpringContext.class, testClazz); if (annotation == null) &#123; return null; &#125; //spring容器是否共享，程序默认为false boolean share = annotation.share(); Test4JSpringContext context = null; if (share) &#123; //SHARED_SPRING_CONTEXT以@SpringContext被注解类为key，来实现spring容器共享 context = SHARED_SPRING_CONTEXT.get(declaredAnnotationClazz); &#125; if (context == null) &#123; //注意：BUG即将诞生！！！！！！！ context = newSpringContext(testClazz, contextFactory, annotation); &#125; if (share) &#123; SHARED_SPRING_CONTEXT.put(declaredAnnotationClazz, context); &#125; //将springContext设置回测试上下文 SpringTestedContext.setSpringContext(context); return context;&#125;private static Test4JSpringContext newSpringContext(Class testClazz, ApplicationContextFactory contextFactory, SpringContext annotation) &#123; long startTime = System.currentTimeMillis(); String[] locations = annotation.value(); boolean allowLazy = annotation.allowLazy(); Test4JSpringContext springContext = contextFactory.createApplicationContext(Arrays.asList(locations), false, allowLazy); //设置Context共享方式，BUG也由此产生了。 springContext.setShared(annotation.share()); //test4j对spring进行了封装，内部调用spring方法初始化 springContext.refresh(); long duration = System.currentTimeMillis() - startTime; MessageHelper.warn(String.format("take %d ms to init spring context for test obejct[%s]", duration, testClazz.getName())); return springContext;&#125;/** * 释放测试类的spring容器 * * @param springContext * AbstractApplicationContext实例，这里定义为Object是方便其它模块脱离spring依赖 */public static void closeSpringContext(Object springContext) &#123; if (springContext == null) &#123; return; &#125; if (!(springContext instanceof Test4JSpringContext)) &#123; String error = String.format("there must be something error, the type[%s] object isn't a spring context.",springContext.getClass().getName()); throw new RuntimeException(error); &#125; Test4JSpringContext context = (Test4JSpringContext) springContext; //这个方法 if (context.isShared() == false) &#123; context.destroy(); MessageHelper.warn("close spring context for class:" + TestContext.currTestedClazzName()); &#125;&#125; 123456789101112public class Test4JSpringContext extends ClassPathXmlApplicationContext &#123; private boolean shared; /** * 设置是否共享spring * * @param share */ public void setShared(boolean share) &#123; //哈哈哈，作者写了一个低级BUG出来，当你没使用共享方式的时候，恭喜你，你惨了！继续看代码！ this.shared = true; &#125;&#125; 此时BUG的全貌出现了，大家仔细看，test4j中默认的shared为false，也就是默认不共享，但是在为Test4JSpringContext设置shared时却写死为true了。我们还记得test4j的每个Module都有一个内部监听类来处理关心的测试中的各个生命周期，在每个测试类开始前（beforeClass），SpringModule负责spring容器的创建（如果需要），在测试结束后（afterClass），负责容器的销毁（如果需要）。 那么问题就在这里，当我们使用默认的shared时，每个测试开始都会创建一个spring容器，这是正常的，因为我们并没有共享spring容器，但是，当测试结束时，本应该根据shared值销毁spring容器，却因为BUG，从Test4JSpringContext中取出的值为true，作孽啊，test4j认为我们是共享的，便保留了当前的spring容器，于是乎，就出现了车祸现场！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring源码 AOP代理流程]]></title>
      <url>%2F2016%2F10%2F29%2FSpring%E6%BA%90%E7%A0%81-AOP%E4%BB%A3%E7%90%86%E6%B5%81%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[AOP是spring中重要的一个组件，今天看了下AOP代理生成的过程，做了简单的记录，留作日后查看。 spring在完成对bean的装配后，在暴露到工厂前，会对进行实例化。 在这个过程中可以看到spring对bean生命周期控制的几个用户可以定制的步骤：BeanPostProcessor.postProcessBeforeInitialization－&gt;InitializingBean.afterPropertiesSet-&gt;BeanPostProcessor.postProcessAfterInitialization我们可以通过实现这几个接口来实现对bean不同阶段的一个定制，spring的AOP就通过BeanPostProcessor.postProcessAfterInitialization阶段介入。可以看出spring面向组件编程的思想。 spring会扫描BeanPostProcessor实现，在此进行处理。我们关注对注解方式实现的Aspect。 如果当前bean需要被代理，则会生成代理 bean，对我们真正的bean进行包装。 这里会从所有的advice中匹配出适合当前bean的advice，如果找到这些advice，就需要该 bean进行封装，即：创建代理。 下面看下，spring筛选advice的过程。找出合适的advisor和advice。但该方法并无实际操作，而是直接调用了其他方法。 首先列出spring中所有advice，然后匹配能够应用的。 此处advice分了两类进行遍历匹配，不知道为什么Advisor会分为两类，客官有知道的请指教（后面也会再看这个问题）。使用注解的aspect不属IntroductionAdvisor。 取出切入点，做最后的判断。 真正的决策者出现了，看看spring到底是怎么来断定该Advice是否符合当前的bean。可以看到，spring为了判断该bean是否能够应用该advice，查了当前bean实现的所有接口，但最终判断还是根据当前实例的某个实现方法是否满足匹配规则（比如：实例的某个复写方法上加上了自定义Aspect注解），如果满足，就认为该bean需要加入该advice。即：该类需要做代理类进行封装。]]></content>
    </entry>

    
  
  
</search>
